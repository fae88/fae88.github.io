<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>A Gemini Boy</title>
  
  <subtitle>welcome to my site</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.fufan.me/"/>
  <updated>2018-11-09T09:01:08.471Z</updated>
  <id>http://www.fufan.me/</id>
  
  <author>
    <name>fae88</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>JVM专题（四）—— 图解垃圾回收</title>
    <link href="http://www.fufan.me/2018/06/09/JVM%E4%B8%93%E9%A2%98%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94-%E5%9B%BE%E8%A7%A3%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <id>http://www.fufan.me/2018/06/09/JVM专题（四）——-图解垃圾回收/</id>
    <published>2018-06-09T09:00:00.000Z</published>
    <updated>2018-11-09T09:01:08.471Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 17:01:08 GMT+0800 (China Standard Time) --><p>对于调优之前，我们必须要了解其运行原理，java 的垃圾收集Garbage Collection 通常被称为“GC”，它诞生于1960年 MIT 的 Lisp 语言，经过半个多世纪，目前已经十分成熟了。因此本篇主要从这三个方面来了解:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 哪些对象需要被回收？</span><br><span class="line"></span><br><span class="line">2. 什么时候回收？</span><br><span class="line"></span><br><span class="line">3. 如何回收？</span><br></pre></td></tr></table></figure><h3 id="一、谁要被回收"><a href="#一、谁要被回收" class="headerlink" title="一、谁要被回收"></a>一、谁要被回收</h3><p>java虚拟机在执行java程序的过程中会把它所管理的内存划分为若干个不同是数据区域，这些区域有各自各自的用途。主要包含以下几个部分组成：<br><img src="/image/jvm-4-1.png" alt=""><br><img src="/image/jvm-4-0.png" alt=""></p><h4 id="1、程序计数器"><a href="#1、程序计数器" class="headerlink" title="1、程序计数器"></a>1、程序计数器</h4><p>程序计数器占用的内存空间我们可以忽略不计，它是每个线程所执行的字节码的行号指示器。</p><h4 id="2、虚拟机栈"><a href="#2、虚拟机栈" class="headerlink" title="2、虚拟机栈"></a>2、虚拟机栈</h4><p>java的虚拟机栈是线程私有的，生命周期和线程相同。它描述的是方法执行的内存模型。同时用于存储局部变量、操作数栈、动态链接、方法出口等。</p><h4 id="3、本地方法栈"><a href="#3、本地方法栈" class="headerlink" title="3、本地方法栈"></a>3、本地方法栈</h4><p>本地方法栈，类似虚拟机栈，它调用的是是native方法。</p><h4 id="4、堆"><a href="#4、堆" class="headerlink" title="4、堆"></a>4、堆</h4><p>堆是jvm中管理内存中最大一块。它是被共享，存放对象实例。也被称为“gc堆”。垃圾回收的主要管理区域</p><h4 id="5、方法区"><a href="#5、方法区" class="headerlink" title="5、方法区"></a>5、方法区</h4><p>方法区也是共享的内存区域。它主要存储已被虚拟机加载的类信息、常量、静态变量、即时编译器（jit）编译后的代码数据。</p><p>以上就是jvm在运行时期主要的内存组成，我们看到常见的内存使用不但存在于堆中，还会存在于其他区域，虽然堆的管理对程序的管理至关重要，但我们不能只局限于这一个区域，特别是当出现内存泄露的时候，我们除了要排查堆内存的情况，还得考虑虚拟机栈的以及方法区域的情况。</p><p>知道了要对谁以及那些区域进行内存管理，我还需要知道什么时候对这些区域进行垃圾回收。</p><h3 id="二、什么时候回收"><a href="#二、什么时候回收" class="headerlink" title="二、什么时候回收"></a>二、什么时候回收</h3><p>在垃圾回收之前，我们必须确定的一件事就是对象是否存活？这就牵扯到了判断对象是否存活的算法了。</p><h4 id="引用计数算法："><a href="#引用计数算法：" class="headerlink" title="引用计数算法："></a>引用计数算法：</h4><p>给对象中添加一个引用计数器，每当有一个地方引用它时，计数器+1，当引用失效，计数器-1.任何时刻计数器为0的对象就是不可能再被使用的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给对象中添加一个引用计数器，每当有一个地方引用它时，计数器+1，当引用失效，计数器-1.任何时刻计数器为0的对象就是不可能再被使用的。</span><br></pre></td></tr></table></figure><h4 id="可达性分析算法："><a href="#可达性分析算法：" class="headerlink" title="可达性分析算法："></a>可达性分析算法：</h4><p>通过一系列称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GCRoots没有任何引用链相连的时候，则证明此对象是不可用的。</p><p>比如如下，右侧的对象是到GCRoot时不可达的，可以判定为可回收对象。</p><p><img src="/image/jvm-4-2.png" alt=""></p><p>在java中，可以作为GCRoot的对象包括以下几种：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">* 虚拟机栈中引用的对象。</span><br><span class="line"></span><br><span class="line">* 方法区中静态属性引用的对象。</span><br><span class="line"></span><br><span class="line">* 方法区中常量引用的对象。</span><br><span class="line"></span><br><span class="line">* 本地方法中JNI引用的对象。</span><br></pre></td></tr></table></figure><p>基于以上，我们可以知道，当当前对象到GCRoot中不可达时候，即会满足被垃圾回收的可能。</p><p>那么是不是这些对象就非死不可，也不一定，此时只能宣判它们存在于一种“缓刑”的阶段，要真正的宣告一个对象死亡。至少要经历两次标记：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">第一次：对象可达性分析之后，发现没有与GCRoots相连接，此时会被第一次标记并筛选。</span><br><span class="line"></span><br><span class="line">第二次：对象没有覆盖finalize（）方法，或者finalize（）方法已经被虚拟机调用过，此时会被认定为没必要执行。</span><br><span class="line">    (大致描述一下finalize流程：当对象变成(GC Roots)不可达时，GC会判断该对象是否覆盖了finalize方法，若未覆盖，则直接将其回收。否则，若对象未执行过finalize方法，将其放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法。执行finalize方法完毕后，GC会再次判断该对象是否可达，若不可达，则进行回收，否则，对象“复活”。)</span><br></pre></td></tr></table></figure><h3 id="三、如何回收"><a href="#三、如何回收" class="headerlink" title="三、如何回收"></a>三、如何回收</h3><p>上述的两点讲解之后，我们大概明白了，哪些对象会被回收，以及回收的依据是什么，但回收的这个工作实现起来并不简单，首先它需要扫描所有的对象，鉴别谁能够被回收，其次在扫描期间需要 ”stop the world“ 对象能被冻结，不然你刚扫描，他的引用信息有变化，你就等于白做了。</p><h4 id="分代回收"><a href="#分代回收" class="headerlink" title="分代回收"></a>分代回收</h4><p>我们从一个object1来说明其在分代垃圾回收算法中的回收轨迹。</p><p>1、object1新建，出生于新生代的Eden区域。</p><p><img src="/image/jvm-4-3.png" alt=""><br>2、minor GC，object1 还存活，移动到Fromsuvivor空间，此时还在新生代。<br><img src="/image/jvm-4-4.png" alt=""></p><p>3、minor GC，object1 仍然存活，此时会通过复制算法，将object1移动到ToSuv区域，此时object1的年龄age+1。<br><img src="/image/jvm-4-5.png" alt=""></p><p>4、minor GC，object1 仍然存活，此时survivor中和object1同龄的对象并没有达到survivor的一半，所以此时通过复制算法，将fromSuv和Tosuv 区域进行互换，存活的对象被移动到了Tosuv。<br><img src="/image/jvm-4-6.png" alt=""></p><p>5、minor GC，object1 仍然存活，此时survivor中和object1同龄的对象已经达到survivor的一半以上（toSuv的区域已经满了），object1被移动到了老年代区域。<br><img src="/image/jvm-4-7.png" alt=""></p><p>6、object1存活一段时间后，发现此时object1不可达GcRoots，而且此时老年代空间比率已经超过了阈值,触发了majorGC（也可以认为是fullGC，但具体需要垃圾收集器来联系），此时object1被回收了。fullGC会触发 stop the world。<br><img src="/image/jvm-4-8.png" alt=""></p><p>在以上的新生代中，我们有提到对象的age，对象存活于survivor状态下，不会立即晋升为老生代对象，以避免给老生代造成过大的影响，它们必须要满足以下条件才可以晋升：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、minor gc 之后，存活于survivor 区域的对象的age会+1，当超过（默认）15的时候，转移到老年代。</span><br><span class="line"></span><br><span class="line">2、动态对象，如果survivor空间中相同年龄所有的对象大小的综合和大于survivor空间的一半，年级大于或等于该年级的对象就可以直接进入老年代。</span><br></pre></td></tr></table></figure><p>以上采用分代垃圾收集的思想，对一个对象从存活到死亡所经历的历程。期间，在新生代的时刻，会用到复制算法，在老年代时，有可能会用到标记-清楚算法（mark-sweep）算法或者标记-整理算法，这些都是垃圾回收算法基于不同区域的实现，我们看下这几种回收算法的实现原理。</p><h3 id="四、垃圾收集器"><a href="#四、垃圾收集器" class="headerlink" title="四、垃圾收集器"></a>四、垃圾收集器</h3><p>垃圾收集器是内存回收的具体实现，不同的厂商提供的垃圾收集器有很大的差别，一般的垃圾收集器都会作用于不同的分代，需要搭配使用。以下是各种垃圾收集器的组合方式：</p><p><img src="/image/jvm-4-9.png" alt=""></p><p><img src="/image/jvm-4-10.png" alt=""></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 17:01:08 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;对于调优之前，我们必须要了解其运行原理，java 的垃圾收集Garbage Collection 通常被称为“GC”，它诞生
      
    
    </summary>
    
    
      <category term="jvm" scheme="http://www.fufan.me/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>分布式锁的实现方式（一）——数据库和Redis锁</title>
    <link href="http://www.fufan.me/2018/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CRedis%E9%94%81/"/>
    <id>http://www.fufan.me/2018/04/07/分布式锁的实现方式（一）——数据库和Redis锁/</id>
    <published>2018-04-07T02:29:00.000Z</published>
    <updated>2018-11-07T06:07:36.483Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>分布式锁一般有三种实现方式：1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁。4.基于consul的分布式锁。</p><p>在之前的java多线程系列中（java多线程系列（三）——锁），我已经学习到了各种各样的锁在jdk中的使用。如今大部分互联网系统都是分布式系统，所以实现支持具体业务的高可用分布式锁是我们经常要做的事情。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><h4 id="什么是锁"><a href="#什么是锁" class="headerlink" title="什么是锁"></a>什么是锁</h4><ul><li>在单进程的系统中，当存在多个线程可以同时改变某个变量（可变共享变量）时，就需要对变量或代码块做同步，使其在修改这种变量时能够线性执行消除并发修改变量。</li><li>而同步的本质是通过锁来实现的。为了实现多个线程在一个时刻同一个代码块只能有一个线程可执行，那么需要在某个地方做个标记，这个标记必须每个线程都能看到，当标记不存在时可以设置该标记，其余后续线程发现已经有标记了则等待拥有标记的线程结束同步代码块取消标记后再去尝试设置标记。这个标记可以理解为锁。</li><li>不同地方实现锁的方式也不一样，只要能满足所有线程都能看得到标记即可。如 Java 中 synchronize 是在对象头设置标记，Lock 接口的实现类基本上都只是某一个 volitile 修饰的 int 型变量其保证每个线程都能拥有对该 int 的可见性和原子修改，linux 内核中也是利用互斥量或信号量等内存数据做标记。</li><li>除了利用内存数据做锁其实任何互斥的都能做锁（只考虑互斥情况），如流水表中流水号与时间结合做幂等校验可以看作是一个不会释放的锁，或者使用某个文件是否存在作为锁等。只需要满足在对标记进行修改能保证原子性和内存可见性即可。</li></ul><h4 id="什么是分布式？"><a href="#什么是分布式？" class="headerlink" title="什么是分布式？"></a>什么是分布式？</h4><p>分布式的 CAP 理论告诉我们:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。</span><br></pre></td></tr></table></figure><p></p><p>目前很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。基于 CAP理论，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证最终一致性。</p><p>在许多的场景中，我们为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。很多时候我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，通过 Java 提供的并发 API 我们可以解决，但是在分布式环境下，就没有那么简单啦。</p><ul><li>分布式与单机情况下最大的不同在于其不是多线程而是多进程。</li><li>多线程由于可以共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一台物理机上，因此需要将标记存储在一个所有进程都能看到的地方。</li></ul><h4 id="什么是分布式锁？"><a href="#什么是分布式锁？" class="headerlink" title="什么是分布式锁？"></a>什么是分布式锁？</h4><ul><li>当在分布式模型下，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数。</li><li>与单机模式下的锁不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。（我觉得分布式情况下之所以问题变得复杂，主要就是需要考虑到网络的延时和不可靠。。。一个大坑）</li><li>分布式锁还是可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如 Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行。</li></ul><h4 id="我们需要怎样的分布式锁？"><a href="#我们需要怎样的分布式锁？" class="headerlink" title="我们需要怎样的分布式锁？"></a>我们需要怎样的分布式锁？</h4><ul><li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器-上的一个线程执行。</li><li>这把锁要是一把可重入锁（避免死锁）</li><li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li><li>这把锁最好是一把公平锁（根据业务需求考虑要不要这条）</li><li>有高可用的获取锁和释放锁功能</li><li>获取锁和释放锁的性能要好</li></ul><h3 id="基于数据库做分布式锁"><a href="#基于数据库做分布式锁" class="headerlink" title="基于数据库做分布式锁"></a>基于数据库做分布式锁</h3><h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p>基于表主键唯一做分布式锁</p><p><strong><em>思路：</em></strong> 利用主键唯一的特性，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可。</p><p>上面这种简单的实现有以下几个问题：</p><ul><li>这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</li><li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li><li>这把锁只能是非阻塞的，因为数据的 insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li><li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li><li>这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁。</li><li>在 MySQL 数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象。</li></ul><p>当然，我们也可以有其他方式解决上面的问题。</p><ul><li>数据库是单点？搞两个数据库，数据之前双向同步，一旦挂掉快速切换到备库上。</li><li>没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。</li><li>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。</li><li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li><li>非公平的？再建一张中间表，将等待锁的线程全记录下来，并根据创建时间排序，只有最先创建的允许获取锁。</li><li>比较好的办法是在程序中生产主键进行防重。</li></ul><h4 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h4><p>基于表字段版本号做分布式锁</p><p>这个策略源于 mysql 的 mvcc 机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断 sql 每次进行判断，增加了数据库操作的次数，在高并发的要求下，对数据库连接的开销也是无法忍受的。</p><h4 id="基于数据库排他锁做分布式锁"><a href="#基于数据库排他锁做分布式锁" class="headerlink" title="基于数据库排他锁做分布式锁"></a>基于数据库排他锁做分布式锁</h4><p>在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁 (注意： InnoDB 引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给要执行的方法字段名添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。)。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。</p><p>我们可以认为获得排他锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，通过connection.commit()操作来释放锁。</p><p>这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。</p><ul><li>阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。</li><li>锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。</li></ul><p>但是还是无法直接解决数据库单点和可重入问题。</p><p>这里还可能存在另外一个问题，虽然我们对方法字段名使用了唯一索引，并且显示使用 for update 来使用行级锁。但是，MySQL 会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。。。</p><p>还有一个问题，就是我们要使用排他锁来进行分布式锁的 lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆。</p><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><ul><li><p>优点：简单，易于理解</p></li><li><p>缺点：会有各种各样的问题（操作数据库需要一定的开销，使用数据库的行级锁并不一定靠谱，性能不靠谱）</p></li></ul><h3 id="基于-Redis-做分布式锁"><a href="#基于-Redis-做分布式锁" class="headerlink" title="基于 Redis 做分布式锁"></a>基于 Redis 做分布式锁</h3><h4 id="使用redis的setNX命令实现分布式锁"><a href="#使用redis的setNX命令实现分布式锁" class="headerlink" title="使用redis的setNX命令实现分布式锁　　"></a>使用redis的setNX命令实现分布式锁</h4><h5 id="实现的原理"><a href="#实现的原理" class="headerlink" title="实现的原理"></a>实现的原理</h5><p>Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系。redis的SETNX命令可以方便的实现分布式锁。</p><h5 id="基本命令解析"><a href="#基本命令解析" class="headerlink" title="基本命令解析"></a>基本命令解析</h5><p>1）setNX（SET if Not eXists）</p><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETNX key value</span><br></pre></td></tr></table></figure><p>将 key 的值设为 value ，当且仅当 key 不存在。</p><p>若给定的 key 已经存在，则 SETNX 不做任何动作。</p><p>SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写</p><p>返回值：<br>设置成功，返回 1 。<br>设置失败，返回 0 。</p><p>所以我们使用执行下面的命令<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETNX lock.foo &lt;current Unix time + lock timeout + 1&gt;</span><br></pre></td></tr></table></figure><p></p><ul><li>如返回1，则该客户端获得锁，把lock.foo的键值设置为时间值表示该键已被锁定，该客户端最后可以通过DEL lock.foo来释放该锁。</li><li>如返回0，表明该锁已被其他客户端取得，这时我们可以先返回或进行重试等对方完成或等待锁超时。</li></ul><p>2）getSET</p><p>语法：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GETSET key value</span><br></pre></td></tr></table></figure><p></p><p>将给定 key 的值设为 value ，并返回 key 的旧值(old value)。</p><p>当 key 存在但不是字符串类型时，返回一个错误。</p><p>返回值：</p><p>返回给定 key 的旧值。<br>当 key 没有旧值时，也即是， key 不存在时，返回 nil 。</p><p>3）get<br>语法：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET key</span><br></pre></td></tr></table></figure><p></p><p>返回值：</p><p>当 key 不存在时，返回 nil ，否则，返回 key 的值。<br>如果 key 不是字符串类型，那么返回一个错误</p><h5 id="解决死锁问题"><a href="#解决死锁问题" class="headerlink" title="解决死锁问题"></a>解决死锁问题</h5><p>如果一个持有锁的客户端失败或崩溃了不能释放锁，该怎么解决？</p><ul><li>设置超时时间来解决</li></ul><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><ol><li><a href="http://www.cnblogs.com/seesun2012/p/9214653.html" target="_blank" rel="noopener">Java分布式锁看这篇就够了</a></li></ol><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;分布式锁一般有三种实现方式：1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁。4.
      
    
    </summary>
    
      <category term="分布式" scheme="http://www.fufan.me/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="http://www.fufan.me/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="锁" scheme="http://www.fufan.me/tags/%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>Kafka学习笔记（三）——kafka设计的要点</title>
    <link href="http://www.fufan.me/2018/04/02/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94kafka%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%A6%81%E7%82%B9/"/>
    <id>http://www.fufan.me/2018/04/02/Kafka学习笔记（三）——kafka设计的要点/</id>
    <published>2018-04-02T10:36:00.000Z</published>
    <updated>2018-11-08T10:37:39.328Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><h2 id="kafka的特点"><a href="#kafka的特点" class="headerlink" title="kafka的特点"></a>kafka的特点</h2><h3 id="1、吞吐量"><a href="#1、吞吐量" class="headerlink" title="1、吞吐量"></a>1、吞吐量</h3><p>高吞吐是kafka需要实现的核心目标之一，为此kafka做了以下一些设计：</p><ol><li>数据磁盘持久化：消息不在内存中cache，直接写入到磁盘，充分利用磁盘的顺序读写性能</li><li>zero-copy：减少IO操作步骤</li><li>数据批量发送</li><li>数据压缩</li><li>Topic划分为多个partition，提高parallelism</li></ol><h3 id="2、负载均衡"><a href="#2、负载均衡" class="headerlink" title="2、负载均衡"></a>2、负载均衡</h3><ol><li>producer根据用户指定的算法，将消息发送到指定的partition</li><li>存在多个partiiton，每个partition有自己的replica，每个replica分布在不同的Broker节点上</li><li>多个partition需要选取出lead partition，lead partition负责读写，并由zookeeper负责fail over</li><li>通过zookeeper管理broker与consumer的动态加入与离开</li></ol><h3 id="3、拉取系统"><a href="#3、拉取系统" class="headerlink" title="3、拉取系统"></a>3、拉取系统</h3><p>由于kafka broker会持久化数据，broker没有内存压力，因此，consumer非常适合采取pull的方式消费数据，具有以下几点好处：</p><ol><li>简化kafka设计</li><li>consumer根据消费能力自主控制消息拉取速度</li><li>consumer根据自身情况自主选择消费模式，例如批量，重复消费，从尾端开始消费等</li></ol><h3 id="4、可扩展性"><a href="#4、可扩展性" class="headerlink" title="4、可扩展性"></a>4、可扩展性</h3><p>当需要增加broker结点时，新增的broker会向zookeeper注册，而producer及consumer会根据注册在zookeeper上的watcher感知这些变化，并及时作出调整。</p><h2 id="kafka的使用场景"><a href="#kafka的使用场景" class="headerlink" title="kafka的使用场景"></a>kafka的使用场景</h2><h3 id="1、消息队列"><a href="#1、消息队列" class="headerlink" title="1、消息队列"></a>1、消息队列</h3><p>比起大多数的消息系统来说，Kafka有更好的吞吐量，内置的分区，冗余及容错性，这让Kafka成为了一个很好的大规模消息处理应用的解决方案。消息系统一般吞吐量相对较低，但是需要更小的端到端延时，并尝尝依赖于Kafka提供的强大的持久性保障。在这个领域，Kafka足以媲美传统消息系统，如ActiveMR或RabbitMQ。</p><h3 id="2、行为跟踪"><a href="#2、行为跟踪" class="headerlink" title="2、行为跟踪"></a>2、行为跟踪</h3><p>Kafka的另一个应用场景是跟踪用户浏览页面、搜索及其他行为，以发布-订阅的模式实时记录到对应的topic里。那么这些结果被订阅者拿到后，就可以做进一步的实时处理，或实时监控，或放到hadoop/离线数据仓库里处理。</p><h3 id="3、元信息监控"><a href="#3、元信息监控" class="headerlink" title="3、元信息监控"></a>3、元信息监控</h3><p>作为操作记录的监控模块来使用，即汇集记录一些操作信息，可以理解为运维性质的数据监控吧。</p><h3 id="4、日志收集"><a href="#4、日志收集" class="headerlink" title="4、日志收集"></a>4、日志收集</h3><p>日志收集方面，其实开源产品有很多，包括Scribe、Apache Flume。很多人使用Kafka代替日志聚合（log aggregation）。日志聚合一般来说是从服务器上收集日志文件，然后放到一个集中的位置（文件服务器或HDFS）进行处理。然而Kafka忽略掉文件的细节，将其更清晰地抽象成一个个日志或事件的消息流。这就让Kafka处理过程延迟更低，更容易支持多数据源和分布式数据处理。比起以日志为中心的系统比如Scribe或者Flume来说，Kafka提供同样高效的性能和因为复制导致的更高的耐用性保证，以及更低的端到端延迟。</p><h2 id="kafka性能"><a href="#kafka性能" class="headerlink" title="kafka性能"></a>kafka性能</h2><p><img src="/image/kafka-2-0.png" alt=""></p><p>为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件.每个分区都是有序的，不可变的记录序列，不断追加到结构化的提交日志中。分区中的记录每个分配一个连续的id号，称为offset(偏移量)，用于唯一标识分区内的每条记录。</p><p>实际上，保留在每个消费者基础上的唯一元数据是该消费者在日志中的抵消或位置。这个偏移量是由消费者控制的：消费者通常会在读取记录时线性地推进其偏移量，但实际上，由于位置由消费者控制，因此它可以按任何喜欢的顺序消费记录。例如，消费者可以重置为较旧的offset(偏移量)以重新处理来自过去的数据，或者跳至最近的记录并从“now”开始消费。随你喜欢爱怎么读怎么读,而且这些操作对集群或其他消费者没有太大影响。</p><p>这样的操作也就说kafka不用考虑加锁的问题,不存在消费完就要删除信息的问题,有效的保证了高吞吐率,这样没有锁竞争，充分发挥了横向的扩展性，吞吐量极高。这也就形成了分布式消费的概念。</p><p><img src="/image/kafka-2-1.png" alt=""></p><p>这里要注意，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关,</p><p>当然kafka也提供了删除旧数据的策略:</p><ol><li><p>时间,可以自己设置一个储存的最大时间.</p></li><li><p>partition大小,可以给分区设置最大储存值.</p><p><img src="/image/kafka-2-2.png" alt=""></p><h3 id="consumer"><a href="#consumer" class="headerlink" title="consumer"></a>consumer</h3><p>p0=&gt;p3三个partition,而partition中的每个message只能被组（Consumer group）中的一个consumer（consumer 线程)消费.也就说一个partition只能被一个消费者消费（一个消费者可以同时消费多个partition）</p></li></ol><p>如果consumer从多个partition读到数据，不保证数据间的顺序性，kafka只保证在一个partition上数据是有序的，但多个partition，根据你读的顺序会有不同</p><h3 id="producer"><a href="#producer" class="headerlink" title="producer"></a>producer</h3><h4 id="Kakfa-Broker-Leader选举"><a href="#Kakfa-Broker-Leader选举" class="headerlink" title="Kakfa Broker Leader选举"></a>Kakfa Broker Leader选举</h4><p>kafka集群是受zookeeper来管理的,这里需要将所有的kafka broker节点一起注册到zookeeper上,而这个过程中只有一个kafka broker能注册成功,在zookeeper上注册一个临时节点,这个kafka broker叫kafka broker Controller,其他的叫kafka broker follower,一旦这个kafka broker Controller发生宕机,临时节点会消失,其他的kafka broker follower会在竞争去zookeeper上注册,产生一个新Leader.(注:Kafka集群中broker之间的关系,不是主从关系，各个broker在集群中地位一样，我们可以随意的增加或删除任何一个broker节点。),还有一种情况是有Controller下的一个follower宕机了,这时Controller会去读取这个follower在zookeeper上所有的partition leader信息(host:port),并且找到这些partition的备份们,让他们选一个成为这个partition的leader.如果该partition的所有的备份都宕机了，则将新的leader设置为-1，等待恢复，等待任一个备份“活”过来，并且选它作为Leader.</p><h4 id="在Producer向kafka-broker推送message"><a href="#在Producer向kafka-broker推送message" class="headerlink" title="在Producer向kafka broker推送message"></a>在Producer向kafka broker推送message</h4><p>kafka在所有broker中产生一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比Zookeeper Queue的方式更高效）通知需为此作出响应的Broker。</p><p>每个partition(分区)都有一台服务器充当“leader”，零个或多个服务器充当“follower”。leader处理分区的所有读取和写入请求，而follower被动地复制leader。如果leader失败，其中一个follower将自动成为新leader。每个服务器都充当其中一些分区的leader和其他人的follower，因此负载在集群内平衡良好。</p><h4 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h4><p>消息生产者,就是向 kafka broker发消息的客户端。 Producer 采用异步 push 方式, 极大提高 Kafka 系统的吞吐率(可以通过参数控制是采用同步还是异步方式)。 producer 端 , 可以将消息 buffer 起来 , 当消息的条数达到一定阀值时 , 批量发送给 broker 。</p><p>小数据 IO 太多,会拖慢整体的网络延迟,批量延迟发送事实上提升了网络效率。不过 这也有一定的隐患,比如说当 producer 失效时,那些尚未发送的消息将会丢失。</p><p>producer将会和Topic下所有partition leader保持 socket 连接 ; 消息由 producer 直接 通过 socket 发送到 broker, 中间不会经过任何 ” 路由层 “. 事实上 , 消息被路由到哪个 partition 上 , 由 producer 客户端决定。 partition leader的位置 (host:port)注册在 zookeeper 中 ,producer 作为 zookeeper client,已经注册了 watch 用来监听 partition leader的变更事件。</p><p><img src="/image/kafka-2-3.png" alt=""></p><p>如上图kafka集群有四个broker,一个topic有四个partition,并且每一个partition都有一个follower(其实就是备份);一个消息流输入之后会先储存一个topic在不同的partition leader中(并行写入),然后在由partition leader同步到各自的备份中.</p><p><img src="/image/kafka-2-5.png" alt=""></p><p>我们加两个broker5,6,这个时候partition的变化</p><h3 id="partition-分区-机制的优势"><a href="#partition-分区-机制的优势" class="headerlink" title="partition(分区)机制的优势:"></a>partition(分区)机制的优势:</h3><p>当Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。也就是我们上面说的机制，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。<strong>所以说kafka可以水平扩展，也就是扩展partition。</strong>segment</p><p>一个partition可以实现跨服务器,可以一个分区占有一个服务器.</p><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p><a href="https://blog.csdn.net/mr_hou2016/article/details/79653242" target="_blank" rel="noopener">日志收集为什么用kafka</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;h2 id=&quot;kafka的特点&quot;&gt;&lt;a href=&quot;#kafka的特点&quot; class=&quot;headerlink&quot; title=&quot;k
      
    
    </summary>
    
      <category term="kafka" scheme="http://www.fufan.me/categories/kafka/"/>
    
    
      <category term="kafka" scheme="http://www.fufan.me/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka学习笔记（二）——Kafka shell命令</title>
    <link href="http://www.fufan.me/2018/03/26/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94Kafka-shell%E5%91%BD%E4%BB%A4/"/>
    <id>http://www.fufan.me/2018/03/26/Kafka学习笔记（二）——Kafka-shell命令/</id>
    <published>2018-03-26T10:17:00.000Z</published>
    <updated>2018-11-08T10:18:12.049Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>排查问题的时候可能会用到终端的一些命令，下面列举一下常用的一些命令</p><h3 id="启动zookeeper"><a href="#启动zookeeper" class="headerlink" title="启动zookeeper"></a>启动zookeeper</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties &amp;</span><br></pre></td></tr></table></figure><h3 id="启动kafka"><a href="#启动kafka" class="headerlink" title="启动kafka"></a>启动kafka</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure><h3 id="停止kafka"><a href="#停止kafka" class="headerlink" title="停止kafka"></a>停止kafka</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure><h3 id="停止zookeeper"><a href="#停止zookeeper" class="headerlink" title="停止zookeeper"></a>停止zookeeper</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-server-stop.sh</span><br></pre></td></tr></table></figure><h3 id="创建topic"><a href="#创建topic" class="headerlink" title="创建topic"></a>创建topic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</span><br></pre></td></tr></table></figure><h3 id="展示topic"><a href="#展示topic" class="headerlink" title="展示topic"></a>展示topic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure><h3 id="描述topic"><a href="#描述topic" class="headerlink" title="描述topic"></a>描述topic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic</span><br></pre></td></tr></table></figure><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list 130.51.23.95:9092 --topic my-replicated-topic</span><br></pre></td></tr></table></figure><h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --zookeeper 130.51.23.95:2181 --topic test --from-beginning</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;排查问题的时候可能会用到终端的一些命令，下面列举一下常用的一些命令&lt;/p&gt;&lt;h3 id=&quot;启动zookeeper&quot;&gt;&lt;a h
      
    
    </summary>
    
    
      <category term="kafka" scheme="http://www.fufan.me/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka学习笔记（一）——Kafka入门</title>
    <link href="http://www.fufan.me/2018/03/18/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94Kafka%E5%85%A5%E9%97%A8/"/>
    <id>http://www.fufan.me/2018/03/18/Kafka学习笔记（一）——Kafka入门/</id>
    <published>2018-03-18T10:32:00.000Z</published>
    <updated>2018-11-08T10:17:19.016Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>Apache Kafka：一个分布式流处理平台</p><ul><li><p>| 对比指标 | kafka | activemq | rabbitmq | rocketmq |<br>| — | — | — | — | — |<br>| 背景 | Kafka 是LinkedIn 开发的一个高性能、分布式的消息系统，广泛用于日志收集、流式数据处理、在线和离线消息分发等场景 | ActiveMQ是一种开源的，实现了JMS1.1规范的，面向消息(MOM)的中间件， 为应用程序提供高效的、可扩展的、稳定的和安全的企业级消息通信。 | RabbitMQ是一个由erlang开发的AMQP协议（Advanced Message Queue ）的开源实现。 | RocketMQ是阿里巴巴在2012年开源的分布式消息中间件，目前已经捐赠给Apache基金会，已经于2016年11月成为 Apache 孵化项目 |<br>|开发语言 | Java、Scala | Java | Erlang | Java |<br>|协议支持 | 自己实现的一套 | JMS协议 | AMQP | JMS、MQTT |<br>|持久化 | 支持 | 支持 | 支持 | 支持 |<br>| producer容错 | 在kafka中提供了acks配置选项, acks=0 生产者在成功写入悄息之前不会等待任何来自服务器的响应 acks=1 只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应 acks=all 只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应,这种模式最安全 | 发送失败后即可重试 | 有ack模型。 ack模型可能重复消息 ，事务模型保证完全一致 | 和kafka类似 |<br>| 吞吐量 | kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高 | | rabbitMQ在吞吐量方面稍逊于kafka，他们的出发点不一样，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作；基于存储的可靠性的要求存储可以采用内存或者硬盘。 | kafka在topic数量不多的情况下吞吐量比rocketMq高，在topic数量多的情况下rocketMq比kafka高 |<br>| 负载均衡 | kafka采用zookeeper对集群中的broker、consumer进行管理，可以注册topic到zookeeper上；通过zookeeper的协调机制，producer保存对应topic的broker信息，可以随机或者轮询发送到broker上；并且producer可以基于语义指定分片，消息发送到broker的某分片上 | | rabbitMQ的负载均衡需要单独的loadbalancer进行支持 | NamerServer进行负载均衡<br>|</p></li></ul><p><img src="/image/kafka-0-0.jpg" alt=""></p><h3 id="相关名词"><a href="#相关名词" class="headerlink" title="相关名词"></a>相关名词</h3><ul><li>Producer :消息生产者，向Broker发送消息的客户端</li><li>Consumer :消息消费者，从Broker读取消息的客户端,消费者&lt;=消息的分区数量</li><li>broker :消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群</li><li>topic : 主题，Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic</li><li>Partition : 分区，物理上的概念，一个topic可以分为多个partition，每个partition内部是有序的，kafka默认根据key%partithon确定消息发送到具体的partition</li><li>ConsumerGroup : 每个Consumer属于一个特定的Consumer Group，一条消息可以发送到多个不同的Consumer Group，但是一个Consumer Group中只能有一个Consumer能够消费该消息</li></ul><h4 id="Topic-和-Partition"><a href="#Topic-和-Partition" class="headerlink" title="Topic 和 Partition"></a>Topic 和 Partition</h4><p>一个Topic中的消息会按照指定的规则(默认是key的hash值%分区的数量，当然你也可以自定义)，发送到某一个分区上面；<br>每一个分区都是一个顺序的、不可变的消息队列，并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的<br>消费者所持有的元数据就是这个偏移量，也就是消费者在这个log（分区）中的位置。这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加</p><p><img src="/image/kafka-0-1.jpg" alt=""></p><h4 id="Consumer-和-Partition"><a href="#Consumer-和-Partition" class="headerlink" title="Consumer 和 Partition"></a>Consumer 和 Partition</h4><p>通常来讲，消息模型可以分为两种， 队列和发布-订阅式。队列的处理方式 是一个消费者组从队列的一端拉取数据，这个数据消费完就没了。在发布-订阅模型中，消息被广播给所有的消费者，接受到消息的消费者都能处理此消息。在Kafka模型中抽象出来了：消费者组（consumer group）<br>消费者组（consumer group）：每个组中有若干个消费者，如果所有的消费者都在一个组中，那么这个就变成了队列模型；如果笑消费者在不同的组中，这就成了发布-订阅模型<br>一个分区里面的数据只会由一个分组中的消费者处理，同分组的其他消费者不会重复处理<br>消费者组中的消费者数量&lt;=分区数量，如果大于分区数量，多出来的消费者会处于收不到消息的状态，造成不必要的浪费。</p><p><img src="/image/kafka-0-2.jpg" alt=""></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;Apache Kafka：一个分布式流处理平台&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;| 对比指标 | kafka | activem
      
    
    </summary>
    
      <category term="kafka" scheme="http://www.fufan.me/categories/kafka/"/>
    
    
      <category term="kafka" scheme="http://www.fufan.me/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Consul学习笔记（一）——安装和命令使用</title>
    <link href="http://www.fufan.me/2018/02/28/Consul%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%AE%89%E8%A3%85%E5%92%8C%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"/>
    <id>http://www.fufan.me/2018/02/28/Consul学习笔记（一）——安装和命令使用/</id>
    <published>2018-02-28T10:14:00.000Z</published>
    <updated>2018-11-08T10:14:33.306Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>由于公司目前工作当中微服务用到了consul集群来作为分布式系统中间件，用到了他内置了服务注册与发现框 架、分布一致性协议实现、健康检查、Key/Value存储、多数据中心方案。不再需要依赖其他工具（比如ZooKeeper等）。使用起来也较 为简单。</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Consul 是 HashiCorp 公司推出的开源工具，用于实现分布式系统的服务发现与配置。与其他分布式服务注册与发现的方案，Consul的方案更“一站式”，内置了服务注册与发现框 架、分布一致性协议实现、健康检查、Key/Value存储、多数据中心方案，不再需要依赖其他工具（比如ZooKeeper等）。使用起来也较 为简单。Consul使用Go语言编写，因此具有天然可移植性(支持Linux、windows和Mac OS X)；安装包仅包含一个可执行文件，方便部署，与Docker等轻量级容器可无缝配合 。</p><ul><li>Service Discovery (服务发现)</li><li>Health Check (健康检查)</li><li>Multi Datacenter (多数据中心)</li><li>Key/Value Storage</li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>mac：64bit（查看mac位数：打开终端–&gt;”uname -a”）<br>consul_0.6.4_darwin_amd64.zip和consul_0.6.4_web_ui.zip，从consul官网<a href="https://www.consul.io/downloads.html进行下载就好（选择好OS和位数）" target="_blank" rel="noopener">https://www.consul.io/downloads.html进行下载就好（选择好OS和位数）</a></p><p>1、解压consul_0.6.4_darwin_amd64.zip<br>2、将解压后的二进制文件consul（上边画红框的部分拷贝到/usr/local/bin下）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp consul /usr/local/bin/</span><br></pre></td></tr></table></figure><p>说明：使用sudo是因为权限问题。</p><p>3、查看是否安装成功</p><p>调用其命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> fufan@fufans-MacBook-Pro-2  ~  consul help</span><br><span class="line">Usage: consul [--version] [--help] &lt;command&gt; [&lt;args&gt;]</span><br><span class="line"></span><br><span class="line">Available commands are:</span><br><span class="line">    agent          Runs a Consul agent</span><br><span class="line">    catalog        Interact with the catalog</span><br><span class="line">    connect        Interact with Consul Connect</span><br><span class="line">    event          Fire a new event</span><br><span class="line">    exec           Executes a command on Consul nodes</span><br><span class="line">    force-leave    Forces a member of the cluster to enter the &quot;left&quot; state</span><br><span class="line">    info           Provides debugging information for operators.</span><br><span class="line">    intention      Interact with Connect service intentions</span><br><span class="line">    join           Tell Consul agent to join cluster</span><br><span class="line">    keygen         Generates a new encryption key</span><br><span class="line">    keyring        Manages gossip layer encryption keys</span><br><span class="line">    kv             Interact with the key-value store</span><br><span class="line">    leave          Gracefully leaves the Consul cluster and shuts down</span><br><span class="line">    lock           Execute a command holding a lock</span><br><span class="line">    maint          Controls node or service maintenance mode</span><br><span class="line">    members        Lists the members of a Consul cluster</span><br><span class="line">    monitor        Stream logs from a Consul agent</span><br><span class="line">    operator       Provides cluster-level tools for Consul operators</span><br><span class="line">    reload         Triggers the agent to reload configuration files</span><br><span class="line">    rtt            Estimates network round trip time between nodes</span><br><span class="line">    snapshot       Saves, restores and inspects snapshots of Consul server state</span><br><span class="line">    validate       Validate config files/directories</span><br><span class="line">    version        Prints the Consul version</span><br><span class="line">    watch          Watch for changes in Consul</span><br></pre></td></tr></table></figure><h3 id="consul相关知识点"><a href="#consul相关知识点" class="headerlink" title="consul相关知识点"></a>consul相关知识点</h3><ol><li>Agent</li></ol><ul><li>Agent 是一个守护进程</li><li>运行在Consul集群的每个成员上</li><li>有Client 和 Server 两种模式</li><li>所有Agent都可以被调用DNS或者HTTP API,并负责检查和维护同步</li></ul><ol start="2"><li>Client</li></ol><ul><li>Client 将所有RPC请求转发至Server</li><li>Client 是相对无状态的</li><li>Client 唯一做的就是参与LAN Gossip Pool</li><li>Client 只消耗少量的资源和少量的网络带宽</li></ul><ol start="3"><li>Server</li></ol><ul><li>参与 Raft quorum(一致性判断)</li><li>响应RPC查询请求</li><li>维护集群的状态</li><li>转发查询到Leader 或 远程数据中心</li></ul><ol start="4"><li>Datacenter数据中心</li></ol><ul><li>私有的</li><li>低延迟</li><li>高带宽</li></ul><ol start="5"><li>Consensus (一致性)</li></ol><p>Consul 使用consensus protocol 来提供CAP(一致性,高可用,分区容错性)</p><ol start="5"><li>Gossip</li></ol><p>一种协议: 用来保证 最终一致性 , 即: 无法保证在某个时刻, 所有节点状态一致, 但可以保证”最终”一致</p><h3 id="注册服务"><a href="#注册服务" class="headerlink" title="注册服务"></a>注册服务</h3><ul><li>服务可以通过提供服务定义或通过对HTTP API进行适当的调用来注册。</li><li>服务定义是注册服务最常用的方式，所以我们将在这一步中使用这种方法。 我们将建立在上一步中介绍的代理配置。</li><li>首先，为Consul配置创建一个目录。 Consul将所有配置文件加载到配置目录中，因此Unix系统上的一个通用约定是将目录命名为/etc/consul.d（.d后缀意味着“该目录包含一组配置文件”）。</li></ul><p>建立服务配置目录:mkdir /etc/consul.d<br>添加文件:echo ‘{“service”: {“name”: “web”, “tags”: [“rails”], “port”: 80}}’ | sudo tee /etc/consul.d/web.json</p><ul><li>以开发模式启动:consul agent -dev -config-dir=/etc/consul.d</li><li>以服务方式启动:consul agent -server -bootstrap-expect 2 -data-dir ./tmp/consul -node=n1 -bind=192.168.109.241 -ui-dir ./dist -dc=dc1</li><li>以客户端方式启动:consul agent -data-dir ./tmp/consul -ui-dir ./dist -bind=192.168.109.204 -dc=dc1</li></ul><h3 id="加入集群"><a href="#加入集群" class="headerlink" title="加入集群"></a>加入集群</h3><p>将新节点添加到集群:consul join 192.168.100.101(其中101这个节点是master)</p><p>显示成员:consul members</p><h3 id="查看UI管理页面"><a href="#查看UI管理页面" class="headerlink" title="查看UI管理页面"></a>查看UI管理页面</h3><p><a href="http://192.168.0.70:8500/ui" target="_blank" rel="noopener">http://192.168.0.70:8500/ui</a></p><p><img src="/image/consul-0-1.png" alt=""></p><h3 id="常用命令参数"><a href="#常用命令参数" class="headerlink" title="常用命令参数"></a>常用命令参数</h3><p>consul agent 命令的常用选项，如下：</p><ul><li>-data-dir<ul><li>作用：指定agent储存状态的数据目录</li><li>这是所有agent都必须的</li><li>对于server尤其重要，因为他们必须持久化集群的状态</li></ul></li><li>-config-dir<ul><li>作用：指定service的配置文件和检查定义所在的位置</li><li>通常会指定为”某一个路径/consul.d”（通常情况下，.d表示一系列配置文件存放的目录）</li></ul></li><li>-config-file<ul><li>作用：指定一个要装载的配置文件</li><li>该选项可以配置多次，进而配置多个配置文件（后边的会合并前边的，相同的值覆盖）</li></ul></li><li>-dev<ul><li>作用：创建一个开发环境下的server节点</li><li>该参数配置下，不会有任何持久化操作，即不会有任何数据写入到磁盘</li><li>这种模式不能用于生产环境（因为第二条）</li></ul></li><li>-bootstrap-expect<ul><li>作用：该命令通知consul server我们现在准备加入的server节点个数，该参数是为了延迟日志复制的启动直到我们指定数量的server节点成功的加入后启动。</li></ul></li><li>-node<ul><li>作用：指定节点在集群中的名称</li><li>该名称在集群中必须是唯一的（默认采用机器的host）</li><li>推荐：直接采用机器的IP</li></ul></li><li>-bind<ul><li>作用：指明节点的IP地址</li><li>有时候不指定绑定IP，会报Failed to get advertise address: Multiple private IPs found. Please configure one. 的异常</li></ul></li><li>-server<ul><li>作用：指定节点为server</li><li>每个数据中心（DC）的server数推荐至少为1，至多为5</li><li>所有的server都采用raft一致性算法来确保事务的一致性和线性化，事务修改了集群的状态，且集群的状态保存在每一台server上保证可用性</li><li>server也是与其他DC交互的门面（gateway）</li></ul></li><li>-client<ul><li>作用：指定节点为client，指定客户端接口的绑定地址，包括：HTTP、DNS、RPC</li><li>默认是127.0.0.1，只允许回环接口访问</li><li>若不指定为-server，其实就是-client</li></ul></li><li>-join<ul><li>作用：将节点加入到集群</li></ul></li><li>-datacenter（老版本叫-dc，-dc已经失效）<ul><li>作用：指定机器加入到哪一个数据中心中</li></ul></li></ul><h3 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h3><p><img src="/image/consul-0-1.png" alt=""></p><p>此部分过程同redis集群、zookeeper集群类似</p><h3 id="问题踩坑"><a href="#问题踩坑" class="headerlink" title="问题踩坑"></a>问题踩坑</h3><ul><li>google</li><li>github issues</li></ul><h3 id="参考博文："><a href="#参考博文：" class="headerlink" title="参考博文："></a>参考博文：</h3><ul><li>Consul官方文档：<a href="https://www.consul.io/intro/getting-started/install.html" target="_blank" rel="noopener">https://www.consul.io/intro/getting-started/install.html</a></li><li>Consul 系列博文：<a href="http://www.cnblogs.com/java-zhao/archive/2016/04/13/5387105.html" target="_blank" rel="noopener">http://www.cnblogs.com/java-zhao/archive/2016/04/13/5387105.html</a></li><li>使用consul实现分布式服务注册和发现：<a href="http://www.tuicool.com/articles/M3QFven" target="_blank" rel="noopener">http://www.tuicool.com/articles/M3QFven</a></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;由于公司目前工作当中微服务用到了consul集群来作为分布式系统中间件，用到了他内置了服务注册与发现框 架、分布一致性协议实
      
    
    </summary>
    
      <category term="consul" scheme="http://www.fufan.me/categories/consul/"/>
    
    
      <category term="consul" scheme="http://www.fufan.me/tags/consul/"/>
    
  </entry>
  
  <entry>
    <title>Redis学习笔记（二）——redis安装</title>
    <link href="http://www.fufan.me/2018/02/15/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94redis%E5%AE%89%E8%A3%85/"/>
    <id>http://www.fufan.me/2018/02/15/Redis学习笔记（二）——redis安装/</id>
    <published>2018-02-15T03:05:00.000Z</published>
    <updated>2018-11-08T10:13:22.293Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>由于公司开发笔记本用的是mac，所以我这里介绍一下在mac和linux环境下的redis安装</p><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p>1、下载源码，解压缩后编译源码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> $ wget http://download.redis.io/releases/redis-2.8.3.tar.gz</span><br><span class="line">$ tar xzf redis-2.8.3.tar.gz</span><br><span class="line">$ cd redis-2.8.3</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure><p>2、编译完成后，在Src目录下，有四个可执行文件redis-server、redis-benchmark、redis-cli和redis.conf。然后拷贝到一个目录下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/redis</span><br><span class="line">cp redis-server  /usr/redis</span><br><span class="line">cp redis-benchmark /usr/redis</span><br><span class="line">cp redis-cli  /usr/redis</span><br><span class="line">cp redis.conf  /usr/redis</span><br><span class="line">cd /usr/redis</span><br></pre></td></tr></table></figure><p>3、启动Redis服务。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ redis-server   redis.conf</span><br></pre></td></tr></table></figure><p></p><p>4、然后用客户端测试一下是否启动成功。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli</span><br><span class="line">redis&gt; set foo bar</span><br><span class="line">OK</span><br><span class="line">redis&gt; get foo</span><br><span class="line">&quot;bar&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h2><h3 id="brew-安装"><a href="#brew-安装" class="headerlink" title="brew 安装"></a>brew 安装</h3><p>1、使用brew命令安装redis<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install redis</span><br></pre></td></tr></table></figure><p></p><p>2、启动redis</p><p>后台方式启动，brew services start redis。这样启动的好处是把控制台关掉后，redis仍然是启动的。当然，如果没有这样的需求，也可以这样启动<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server /usr/local/etc/redis.conf</span><br></pre></td></tr></table></figure><p></p><p>3、关闭redis<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew services stop redis</span><br></pre></td></tr></table></figure><p></p><p>4、使用控制台连接redis</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli</span><br><span class="line"></span><br><span class="line">redis-cli -h 127.0.0.1 -p</span><br></pre></td></tr></table></figure><h2 id="redis-conf配置说明"><a href="#redis-conf配置说明" class="headerlink" title="redis.conf配置说明"></a>redis.conf配置说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br></pre></td><td class="code"><pre><span class="line"># Redis配置文件样例</span><br><span class="line"></span><br><span class="line"># Note on units: when memory size is needed, it is possible to specifiy</span><br><span class="line"># it in the usual form of 1k 5GB 4M and so forth:</span><br><span class="line">#</span><br><span class="line"># 1k =&gt; 1000 bytes</span><br><span class="line"># 1kb =&gt; 1024 bytes</span><br><span class="line"># 1m =&gt; 1000000 bytes</span><br><span class="line"># 1mb =&gt; 1024*1024 bytes</span><br><span class="line"># 1g =&gt; 1000000000 bytes</span><br><span class="line"># 1gb =&gt; 1024*1024*1024 bytes</span><br><span class="line">#</span><br><span class="line"># units are case insensitive so 1GB 1Gb 1gB are all the same.</span><br><span class="line"></span><br><span class="line"># Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程</span><br><span class="line"># 启用守护进程后，Redis会把pid写到一个pidfile中，在/var/run/redis.pid</span><br><span class="line">daemonize no</span><br><span class="line"></span><br><span class="line"># 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定</span><br><span class="line">pidfile /var/run/redis.pid</span><br><span class="line"></span><br><span class="line"># 指定Redis监听端口，默认端口为6379</span><br><span class="line"># 如果指定0端口，表示Redis不监听TCP连接</span><br><span class="line">port 6379</span><br><span class="line"></span><br><span class="line"># 绑定的主机地址</span><br><span class="line"># 你可以绑定单一接口，如果没有绑定，所有接口都会监听到来的连接</span><br><span class="line"># bind 127.0.0.1</span><br><span class="line"></span><br><span class="line"># Specify the path for the unix socket that will be used to listen for</span><br><span class="line"># incoming connections. There is no default, so Redis will not listen</span><br><span class="line"># on a unix socket when not specified.</span><br><span class="line">#</span><br><span class="line"># unixsocket /tmp/redis.sock</span><br><span class="line"># unixsocketperm 755</span><br><span class="line"></span><br><span class="line"># 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能</span><br><span class="line">timeout 0</span><br><span class="line"></span><br><span class="line"># 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose</span><br><span class="line"># debug (很多信息, 对开发／测试比较有用)</span><br><span class="line"># verbose (many rarely useful info, but not a mess like the debug level)</span><br><span class="line"># notice (moderately verbose, what you want in production probably)</span><br><span class="line"># warning (only very important / critical messages are logged)</span><br><span class="line">loglevel verbose</span><br><span class="line"></span><br><span class="line"># 日志记录方式，默认为标准输出，如果配置为redis为守护进程方式运行，而这里又配置为标准输出，则日志将会发送给/dev/null</span><br><span class="line">logfile stdout</span><br><span class="line"></span><br><span class="line"># To enable logging to the system logger, just set &apos;syslog-enabled&apos; to yes,</span><br><span class="line"># and optionally update the other syslog parameters to suit your needs.</span><br><span class="line"># syslog-enabled no</span><br><span class="line"></span><br><span class="line"># Specify the syslog identity.</span><br><span class="line"># syslog-ident redis</span><br><span class="line"></span><br><span class="line"># Specify the syslog facility.  Must be USER or between LOCAL0-LOCAL7.</span><br><span class="line"># syslog-facility local0</span><br><span class="line"></span><br><span class="line"># 设置数据库的数量，默认数据库为0，可以使用select &lt;dbid&gt;命令在连接上指定数据库id</span><br><span class="line"># dbid是从0到‘databases’-1的数目</span><br><span class="line">databases 16</span><br><span class="line"></span><br><span class="line">################################ SNAPSHOTTING  #################################</span><br><span class="line"># 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合</span><br><span class="line"># Save the DB on disk:</span><br><span class="line">#</span><br><span class="line">#   save &lt;seconds&gt; &lt;changes&gt;</span><br><span class="line">#</span><br><span class="line">#   Will save the DB if both the given number of seconds and the given</span><br><span class="line">#   number of write operations against the DB occurred.</span><br><span class="line">#</span><br><span class="line">#   满足以下条件将会同步数据:</span><br><span class="line">#   900秒（15分钟）内有1个更改</span><br><span class="line">#   300秒（5分钟）内有10个更改</span><br><span class="line">#   60秒内有10000个更改</span><br><span class="line">#   Note: 可以把所有“save”行注释掉，这样就取消同步操作了</span><br><span class="line"></span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line"></span><br><span class="line"># 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大</span><br><span class="line">rdbcompression yes</span><br><span class="line"></span><br><span class="line"># 指定本地数据库文件名，默认值为dump.rdb</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line"></span><br><span class="line"># 工作目录.</span><br><span class="line"># 指定本地数据库存放目录，文件名由上一个dbfilename配置项指定</span><br><span class="line"># </span><br><span class="line"># Also the Append Only File will be created inside this directory.</span><br><span class="line"># </span><br><span class="line"># 注意，这里只能指定一个目录，不能指定文件名</span><br><span class="line">dir ./</span><br><span class="line"></span><br><span class="line">################################# REPLICATION #################################</span><br><span class="line"></span><br><span class="line"># 主从复制。使用slaveof从 Redis服务器复制一个Redis实例。注意，该配置仅限于当前slave有效</span><br><span class="line"># so for example it is possible to configure the slave to save the DB with a</span><br><span class="line"># different interval, or to listen to another port, and so on.</span><br><span class="line"># 设置当本机为slav服务时，设置master服务的ip地址及端口，在Redis启动时，它会自动从master进行数据同步</span><br><span class="line"># slaveof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 当master服务设置了密码保护时，slav服务连接master的密码</span><br><span class="line"># 下文的“requirepass”配置项可以指定密码</span><br><span class="line"># masterauth &lt;master-password&gt;</span><br><span class="line"></span><br><span class="line"># When a slave lost the connection with the master, or when the replication</span><br><span class="line"># is still in progress, the slave can act in two different ways:</span><br><span class="line">#</span><br><span class="line"># 1) if slave-serve-stale-data is set to &apos;yes&apos; (the default) the slave will</span><br><span class="line">#    still reply to client requests, possibly with out of data data, or the</span><br><span class="line">#    data set may just be empty if this is the first synchronization.</span><br><span class="line">#</span><br><span class="line"># 2) if slave-serve-stale data is set to &apos;no&apos; the slave will reply with</span><br><span class="line">#    an error &quot;SYNC with master in progress&quot; to all the kind of commands</span><br><span class="line">#    but to INFO and SLAVEOF.</span><br><span class="line">#</span><br><span class="line">slave-serve-stale-data yes</span><br><span class="line"></span><br><span class="line"># Slaves send PINGs to server in a predefined interval. It&apos;s possible to change</span><br><span class="line"># this interval with the repl_ping_slave_period option. The default value is 10</span><br><span class="line"># seconds.</span><br><span class="line">#</span><br><span class="line"># repl-ping-slave-period 10</span><br><span class="line"></span><br><span class="line"># The following option sets a timeout for both Bulk transfer I/O timeout and</span><br><span class="line"># master data or ping response timeout. The default value is 60 seconds.</span><br><span class="line">#</span><br><span class="line"># It is important to make sure that this value is greater than the value</span><br><span class="line"># specified for repl-ping-slave-period otherwise a timeout will be detected</span><br><span class="line"># every time there is low traffic between the master and the slave.</span><br><span class="line">#</span><br><span class="line"># repl-timeout 60</span><br><span class="line"></span><br><span class="line">################################## SECURITY ###################################</span><br><span class="line"></span><br><span class="line"># Warning: since Redis is pretty fast an outside user can try up to</span><br><span class="line"># 150k passwords per second against a good box. This means that you should</span><br><span class="line"># use a very strong password otherwise it will be very easy to break.</span><br><span class="line"># 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过auth &lt;password&gt;命令提供密码，默认关闭</span><br><span class="line"># requirepass foobared</span><br><span class="line"></span><br><span class="line"># Command renaming.</span><br><span class="line">#</span><br><span class="line"># It is possilbe to change the name of dangerous commands in a shared</span><br><span class="line"># environment. For instance the CONFIG command may be renamed into something</span><br><span class="line"># of hard to guess so that it will be still available for internal-use</span><br><span class="line"># tools but not available for general clients.</span><br><span class="line">#</span><br><span class="line"># Example:</span><br><span class="line">#</span><br><span class="line"># rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52</span><br><span class="line">#</span><br><span class="line"># It is also possilbe to completely kill a command renaming it into</span><br><span class="line"># an empty string:</span><br><span class="line">#</span><br><span class="line"># rename-command CONFIG &quot;&quot;</span><br><span class="line"></span><br><span class="line">################################### LIMITS ####################################</span><br><span class="line"></span><br><span class="line"># 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，</span><br><span class="line"># 如果设置maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max Number of clients reached错误信息</span><br><span class="line"># maxclients 128</span><br><span class="line"></span><br><span class="line"># Don&apos;t use more memory than the specified amount of bytes.</span><br><span class="line"># When the memory limit is reached Redis will try to remove keys with an</span><br><span class="line"># EXPIRE set. It will try to start freeing keys that are going to expire</span><br><span class="line"># in little time and preserve keys with a longer time to live.</span><br><span class="line"># Redis will also try to remove objects from free lists if possible.</span><br><span class="line">#</span><br><span class="line"># If all this fails, Redis will start to reply with errors to commands</span><br><span class="line"># that will use more memory, like SET, LPUSH, and so on, and will continue</span><br><span class="line"># to reply to most read-only commands like GET.</span><br><span class="line">#</span><br><span class="line"># WARNING: maxmemory can be a good idea mainly if you want to use Redis as a</span><br><span class="line"># &apos;state&apos; server or cache, not as a real DB. When Redis is used as a real</span><br><span class="line"># database the memory usage will grow over the weeks, it will be obvious if</span><br><span class="line"># it is going to use too much memory in the long run, and you&apos;ll have the time</span><br><span class="line"># to upgrade. With maxmemory after the limit is reached you&apos;ll start to get</span><br><span class="line"># errors for write operations, and this may even lead to DB inconsistency.</span><br><span class="line"># 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，</span><br><span class="line"># 当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。</span><br><span class="line"># Redis新的vm机制，会把Key存放内存，Value会存放在swap区</span><br><span class="line"># maxmemory &lt;bytes&gt;</span><br><span class="line"></span><br><span class="line"># MAXMEMORY POLICY: how Redis will select what to remove when maxmemory</span><br><span class="line"># is reached? You can select among five behavior:</span><br><span class="line"># </span><br><span class="line"># volatile-lru -&gt; remove the key with an expire set using an LRU algorithm</span><br><span class="line"># allkeys-lru -&gt; remove any key accordingly to the LRU algorithm</span><br><span class="line"># volatile-random -&gt; remove a random key with an expire set</span><br><span class="line"># allkeys-&gt;random -&gt; remove a random key, any key</span><br><span class="line"># volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)</span><br><span class="line"># noeviction -&gt; don&apos;t expire at all, just return an error on write operations</span><br><span class="line"># </span><br><span class="line"># Note: with all the kind of policies, Redis will return an error on write</span><br><span class="line">#       operations, when there are not suitable keys for eviction.</span><br><span class="line">#</span><br><span class="line">#       At the date of writing this commands are: set setnx setex append</span><br><span class="line">#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd</span><br><span class="line">#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby</span><br><span class="line">#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby</span><br><span class="line">#       getset mset msetnx exec sort</span><br><span class="line">#</span><br><span class="line"># The default is:</span><br><span class="line">#</span><br><span class="line"># maxmemory-policy volatile-lru</span><br><span class="line"></span><br><span class="line"># LRU and minimal TTL algorithms are not precise algorithms but approximated</span><br><span class="line"># algorithms (in order to save memory), so you can select as well the sample</span><br><span class="line"># size to check. For instance for default Redis will check three keys and</span><br><span class="line"># pick the one that was used less recently, you can change the sample size</span><br><span class="line"># using the following configuration directive.</span><br><span class="line">#</span><br><span class="line"># maxmemory-samples 3</span><br><span class="line"></span><br><span class="line">############################## APPEND ONLY MODE ###############################</span><br><span class="line"></span><br><span class="line"># </span><br><span class="line"># Note that you can have both the async dumps and the append only file if you</span><br><span class="line"># like (you have to comment the &quot;save&quot; statements above to disable the dumps).</span><br><span class="line"># Still if append only mode is enabled Redis will load the data from the</span><br><span class="line"># log file at startup ignoring the dump.rdb file.</span><br><span class="line"># 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。</span><br><span class="line"># 因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no</span><br><span class="line"># IMPORTANT: Check the BGREWRITEAOF to check how to rewrite the append</span><br><span class="line"># log file in background when it gets too big.</span><br><span class="line"></span><br><span class="line">appendonly no</span><br><span class="line"></span><br><span class="line"># 指定更新日志文件名，默认为appendonly.aof</span><br><span class="line"># appendfilename appendonly.aof</span><br><span class="line"></span><br><span class="line"># The fsync() call tells the Operating System to actually write data on disk</span><br><span class="line"># instead to wait for more data in the output buffer. Some OS will really flush </span><br><span class="line"># data on disk, some other OS will just try to do it ASAP.</span><br><span class="line"></span><br><span class="line"># 指定更新日志条件，共有3个可选值：</span><br><span class="line"># no:表示等操作系统进行数据缓存同步到磁盘（快）</span><br><span class="line"># always:表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）</span><br><span class="line"># everysec:表示每秒同步一次（折衷，默认值）</span><br><span class="line"></span><br><span class="line">appendfsync everysec</span><br><span class="line"># appendfsync no</span><br><span class="line"></span><br><span class="line"># When the AOF fsync policy is set to always or everysec, and a background</span><br><span class="line"># saving process (a background save or AOF log background rewriting) is</span><br><span class="line"># performing a lot of I/O against the disk, in some Linux configurations</span><br><span class="line"># Redis may block too long on the fsync() call. Note that there is no fix for</span><br><span class="line"># this currently, as even performing fsync in a different thread will block</span><br><span class="line"># our synchronous write(2) call.</span><br><span class="line">#</span><br><span class="line"># In order to mitigate this problem it&apos;s possible to use the following option</span><br><span class="line"># that will prevent fsync() from being called in the main process while a</span><br><span class="line"># BGSAVE or BGREWRITEAOF is in progress.</span><br><span class="line">#</span><br><span class="line"># This means that while another child is saving the durability of Redis is</span><br><span class="line"># the same as &quot;appendfsync none&quot;, that in pratical terms means that it is</span><br><span class="line"># possible to lost up to 30 seconds of log in the worst scenario (with the</span><br><span class="line"># default Linux settings).</span><br><span class="line"># </span><br><span class="line"># If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as</span><br><span class="line"># &quot;no&quot; that is the safest pick from the point of view of durability.</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"># Automatic rewrite of the append only file.</span><br><span class="line"># Redis is able to automatically rewrite the log file implicitly calling</span><br><span class="line"># BGREWRITEAOF when the AOF log size will growth by the specified percentage.</span><br><span class="line"># </span><br><span class="line"># This is how it works: Redis remembers the size of the AOF file after the</span><br><span class="line"># latest rewrite (or if no rewrite happened since the restart, the size of</span><br><span class="line"># the AOF at startup is used).</span><br><span class="line">#</span><br><span class="line"># This base size is compared to the current size. If the current size is</span><br><span class="line"># bigger than the specified percentage, the rewrite is triggered. Also</span><br><span class="line"># you need to specify a minimal size for the AOF file to be rewritten, this</span><br><span class="line"># is useful to avoid rewriting the AOF file even if the percentage increase</span><br><span class="line"># is reached but it is still pretty small.</span><br><span class="line">#</span><br><span class="line"># Specify a precentage of zero in order to disable the automatic AOF</span><br><span class="line"># rewrite feature.</span><br><span class="line"></span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"></span><br><span class="line">################################## SLOW LOG ###################################</span><br><span class="line"></span><br><span class="line"># The Redis Slow Log is a system to log queries that exceeded a specified</span><br><span class="line"># execution time. The execution time does not include the I/O operations</span><br><span class="line"># like talking with the client, sending the reply and so forth,</span><br><span class="line"># but just the time needed to actually execute the command (this is the only</span><br><span class="line"># stage of command execution where the thread is blocked and can not serve</span><br><span class="line"># other requests in the meantime).</span><br><span class="line"># </span><br><span class="line"># You can configure the slow log with two parameters: one tells Redis</span><br><span class="line"># what is the execution time, in microseconds, to exceed in order for the</span><br><span class="line"># command to get logged, and the other parameter is the length of the</span><br><span class="line"># slow log. When a new command is logged the oldest one is removed from the</span><br><span class="line"># queue of logged commands.</span><br><span class="line"></span><br><span class="line"># The following time is expressed in microseconds, so 1000000 is equivalent</span><br><span class="line"># to one second. Note that a negative number disables the slow log, while</span><br><span class="line"># a value of zero forces the logging of every command.</span><br><span class="line">slowlog-log-slower-than 10000</span><br><span class="line"></span><br><span class="line"># There is no limit to this length. Just be aware that it will consume memory.</span><br><span class="line"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span><br><span class="line">slowlog-max-len 1024</span><br><span class="line"></span><br><span class="line">################################ VIRTUAL MEMORY ###############################</span><br><span class="line"></span><br><span class="line">### WARNING! Virtual Memory is deprecated in Redis 2.4</span><br><span class="line">### The use of Virtual Memory is strongly discouraged.</span><br><span class="line"></span><br><span class="line">### WARNING! Virtual Memory is deprecated in Redis 2.4</span><br><span class="line">### The use of Virtual Memory is strongly discouraged.</span><br><span class="line"></span><br><span class="line"># Virtual Memory allows Redis to work with datasets bigger than the actual</span><br><span class="line"># amount of RAM needed to hold the whole dataset in memory.</span><br><span class="line"># In order to do so very used keys are taken in memory while the other keys</span><br><span class="line"># are swapped into a swap file, similarly to what operating systems do</span><br><span class="line"># with memory pages.</span><br><span class="line"># 指定是否启用虚拟内存机制，默认值为no，</span><br><span class="line"># VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中</span><br><span class="line"># 把vm-enabled设置为yes，根据需要设置好接下来的三个VM参数，就可以启动VM了</span><br><span class="line">vm-enabled no</span><br><span class="line"># vm-enabled yes</span><br><span class="line"></span><br><span class="line"># This is the path of the Redis swap file. As you can guess, swap files</span><br><span class="line"># can&apos;t be shared by different Redis instances, so make sure to use a swap</span><br><span class="line"># file for every redis process you are running. Redis will complain if the</span><br><span class="line"># swap file is already in use.</span><br><span class="line">#</span><br><span class="line"># Redis交换文件最好的存储是SSD（固态硬盘）</span><br><span class="line"># 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享</span><br><span class="line"># *** WARNING *** if you are using a shared hosting the default of putting</span><br><span class="line"># the swap file under /tmp is not secure. Create a dir with access granted</span><br><span class="line"># only to Redis user and configure Redis to create the swap file there.</span><br><span class="line">vm-swap-file /tmp/redis.swap</span><br><span class="line"></span><br><span class="line"># With vm-max-memory 0 the system will swap everything it can. Not a good</span><br><span class="line"># default, just specify the max amount of RAM you can in bytes, but it&apos;s</span><br><span class="line"># better to leave some margin. For instance specify an amount of RAM</span><br><span class="line"># that&apos;s more or less between 60 and 80% of your free RAM.</span><br><span class="line"># 将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多少，所有索引数据都是内存存储的（Redis的索引数据就是keys）</span><br><span class="line"># 也就是说当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认值为0</span><br><span class="line">vm-max-memory 0</span><br><span class="line"></span><br><span class="line"># Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的。</span><br><span class="line"># 建议如果存储很多小对象，page大小最后设置为32或64bytes；如果存储很大的对象，则可以使用更大的page，如果不确定，就使用默认值</span><br><span class="line">vm-page-size 32</span><br><span class="line"></span><br><span class="line"># 设置swap文件中的page数量由于页表（一种表示页面空闲或使用的bitmap）是存放在内存中的，在磁盘上每8个pages将消耗1byte的内存</span><br><span class="line"># swap空间总容量为 vm-page-size * vm-pages</span><br><span class="line">#</span><br><span class="line"># With the default of 32-bytes memory pages and 134217728 pages Redis will</span><br><span class="line"># use a 4 GB swap file, that will use 16 MB of RAM for the page table.</span><br><span class="line">#</span><br><span class="line"># It&apos;s better to use the smallest acceptable value for your application,</span><br><span class="line"># but the default is large in order to work in most conditions.</span><br><span class="line">vm-pages 134217728</span><br><span class="line"></span><br><span class="line"># Max number of VM I/O threads running at the same time.</span><br><span class="line"># This threads are used to read/write data from/to swap file, since they</span><br><span class="line"># also encode and decode objects from disk to memory or the reverse, a bigger</span><br><span class="line"># number of threads can help with big objects even if they can&apos;t help with</span><br><span class="line"># I/O itself as the physical device may not be able to couple with many</span><br><span class="line"># reads/writes operations at the same time.</span><br><span class="line"># 设置访问swap文件的I/O线程数，最后不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟，默认值为4</span><br><span class="line">vm-max-threads 4</span><br><span class="line"></span><br><span class="line">############################### ADVANCED CONFIG ###############################</span><br><span class="line"></span><br><span class="line"># Hashes are encoded in a special way (much more memory efficient) when they</span><br><span class="line"># have at max a given numer of elements, and the biggest element does not</span><br><span class="line"># exceed a given threshold. You can configure this limits with the following</span><br><span class="line"># configuration directives.</span><br><span class="line"># 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法</span><br><span class="line">hash-max-zipmap-entries 512</span><br><span class="line">hash-max-zipmap-value 64</span><br><span class="line"></span><br><span class="line"># Similarly to hashes, small lists are also encoded in a special way in order</span><br><span class="line"># to save a lot of space. The special representation is only used when</span><br><span class="line"># you are under the following limits:</span><br><span class="line">list-max-ziplist-entries 512</span><br><span class="line">list-max-ziplist-value 64</span><br><span class="line"></span><br><span class="line"># Sets have a special encoding in just one case: when a set is composed</span><br><span class="line"># of just strings that happens to be integers in radix 10 in the range</span><br><span class="line"># of 64 bit signed integers.</span><br><span class="line"># The following configuration setting sets the limit in the size of the</span><br><span class="line"># set in order to use this special memory saving encoding.</span><br><span class="line">set-max-intset-entries 512</span><br><span class="line"></span><br><span class="line"># Similarly to hashes and lists, sorted sets are also specially encoded in</span><br><span class="line"># order to save a lot of space. This encoding is only used when the length and</span><br><span class="line"># elements of a sorted set are below the following limits:</span><br><span class="line">zset-max-ziplist-entries 128</span><br><span class="line">zset-max-ziplist-value 64</span><br><span class="line"></span><br><span class="line"># Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in</span><br><span class="line"># order to help rehashing the main Redis hash table (the one mapping top-level</span><br><span class="line"># keys to values). The hash table implementation redis uses (see dict.c)</span><br><span class="line"># performs a lazy rehashing: the more operation you run into an hash table</span><br><span class="line"># that is rhashing, the more rehashing &quot;steps&quot; are performed, so if the</span><br><span class="line"># server is idle the rehashing is never complete and some more memory is used</span><br><span class="line"># by the hash table.</span><br><span class="line"># </span><br><span class="line"># The default is to use this millisecond 10 times every second in order to</span><br><span class="line"># active rehashing the main dictionaries, freeing memory when possible.</span><br><span class="line">#</span><br><span class="line"># If unsure:</span><br><span class="line"># use &quot;activerehashing no&quot; if you have hard latency requirements and it is</span><br><span class="line"># not a good thing in your environment that Redis can reply form time to time</span><br><span class="line"># to queries with 2 milliseconds delay.</span><br><span class="line"># 指定是否激活重置哈希，默认为开启</span><br><span class="line">activerehashing yes</span><br><span class="line"></span><br><span class="line">################################## INCLUDES ###################################</span><br><span class="line"></span><br><span class="line"># 指定包含其他的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各实例又拥有自己的特定配置文件</span><br><span class="line"># include /path/to/local.conf</span><br><span class="line"># include /path/to/other.conf</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;由于公司开发笔记本用的是mac，所以我这里介绍一下在mac和linux环境下的redis安装&lt;/p&gt;&lt;h2 id=&quot;Linu
      
    
    </summary>
    
    
      <category term="redis" scheme="http://www.fufan.me/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Mac开发提升效率工具（一）</title>
    <link href="http://www.fufan.me/2018/02/09/Mac%E5%BC%80%E5%8F%91%E6%8F%90%E5%8D%87%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://www.fufan.me/2018/02/09/Mac开发提升效率工具（一）/</id>
    <published>2018-02-09T06:07:00.000Z</published>
    <updated>2018-11-09T06:17:17.315Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:17:17 GMT+0800 (China Standard Time) --><h3 id="Markdown编辑器"><a href="#Markdown编辑器" class="headerlink" title="Markdown编辑器"></a>Markdown编辑器</h3><p>目前可供选择的markdown编辑器至少以下有六种:</p><ol><li><a href="http://www.typora.io/" target="_blank" rel="noopener">Typora</a>, 简洁轻便免费, 独有的所见即所得, 可在预览状态下编辑, 快捷键丰富, 脚本高亮功能出彩, 导出为pdf后, 排版同样正常, 这点非常难得, 笔者使用的就是该款.</li><li><a href="http://www.ulyssesapp.com/" target="_blank" rel="noopener">Ulysses</a>, 功能强大, 快捷键丰富, 支持目录导入, 支持多终端同步.</li><li><a href="http://www.pc6.com/mac/161974.html" target="_blank" rel="noopener">MWeb Lite</a>, <a href="http://zh.mweb.im/" target="_blank" rel="noopener">MWeb</a>的微型版, 不收费, 支持目录导入.</li><li><a href="http://macdown.uranusjr.com/" target="_blank" rel="noopener">macdown</a>, 基于mou开发, 轻量, 不支持目录导入.</li><li><a href="http://25.io/mou/" target="_blank" rel="noopener">mou</a> 历史悠久, 据说有少量的bug, 具体请参考 <a href="http://www.jianshu.com/p/6c157af09e84" target="_blank" rel="noopener">Mac 下两款 Markdown 编辑器 Mou/MacDown 大 PK - 简书</a> .</li><li><a href="http://markeditor.com/app/markeditor" target="_blank" rel="noopener">markeditor</a>, 新出的markdown编辑器, 注重视觉感受, 界面不错, 但运行较慢.</li></ol><p>以上, 推荐开发使用 Typora, PM等使用 Ulysses.</p><h3 id="Mac重度依赖者"><a href="#Mac重度依赖者" class="headerlink" title="Mac重度依赖者"></a>Mac重度依赖者</h3><h4 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h4><ul><li><a href="https://www.charlesproxy.com/" target="_blank" rel="noopener">Charles</a> 网络封包分析应用, mac必备.</li><li><a href="http://www.trankynam.com/atext/" target="_blank" rel="noopener">aText</a> 输入增强应用, 比 <a href="http://www.pc6.com/mac/146924.html" target="_blank" rel="noopener"><code>TextExpander</code></a> 要人性化许多，并且对中文和第三方输入法的支持都要更好.</li><li><a href="https://kapeli.com/dash" target="_blank" rel="noopener">Dash</a> mac上api集合应用, 几乎包含各种语言的api文档.</li><li><a href="http://www.renfei.org/snippets-lab/" target="_blank" rel="noopener">SnippetsLab</a> 优秀的代码片段管理工具, 轻量, 可基于菜单栏操作.</li></ul><h4 id="提高效率"><a href="#提高效率" class="headerlink" title="提高效率"></a>提高效率</h4><ul><li><a href="http://www.sdifenzhou.com/alfred3.html" target="_blank" rel="noopener">Alfred 3</a> 神奇的魔法帽, 支持 ① 快速打开application; ② 支持Finder, Calculator, Contacts, Clipboard, iTunes, System, Terminal 等原生应用的各种便捷功能; ③ 支持workflow(工作流).</li><li><a href="http://www.iterm2.com/" target="_blank" rel="noopener">iterm2</a> 增强版的终端应用, 功能强大, 支持分屏, 历史记录, 选中即复制等.</li><li><a href="http://www.pc6.com/mac/124262.html" target="_blank" rel="noopener">Sip</a> 全屏取色应用, 支持快捷键调出(前端福音, 寻找多年, 终于发掘出来了).</li><li><a href="http://www.kekaosx.com/en/" target="_blank" rel="noopener">Keka</a> 压缩或解压缩应用, 开源免费, 压缩比高, 操作便捷, 支持rar等解压, 压缩中文目录后, 在windows下打开不会存在乱码等现象.</li><li><a href="https://github.com/oldj/SwitchHosts/releases" target="_blank" rel="noopener">SwitchHosts</a> 域名host解析必备神器, 支持 windows和Mac的开源工具, mac下只有几百K大小.</li><li><a href="http://pilotmoon.com/scrollreverser/" target="_blank" rel="noopener">Scroll Reverser</a> mac滚动方向自定义应用, 可分别设置鼠标和触摸板的上下左右的滚动效果.</li><li><a href="http://www.irradiatedsoftware.com/sizeup/" target="_blank" rel="noopener">Size up</a> 分屏应用, 类似Moon的一款应用, 支持上下左右居中、4个角落快速分屏及多屏幕切换.</li><li><a href="http://www.pc6.com/mac/124992.html" target="_blank" rel="noopener">Divvy</a> 另一款分屏应用, 可将屏幕分成多宫格的形式, 然后为每个格子定义快捷键, 遗憾的是不支持多屏幕切换.</li><li><a href="http://www.graphviz.org/" target="_blank" rel="noopener">Graphviz</a> 贝尔实验室开发的有向图/无向图自动布局应用, 支持dot脚本绘制结构图, 流程图等. 可参考教程 <a href="http://www.cnblogs.com/sld666666/archive/2010/06/25/1765510.html" target="_blank" rel="noopener">利用Graphviz 画结构图</a> 及 <a href="http://www.cnblogs.com/CoolJie/archive/2012/07/17/graphviz.html" target="_blank" rel="noopener">使用graphviz绘制流程图</a> .</li><li><a href="http://www.xmindchina.net/" target="_blank" rel="noopener">XMind</a> 思维导图应用, 适合业务及思路梳理.</li><li><a href="http://www.pc6.com/mac/129882.html" target="_blank" rel="noopener">iThoughtsX</a> 另一款思维导图应用, 更加简洁和轻量.</li><li><a href="http://www.pc6.com/mac/136806.html" target="_blank" rel="noopener">Pomodoro One</a> 番茄工作法的一款应用.</li></ul><h4 id="博主必备"><a href="#博主必备" class="headerlink" title="博主必备"></a>博主必备</h4><ul><li><a href="http://screenflow.en.softonic.com/mac" target="_blank" rel="noopener">ScreenFlow</a> 这或许是mac上最好用的屏幕录制应用.</li><li><a href="http://www.waitsun.com/annotate-2-0-5.html" target="_blank" rel="noopener">Annotate</a> 屏幕截图批注应用, 令人惊喜的是, 支持划区域gif制作, 教程以及动图制作者必备.</li><li><a href="http://www.cockos.com/licecap/" target="_blank" rel="noopener">Licecap</a> mac上超强大的且极简的gif录制应用, 使用免费, 支持FPS帧率调整且无录制时间限制(笔者用它录制了很多gif动图).</li><li><a href="http://mac.softpedia.com/get/Utilities/KeyCastr.shtml" target="_blank" rel="noopener">KeyCastr</a> 将mac按键显示在屏幕上，分享演示、录制视频或动图时超赞.</li></ul><h4 id="Mac定制化"><a href="#Mac定制化" class="headerlink" title="Mac定制化"></a>Mac定制化</h4><ul><li><a href="https://www.macbartender.com/" target="_blank" rel="noopener">Bartender 2</a> 菜单栏管理应用, 支持隐藏所有菜单栏图标, 还您一个干净的菜单栏.</li><li><a href="http://www.pc6.com/mac/161158.html" target="_blank" rel="noopener">CDock</a> 任务栏定制应用, 可设置Dock全透明, 还您一个清爽的任务栏.</li><li><a href="https://www.macstories.net/mac/textbar-puts-your-text-into-the-menu-bar/" target="_blank" rel="noopener">TextBar</a> 自定义菜单栏输出, 支持script运行, 支持H5渲染.</li><li><a href="http://growl.info/" target="_blank" rel="noopener">Growl</a> 自定义通知样式, 支持多种主题以及颜色, 大小, 渐隐时间等各项参数的自定义.</li><li><a href="https://pqrs.org/osx/karabiner/" target="_blank" rel="noopener">Karabiner</a> 键盘映射修改神器.</li><li><a href="https://www.keyboardmaestro.com/main/" target="_blank" rel="noopener">Keyboard Maestro</a> 键盘大师, mac下功能最为丰富的键盘增强应用.</li><li><a href="https://www.boastr.net/" target="_blank" rel="noopener">BetterTouchTool</a> mac触摸板增强神器.</li><li><a href="http://sspai.com/28020" target="_blank" rel="noopener">Übersicht</a> 华丽的桌面自定义应用, 类似于windows的 <a href="http://rainmeter.cn/cms/" target="_blank" rel="noopener"><code>rainmeter</code></a>. 支持H5.</li><li><a href="http://www.waerfa.com/today-scripts-for-yosemite-today-view" target="_blank" rel="noopener">Today Scripts</a> 个性化通知栏插件, 支持bash脚本(最新的OSX系统不支持).</li><li><a href="http://tweaksapp.com/app/mountain-tweaks/" target="_blank" rel="noopener">Mountain Tweaks</a> mac隐藏功能开启应用.</li></ul><h4 id="折腾党玩转Mac"><a href="#折腾党玩转Mac" class="headerlink" title="折腾党玩转Mac"></a>折腾党玩转Mac</h4><ul><li><a href="http://www.pc6.com/mac/144495.html" target="_blank" rel="noopener">TripMode</a> 移动热点流量管家, 出差达人的福音.</li><li><a href="http://www.pc6.com/mac/121734.html" target="_blank" rel="noopener">Caffeine</a> 点亮mac, 避免长时间演示ppt而进入到休眠状态.</li><li><a href="http://www.yingdev.com/projects/tickeys" target="_blank" rel="noopener">Tickeys</a> 键盘打字风格模拟应用, 支持 Cherry轴等多种风格.</li><li><a href="http://www.pc6.com/mac/116332.html" target="_blank" rel="noopener">keycue</a> 快捷键辅助应用, 帮助记忆快捷键.</li><li><a href="http://www.airserver.com/" target="_blank" rel="noopener">AirServer</a> IOS连接mac必备.</li><li><a href="http://www.beyondcompare.cc/" target="_blank" rel="noopener">Beyond Compare</a> 文件比较应用, 支持文件, 目录, FTP远程地址比较等.</li><li><a href="http://www.pc6.com/mac/129593.html" target="_blank" rel="noopener">Debookee</a> 网络抓包及数据分析应用.</li><li><a href="http://www.waerfa.com/easyfind" target="_blank" rel="noopener">EasyFind</a> 小而强大的文件搜索应用, 媲美windows下的Everything.</li><li><a href="https://filezilla-project.org/" target="_blank" rel="noopener">FileZilla</a> 免费开源的FTP应用.</li><li><a href="http://newping.cn/322" target="_blank" rel="noopener">OmniDiskSweeper</a> 硬盘空间扫描应用, 帮助mac减肥.</li><li><a href="http://www.pc6.com/mac/113361.html" target="_blank" rel="noopener">Kaleidoscope</a> 文件和图像比较应用, 支持图片比较, 能与 git, svn 等版本控制工具完美结合.</li><li><a href="http://freemacsoft.net/appcleaner/" target="_blank" rel="noopener">AppCleaner</a> mac应用卸载工具, 结合 <a href="https://github.com/Louiszhai/tool/blob/master/workflow/AppCleaner.alfredworkflow?raw=true" target="_blank" rel="noopener"><code>AppCleaner</code></a> 的workflow, 使用效果更佳.</li><li><a href="http://www.pc6.com/mac/115425.html" target="_blank" rel="noopener">TeamViewer</a> 远程开发或协助必备应用.</li><li><a href="http://www.pc6.com/mac/428096.html" target="_blank" rel="noopener">Script Debugger</a> 强大的AppleScript编辑器.</li><li><a href="http://www.pc6.com/mac/158839.html" target="_blank" rel="noopener">Reeder</a> 界面优美的RSS订阅应用.</li><li><a href="https://bahoom.com/hyperswitch" target="_blank" rel="noopener">HyperSwitch</a> 带有预览图的快速切换, 作用同Command+Tab.</li><li><a href="https://github.com/Swordfish90/cool-retro-term" target="_blank" rel="noopener">Cool retro term</a> 终端变身复古显示器.</li><li><a href="http://www.pc6.com/mac/119197.html" target="_blank" rel="noopener">Fruit Juice</a> 电池管理应用, 帮助延迟电池的使用时间.</li></ul><h3 id="终端命令"><a href="#终端命令" class="headerlink" title="终端命令"></a>终端命令</h3><ul><li><p><a href="http://ohmyz.sh/" target="_blank" rel="noopener">ohmyzsh</a> shell有很多种, 常用的bash就是之一. 而zsh是shell中目前最强大的, 没有之一. ohmyzsh屏蔽了zsh复杂的配置, 真正达到了一键上手zsh的目的.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Mac下自动安装&amp;设置</span></span><br><span class="line">wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh</span><br><span class="line"><span class="comment"># 设置 shell 默认使用 zsh</span></span><br><span class="line">chsh -s /bin/zsh</span><br><span class="line"><span class="comment">#在 dock 栏右键退出终端, 然后重启终端~安装完成</span></span><br></pre></td></tr></table></figure></li><li><p><a href="https://github.com/wting/autojump" target="_blank" rel="noopener">autojump</a> 支持快速跳转到曾经打开过的目录下,安装方法: brew install autojump .</p></li><li><p><a href="http://tmux.github.io/" target="_blank" rel="noopener">tmux</a> 终端复用工具, 支持在终端中创建不依赖于终端的窗口, 安装方法: brew install tmux. 使用请参考：<a href="http://louiszhai.github.io/2017/09/30/tmux/" target="_blank" rel="noopener">Tmux使用手册</a>.</p></li></ul><h3 id="Chrome-Extension篇"><a href="#Chrome-Extension篇" class="headerlink" title="Chrome Extension篇"></a>Chrome Extension篇</h3><h4 id="自制"><a href="#自制" class="headerlink" title="自制"></a>自制</h4><ul><li><a href="https://github.com/Louiszhai/IHeader" target="_blank" rel="noopener">Iheader</a> 监听和修改http/https请求/响应头，可用于渗透测试（笔者修改请求头用于跨域调试，特别好用）。</li><li><a href="https://chrome.google.com/webstore/detail/qrcode/cmpjmgpafdgofigbhbneckneoakpdhag?utm_source=chrome-ntp-icon" target="_blank" rel="noopener">Qrcode</a> URL生成二维码，如果网页中包含选中文本，则生成选中文本的二维码。</li></ul><h4 id="前端有关"><a href="#前端有关" class="headerlink" title="前端有关"></a>前端有关</h4><ul><li><a href="https://chrome.google.com/webstore/detail/react-developer-tools/fmkadmapgofadopljbjfkapdkoienihi" target="_blank" rel="noopener">React Developer Tools</a> React开发者工具.</li><li><a href="https://chrome.google.com/webstore/detail/redux-devtools/lmhkpmbekcpmknklioeibfkpmmfibljd" target="_blank" rel="noopener">Redux DevTools</a> Redux开发者工具.</li><li><a href="https://chrome.google.com/webstore/detail/web%E5%89%8D%E7%AB%AF%E5%8A%A9%E6%89%8Bfehelper/pkgccpejnmalmdinmhkkfafefagiiiad0" target="_blank" rel="noopener">FE助手</a> 百度推出的前端助手, 具有很多便捷的小功能.</li><li><a href="https://chrome.google.com/webstore/detail/yslow/ninejjcohidippngpapiilnmkgllmakh" target="_blank" rel="noopener">YSlow</a> 雅虎性能分析工具.</li><li><a href="https://chrome.google.com/webstore/detail/postman/fhbjgbiflinjbdggehcddcbncdddomop" target="_blank" rel="noopener">Postman</a> 接口调试工具, 几乎支持所有类型的http(s)请求.</li><li><a href="https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg?utm_source=chrome-ntp-icon" target="_blank" rel="noopener">EditThisCookie</a> cookie编辑工具, 可用于获取或设置http only等cookie的值.</li><li><a href="https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc" target="_blank" rel="noopener">JSONView</a> json预览工具, 接口调试必备.</li><li><a href="https://chrome.google.com/webstore/detail/page-ruler/jlpkojjdgbllmedoapgfodplfhcbnbpn" target="_blank" rel="noopener">Page Ruler</a> 页面尺子, 页面重构或者严格按照设计图开发页面时, 将会非常有用.</li><li><a href="https://chrome.google.com/webstore/detail/alexa-traffic-rank/cknebhggccemgcnbidipinkifmmegdel" target="_blank" rel="noopener">Alexa Traffic Rank</a> 网站Alexa排名查看工具.</li></ul><h4 id="工作效率有关"><a href="#工作效率有关" class="headerlink" title="工作效率有关"></a>工作效率有关</h4><ul><li><a href="https://chrome.google.com/webstore/detail/onetab/chphlpgkkbolifaimnlloiipkdnihall" target="_blank" rel="noopener">OneTab</a> 快速关闭并存储浏览器当前窗口所有Tab页, 可用于下次一键全部恢复.</li><li><a href="https://chrome.google.com/webstore/detail/merge-windows/mmpokgfcmbkfdeibafoafkiijdbfblfg" target="_blank" rel="noopener">Merge Windows</a> 合并所有浏览器窗口为同一个窗口.</li><li><a href="https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb" target="_blank" rel="noopener">Vimium</a> 键盘党必备, 使用vim命令管理页面.</li><li><a href="https://chrome.google.com/webstore/detail/vysor/gidgenkbbabolejbgbpnhbimgjbffefm" target="_blank" rel="noopener">Vysor</a> mac上直接操作 Android 手机, 且可远程共享手机操作界面.</li></ul><h4 id="网站有关"><a href="#网站有关" class="headerlink" title="网站有关"></a>网站有关</h4><ul><li><a href="https://chrome.google.com/webstore/detail/octotree/bkhaagjahfmjljalopjnoealnfndnagc" target="_blank" rel="noopener">Octotree</a> Github重度依赖者必备, 提供左侧边栏, 快速浏览仓库内容.</li><li><a href="https://chrome.google.com/webstore/detail/adblock/gighmmpiobklfepjocnamgkkbiglidom" target="_blank" rel="noopener">AdBlock</a> 超强去广告工具, 最受欢迎的Chrome扩展, 拥有超过4000万用户.</li><li><a href="https://chrome.google.com/webstore/detail/reader-view/iibolhpkjjmoepndefdmdlmbpfhlgjpl" target="_blank" rel="noopener">阅读模式</a> 快速开启阅读模式, 进入沉浸式阅读, 并非支持所有网页.</li><li><a href="https://chrome.google.com/webstore/detail/blipshot-one-click-full-p/mdaboflcmhejfihjcbmdiebgfchigjcf?utm_source=chrome-ntp-icon" target="_blank" rel="noopener">Blipshot</a> 全网页截图工具, 支持自动垂直滚动, 截取网页的所有内容为一张图片.</li></ul><h4 id="Chrome-Extension开发"><a href="#Chrome-Extension开发" class="headerlink" title="Chrome Extension开发"></a>Chrome Extension开发</h4><p>相关文章</p><ul><li><a href="https://developer.chrome.com/extensions/samples" target="_blank" rel="noopener">Sample Extensions - Google Chrome</a></li><li><a href="http://www.ituring.com.cn/minibook/950" target="_blank" rel="noopener">图灵社区: 合集 : Chrome扩展及应用开发</a></li><li><a href="http://www.cnblogs.com/champagne/tag/Google%20Chrome%E6%89%A9%E5%B1%95/" target="_blank" rel="noopener">Google Chrome扩展开发系列</a></li></ul><h3 id="Alfred-workflow"><a href="#Alfred-workflow" class="headerlink" title="Alfred workflow"></a>Alfred workflow</h3><p>我曾经耗费巨大的精力, 试图在计算机的使用效率上找到一条优化的策略, 一直以来都收效甚微. 直到遇上Alfred, 它强大的工作流机制, 才让我明白原来计算机可以这么玩. 因为<strong>它彻底解决了输入输出的痛点, 极大的减少了程序之间的切换成本以及按键成本</strong>.</p><p>传统意义上, 使用mac时, 为了查询一个单词, 或者翻译一个单词, 我们要么经历五步: ① 手动打开浏览器 ② 进入谷歌首页 ③ 选中输入框 ④ 输入或粘贴查询单词, 然后空格并加上”翻译” 两个字, 然后再回车 ⑤ 等待浏览器展示查询结果; 要么经历四步: ① 打开翻译应用(比如自带词典) ② 输入或粘贴查询单词 ③ 翻译应用输出查询结果 ④ 查询过后, 一般都需要Command+Q退出应用(否则Dock栏将会全是未关闭的应用).</p><p>查询单词这个场景中, 我们至少需要兴师动众, 切换或打开一个应用两次, 定位输入框一次, 输入或复制粘贴一次. 且查询结果页也会挡住当前的工作区, 使得我们分心, 甚至忘记自己刚刚在做啥. 五个字 — 体验不流畅.</p><p>而 Alfred 的工作流正是为了解决这个问题而设计的. 如果我们使用网友开发的 <a href="https://github.com/Louiszhai/tool/blob/master/workflow/youdao.alfredworkflow?raw=true" target="_blank" rel="noopener"><code>有道词典</code></a> 的 workflow, <strong>最快只需通过两次按键便可获取单词的查询结果</strong>. 假如: 为了查询单词”workflow”, 我会选中单词所在区域, 然后按住 Option+Y 键(我已将有道翻译的快捷键设置为 Option+Y), 单词查询结果就出来了, 而且不需要切换应用, 同时查询结果也较少的挡住工作区了.</p><p>以上 Alfred 界面使用了少数派的主题.</p><p>有关其他的workflow 内容, 请移步 <a href="https://github.com/Louiszhai/alfred-workflows" target="_blank" rel="noopener"><code>Alfred Workflows</code></a> , 那里会有更多非常不错的 workflow 供您选用.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:17:17 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;Markdown编辑器&quot;&gt;&lt;a href=&quot;#Markdown编辑器&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
      <category term="mac" scheme="http://www.fufan.me/categories/mac/"/>
    
    
      <category term="mac" scheme="http://www.fufan.me/tags/mac/"/>
    
      <category term="工具" scheme="http://www.fufan.me/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Redis学习笔记（一）——初识redis</title>
    <link href="http://www.fufan.me/2018/02/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%88%9D%E8%AF%86redis/"/>
    <id>http://www.fufan.me/2018/02/07/Redis学习笔记（一）——初识redis/</id>
    <published>2018-02-07T13:02:00.000Z</published>
    <updated>2018-11-08T10:11:15.679Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>由于加入公司一段时间了，公司的爬虫项目太过于依赖redis这个中间件，包括线上的几次重大异常都是由redis来引起的（redis分布式锁问题，阿里云redis主从和分布式服务异常问题等）。所以找时间专门学习一下关于redis的一些使用。</p><p>Redis学习链接：<br><a href="http://www.runoob.com/redis/redis-tutorial.html" target="_blank" rel="noopener">菜鸟redis教程</a><br><a href="http://www.redis.net.cn/tutorial/3501.html" target="_blank" rel="noopener">官网教程</a></p><p><img src="/image/redis-0-0.png" alt=""></p><h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h2><p>Redis是一个速度极快的非关系数据库，也就是我们所说的NoSQL数据库(non-relational database)，它可以存储键(key)与5种不同类型的值(value)之间的映射(mapping)，可以将存储在内存的键值对数据持久化到硬盘，可以使用复制特性来扩展读性能，还可以使用客户端分片来扩展性能，并且它还提供了多种语言的API。</p><ul><li>Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。</li><li>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis支持数据的备份，即master-slave模式的数据备份。</li></ul><h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><ul><li>性能极高： Redis能读的速度是110000次/s,写的速度是81000次/s</li><li>丰富的数据类型：Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。</li><li>原子性：Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。</li><li>丰富的特性：支持 publish/subscribe, 通知, key 过期等等特性。</li><li>分布式锁：很多分布式系统中可以用redis的setnx和getset来做分布式锁</li></ul><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="字符串-String"><a href="#字符串-String" class="headerlink" title="字符串 - String"></a>字符串 - String</h3><ul><li>string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。</li><li>string类型是Redis最基本的数据类型，一个键最大能存储512MB。</li></ul><p>api示例：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set username fufan</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get username</span><br><span class="line">&quot;fufan&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p></p><h3 id="哈希-hash"><a href="#哈希-hash" class="headerlink" title="哈希 - hash"></a>哈希 - hash</h3><ul><li>Redis hash 是一个键值对集合。</li><li>Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。</li><li>每个 hash 可以存储 232 - 1 键值对（40多亿）。</li></ul><p>api示例：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; HSET user name fufan password 121314</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; HGETALL user</span><br><span class="line">1) &quot;name&quot;</span><br><span class="line">2) &quot;fufan&quot;</span><br><span class="line">3) &quot;password&quot;</span><br><span class="line">4) &quot;121314&quot;</span><br></pre></td></tr></table></figure><p></p><h3 id="列表-list"><a href="#列表-list" class="headerlink" title="列表 - list"></a>列表 - list</h3><ul><li>Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。</li><li>列表最多可存储 2^32 - 1 元素 (4294967295, 每个列表可存储40多亿)。</li></ul><p>api示例：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; LPUSH userlist fufan</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; LPUSH userlist yajun</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; LPUSH userlist luwei</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; LPOP userlist</span><br><span class="line">&quot;luwei&quot;</span><br><span class="line">127.0.0.1:6379&gt; RPOP userlist</span><br><span class="line">&quot;fufan&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p></p><h3 id="集合-set"><a href="#集合-set" class="headerlink" title="集合 - set"></a>集合 - set</h3><ul><li>Redis的Set是string类型的无序集合。</li><li>集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)</li><li>根据集合内元素的唯一性，第二次插入的元素将被忽略。</li><li>集合中最大的成员数为 2^32 -1(4294967295,每个集合可存储40多亿个成员)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd product phone</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sadd product pad</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sadd product tv</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; SMEMBERS product</span><br><span class="line">1) &quot;tv&quot;</span><br><span class="line">2) &quot;phone&quot;</span><br><span class="line">3) &quot;pad&quot;</span><br></pre></td></tr></table></figure></li></ul><h3 id="有序集合-sorted-set"><a href="#有序集合-sorted-set" class="headerlink" title="有序集合 - sorted set"></a>有序集合 - sorted set</h3><ul><li>Redis zset 和 set一样也是string类型元素的集合,且不允许重复的成员。</li><li>不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。</li><li>zset的成员是唯一的,但分数(score)却可以重复。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZADD fufan 100 chinese</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ZADD fufan 100 math</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ZADD fufan 135 english</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE fufan 0 10 withscores</span><br><span class="line">1) &quot;chinese&quot;</span><br><span class="line">2) &quot;100&quot;</span><br><span class="line">3) &quot;math&quot;</span><br><span class="line">4) &quot;100&quot;</span><br><span class="line">5) &quot;english&quot;</span><br><span class="line">6) &quot;135&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE fufan 100 100</span><br><span class="line">1) &quot;chinese&quot;</span><br><span class="line">2) &quot;math&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;由于加入公司一段时间了，公司的爬虫项目太过于依赖redis这个中间件，包括线上的几次重大异常都是由redis来引起的（red
      
    
    </summary>
    
      <category term="redis" scheme="http://www.fufan.me/categories/redis/"/>
    
    
      <category term="redis" scheme="http://www.fufan.me/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>JVM专题（三）——GC算法 垃圾收集器</title>
    <link href="http://www.fufan.me/2017/11/21/JVM%E4%B8%93%E9%A2%98%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94GC%E7%AE%97%E6%B3%95-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/"/>
    <id>http://www.fufan.me/2017/11/21/JVM专题（三）——GC算法-垃圾收集器/</id>
    <published>2017-11-20T16:30:00.000Z</published>
    <updated>2018-11-08T10:38:47.127Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>这篇文件将给大家介绍GC都有哪几种算法，以及JVM都有那些垃圾回收器，它们的工作原理。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>垃圾收集 Garbage Collection 通常被称为“GC”，它诞生于1960年 MIT 的 Lisp 语言，经过半个多世纪，目前已经十分成熟了。 jvm 中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈帧随着方法的进入和退出做入栈和出栈操作，实现了自动的内存清理，因此，我们的内存垃圾回收主要集中于 java 堆和方法区中，在程序运行期间，这部分内存的分配和使用都是动态的.</p><h2 id="对象存活判断"><a href="#对象存活判断" class="headerlink" title="对象存活判断"></a>对象存活判断</h2><p>判断对象是否存活一般有两种方式：</p><p>引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。<br>可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。不可达对象。</p><p>在Java语言中，GC Roots包括：</p><ul><li>虚拟机栈中引用的对象。</li><li>方法区中类静态属性实体引用的对象。</li><li>方法区中常量引用的对象。</li><li>本地方法栈中JNI引用的对象。</li></ul><h2 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h2><h3 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记 -清除算法"></a>标记 -清除算法</h3><p>“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。</p><p>它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</p><p><img src="/image/jvm-3-0.png" alt=""></p><h3 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h3><p>“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。</p><p>这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为原来的一半，持续复制长生存期的对象则导致效率降低。<br><img src="/image/jvm-3-1.png" alt=""></p><h3 id="标记-压缩算法"><a href="#标记-压缩算法" class="headerlink" title="标记-压缩算法"></a>标记-压缩算法</h3><p>复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。</p><p>根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存<br><img src="/image/jvm-3-2.png" alt=""></p><h3 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h3><p>GC分代的基本假设：绝大部分对象的生命周期都非常短暂，存活时间短。</p><p>“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。</p><h3 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现</span><br></pre></td></tr></table></figure><h3 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h3><p>串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。新生代、老年代使用串行回收；新生代复制算法、老年代标记-压缩；垃圾收集的过程中会Stop The World（服务暂停）</p><p>参数控制：-XX:+UseSerialGC 串行收集器<br><img src="/image/jvm-3-3.png" alt=""></p><h3 id="ParNew收集器"><a href="#ParNew收集器" class="headerlink" title="ParNew收集器"></a>ParNew收集器</h3><p>ParNew收集器其实就是Serial收集器的多线程版本。新生代并行，老年代串行；新生代复制算法、老年代标记-压缩</p><p>参数控制：</p><p>-XX:+UseParNewGC ParNew收集器<br>-XX:ParallelGCThreads 限制线程数量</p><p><img src="/image/jvm-3-4.png" alt=""></p><h3 id="Parallel收集器"><a href="#Parallel收集器" class="headerlink" title="Parallel收集器"></a>Parallel收集器</h3><p>Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩</p><p>参数控制：-XX:+UseParallelGC 使用Parallel收集器+ 老年代串行</p><h3 id="Parallel-Old-收集器"><a href="#Parallel-Old-收集器" class="headerlink" title="Parallel Old 收集器"></a>Parallel Old 收集器</h3><p>Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。这个收集器是在JDK 1.6中才开始提供</p><p>参数控制： -XX:+UseParallelOldGC 使用Parallel收集器+ 老年代并行</p><h3 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h3><p>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。</p><p>从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括：</p><ul><li>初始标记（CMS initial mark）</li><li>并发标记（CMS concurrent mark）</li><li>重新标记（CMS remark）</li><li>并发清除（CMS concurrent sweep）</li></ul><p>其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。</p><p>由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。老年代收集器（新生代使用ParNew）</p><p>优点: 并发收集、低停顿<br>缺点: 产生大量空间碎片、并发阶段会降低吞吐量</p><p>参数控制：</p><ul><li>-XX:+UseConcMarkSweepGC 使用CMS收集器</li><li>-XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长</li><li>-XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理</li><li>-XX:ParallelCMSThreads 设定CMS的线程数量（一般情况约等于可用CPU数量）</li></ul><p><img src="/image/jvm-3-5.png" alt=""></p><h3 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h3><p>G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。与CMS收集器相比G1收集器有以下特点：</p><ol><li>空间整合，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。</li><li>可预测停顿，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。</li></ol><p><img src="/image/jvm-3-6.png" alt=""></p><p>上面提到的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。</p><p>G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。和CMS类似，G1收集器收集老年代对象会有短暂停顿。</p><p>收集步骤：</p><ul><li>1、标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark)</li><li>2、Root Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。</li><li>3、Concurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。<br><img src="/image/jvm-3-7.png" alt=""></li><li>4、Remark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。</li><li>5、Copy/Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。</li></ul><p><img src="/image/jvm-3-8.png" alt=""></p><p>6、复制/清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。</p><p><img src="/image/jvm-3-9.png" alt=""></p><h3 id="常用的收集器组合"><a href="#常用的收集器组合" class="headerlink" title="常用的收集器组合"></a>常用的收集器组合</h3><table><thead><tr><th>服务器</th><th>新生代GC策略</th><th>老年老代GC策略</th><th>说明</th></tr></thead><tbody><tr><td>组合1</td><td>Serial</td><td>Serial Old</td><td>Serial和Serial Old都是单线程进行GC，特点就是GC时暂停所有应用线程。</td></tr><tr><td>组合2</td><td>Serial</td><td>CMS+Serial Old</td><td>CMS（Concurrent Mark Sweep）是并发GC，实现GC线程和应用线程并发工作，不需要暂停所有应用线程。另外，当CMS进行GC失败时，会自动使用Serial Old策略进行GC。</td></tr><tr><td>组合3</td><td>ParNew</td><td>CMS</td><td>使用-XX:+UseParNewGC选项来开启。ParNew是Serial的并行版本，可以指定GC线程数，默认GC线程数为CPU的数量。可以使用-XX:ParallelGCThreads选项指定GC的线程数。如果指定了选项-XX:+UseConcMarkSweepGC选项，则新生代默认使用ParNew GC策略。</td></tr><tr><td>组合4</td><td>ParNew</td><td>Serial Old</td><td>使用-XX:+UseParNewGC选项来开启。新生代使用ParNew GC策略，年老代默认使用Serial Old GC策略。</td></tr><tr><td>组合5</td><td>Parallel Scavenge</td><td>Serial Old</td><td>Parallel Scavenge策略主要是关注一个可控的吞吐量：应用程序运行时间 / (应用程序运行时间 + GC时间)，可见这会使得CPU的利用率尽可能的高，适用于后台持久运行的应用程序，而不适用于交互较多的应用程序。</td></tr><tr><td>组合6</td><td>Parallel Scavenge</td><td>Parallel Old</td><td>Parallel Old是Serial Old的并行版本</td></tr><tr><td>组合7</td><td>G1GC</td><td>G1GC</td><td>-XX:+UnlockExperimentalVMOptions -XX:+UseG1GC #开启；-XX:MaxGCPauseMillis =50 #暂停时间目标；-XX:GCPauseIntervalMillis =200 #暂停间隔目标；-XX:+G1YoungGenSize=512m #年轻代大小；-XX:SurvivorRatio=6 #幸存区比例</td></tr></tbody></table><h3 id="系统吞吐量和系统并发数以及响时间的关系理解"><a href="#系统吞吐量和系统并发数以及响时间的关系理解" class="headerlink" title="系统吞吐量和系统并发数以及响时间的关系理解"></a>系统吞吐量和系统并发数以及响时间的关系理解</h3><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;这篇文件将给大家介绍GC都有哪几种算法，以及JVM都有那些垃圾回收器，它们的工作原理。&lt;/p&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a 
      
    
    </summary>
    
      <category term="java虚拟机" scheme="http://www.fufan.me/categories/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    
      <category term="java虚拟机" scheme="http://www.fufan.me/tags/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>JVM专题（二）——JVM内存模型</title>
    <link href="http://www.fufan.me/2017/11/19/JVM%E4%B8%93%E9%A2%98%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"/>
    <id>http://www.fufan.me/2017/11/19/JVM专题（二）——JVM内存模型/</id>
    <published>2017-11-18T19:30:00.000Z</published>
    <updated>2018-11-08T10:38:30.873Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>所有的Java开发人员可能会遇到这样的困惑？我该为堆内存设置多大空间呢？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域？该怎么解决呢？其实如果你经常解决服务器性能问题，那么这些问题就会变的非常常见，了解JVM内存也是为了服务器出现性能问题的时候可以快速的了解那块的内存区域出现问题，以便于快速的解决生产故障。</p><p>先看一张图，这张图能很清晰的说明JVM内存结构布局。</p><p><img src="/image/jvm-2-0.png" alt=""></p><p>JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配；</p><p>方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。</p><p>在通过一张图来了解如何通过参数来控制各区域的内存大小</p><p><img src="/image/jvm-2-1.png" alt=""></p><p>控制参数</p><ul><li>-Xms设置堆的最小空间大小。</li><li>-Xmx设置堆的最大空间大小。</li><li>-XX:NewSize设置新生代最小空间大小。</li><li>-XX:MaxNewSize设置新生代最大空间大小。</li><li>-XX:PermSize设置永久代最小空间大小。</li><li>-XX:MaxPermSize设置永久代最大空间大小。</li><li>-Xss设置每个线程的堆栈大小。</li></ul><p>没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。</p><p>老年代空间大小=堆空间大小-年轻代大空间大小</p><p>从更高的一个维度再次来看JVM和系统调用之间的关系</p><p><img src="/image/jvm-2-2.png" alt=""></p><p>方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。</p><p>下面我们详细介绍每个区域的作用</p><h3 id="Java堆（Heap）"><a href="#Java堆（Heap）" class="headerlink" title="Java堆（Heap）"></a>Java堆（Heap）</h3><p>对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。</p><p>Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。</p><p>根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。</p><p>如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。</p><h3 id="方法区（Method-Area）"><a href="#方法区（Method-Area）" class="headerlink" title="方法区（Method Area）"></a>方法区（Method Area）</h3><p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。</p><p>对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。</p><p>Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。</p><p>根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。</p><p>方法区有时被称为持久代（PermGen）。</p><p><img src="/image/jvm-2-3.png" alt=""></p><p>所有的对象在实例化后的整个运行周期内，都被存放在堆内存中。堆内存又被划分成不同的部分：伊甸区(Eden)，幸存者区域(Survivor Sapce)，老年代（Old Generation Space）。</p><p>方法的执行都是伴随着线程的。原始类型的本地变量以及引用都存放在线程栈中。而引用关联的对象比如String，都存在在堆中。</p><h3 id="程序计数器（Program-Counter-Register）"><a href="#程序计数器（Program-Counter-Register）" class="headerlink" title="程序计数器（Program Counter Register）"></a>程序计数器（Program Counter Register）</h3><p>程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p><p>由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。</p><p>如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。</p><h3 id="JVM栈（JVM-Stacks）"><a href="#JVM栈（JVM-Stacks）" class="headerlink" title="JVM栈（JVM Stacks）"></a>JVM栈（JVM Stacks）</h3><p>与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p><p>局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。</p><p>其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</p><p>在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。</p><h3 id="本地方法栈（Native-Method-Stacks）"><a href="#本地方法栈（Native-Method-Stacks）" class="headerlink" title="本地方法栈（Native Method Stacks）"></a>本地方法栈（Native Method Stacks）</h3><p>本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。</p><h3 id="哪儿的OutOfMemoryError"><a href="#哪儿的OutOfMemoryError" class="headerlink" title="哪儿的OutOfMemoryError"></a>哪儿的OutOfMemoryError</h3><p>对内存结构清晰的认识同样可以帮助理解不同OutOfMemoryErrors：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space</span><br></pre></td></tr></table></figure><p>原因：对象不能被分配到堆内存中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space</span><br></pre></td></tr></table></figure><p>原因：类或者方法不能被加载到持久代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit</span><br></pre></td></tr></table></figure><p>原因：创建的数组大于堆内存的空间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: request &lt;size&gt; bytes for &lt;reason&gt;. Out of swap space?</span><br></pre></td></tr></table></figure><p>原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: &lt;reason&gt; &lt;stack trace&gt;（Native method）</span><br></pre></td></tr></table></figure><p>原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;所有的Java开发人员可能会遇到这样的困惑？我该为堆内存设置多大空间呢？OutOfMemoryError的异常到底涉及到运行
      
    
    </summary>
    
      <category term="java虚拟机" scheme="http://www.fufan.me/categories/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    
      <category term="java虚拟机" scheme="http://www.fufan.me/tags/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>Java面试总结积累（基础篇）之JVM问题(三)</title>
    <link href="http://www.fufan.me/2017/11/13/Java%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E7%A7%AF%E7%B4%AF%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E4%B9%8BJVM%E9%97%AE%E9%A2%98-%E4%B8%89/"/>
    <id>http://www.fufan.me/2017/11/13/Java面试总结积累（基础篇）之JVM问题-三/</id>
    <published>2017-11-13T11:44:00.000Z</published>
    <updated>2018-11-07T02:01:43.507Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><h3 id="一-垃圾回收算法的实现原理"><a href="#一-垃圾回收算法的实现原理" class="headerlink" title="一. 垃圾回收算法的实现原理"></a>一. 垃圾回收算法的实现原理</h3><p>垃圾回收算法有一下几种：</p><h4 id="1-引用计数法"><a href="#1-引用计数法" class="headerlink" title="1. 引用计数法"></a>1. 引用计数法</h4><p>对于一个A对象，只要有任何一个对象引用了A，则A的引用计算器就加1，当引用失效时，引用计数器减1.只要A的引用计数器值为0，则对象A就不可能再被使用。存在两个问题：1.无法处理循环引用的问题，因此在Java的垃圾回收器中，没有使用该算法；2.伴随一个加法操作和减法操作，对系统性能会有一定的影响。<br><img src="/image/base-jvm-3.png" alt=""></p><h4 id="2-标记清除法"><a href="#2-标记清除法" class="headerlink" title="2. 标记清除法"></a>2. 标记清除法</h4><p>标记清除法是现代垃圾回收算法的思想基础。分为两个阶段：标记阶段和清除阶段。缺点是可能产生的最大的问题就是空间碎片。标记清除算法先通过根节点标记所有可达对象，然后清除所有不可达对象，完成垃圾回收。<br><img src="/image/base-jvm-4.png" alt=""></p><h4 id="3-复制算法"><a href="#3-复制算法" class="headerlink" title="3. 复制算法"></a>3. 复制算法</h4><p>将原有的内存空间分为两块相同的存储空间，每次只使用一块，在垃圾回收时，将正在使用的内存块中存活对象复制到未使用的那一块内存空间中，之后清除正在使用的内存块中的所有对象，完成垃圾回收。在java中的新生代串行垃圾回收器中，使用了复制算法的思想，新生代分为eden空间、from空间和to空间3个部分，其中from和to空间可以看做用于复制的两块大小相同、可互换角色的内存空间块（同一时间只能有一个被当做当前内存空间使用，另一个在垃圾回收时才发挥作用），from和to空间也称为survivor空间，用于存放未被回收的对象。<br><img src="/image/base-jvm-5.png" alt=""></p><p>在java中的新生代串行垃圾回收器中，使用了复制算法的思想，新生代分为eden空间、from空间和to空间3个部分，其中from和to空间可以看做用于复制的两块大小相同、可互换角色的内存空间块（同一时间只能有一个被当做当前内存空间使用，另一个在垃圾回收时才发挥作用），from和to空间也称为survivor空间，用于存放未被回收的对象。<br><img src="/image/base-jvm-6.png" alt=""></p><h4 id="4-标记压缩算法"><a href="#4-标记压缩算法" class="headerlink" title="4. 标记压缩算法"></a>4. 标记压缩算法</h4><p>类似标记清除算法，也是先将可达对象标记，然后扫描的时候，在清除不可达对象之前，先做了一步压缩到内存空间的一端的操作，减少了内存空间中的碎片。这样做避免的碎片的产生，又不需要两块相同的内存空间，因此性价比高。<br><img src="/image/base-jvm-7.png" alt=""></p><h4 id="5-分代算法"><a href="#5-分代算法" class="headerlink" title="5. 分代算法"></a>5. 分代算法</h4><p>将内存空间根据对象的特点不同进行划分，选择合适的垃圾回收算法，以提高垃圾回收的效率。<br><img src="/image/base-jvm-8.png" alt=""></p><p>通常，java虚拟机会将所有的新建对象都放入称为新生代的内存空间。<br>新生代的特点是：对象朝生夕灭，大约90%的对象会很快回收，因此，新生代比较适合使用复制算法。<br>当一个对象经过几次垃圾回收后依然存活，对象就会放入老年代的内存空间，在老年代中，几乎所有的对象都是经过几次垃圾回收后依然得以存活的，因此，认为这些对象在一段时间内，甚至在程序的整个生命周期将是常驻内存的。<br>老年代的存活率是很高的，如果依然使用复制算法回收老年代，将需要复制大量的对象。这种做法是不可取的，根据分代的思想，对老年代的回收使用标记清除或者标记压缩算法可以提高垃圾回收效率。</p><p>分代的思想被现有的虚拟机广泛使用，几乎所有的垃圾回收器都区分新生代和老年代。</p><h4 id="6-分区算法"><a href="#6-分区算法" class="headerlink" title="6. 分区算法"></a>6. 分区算法</h4><p>分区算法将整个堆空间划分为连续的不同小区间。</p><p>每一个小区间都独立使用，独立回收。<br>算法优点是：可以控制一次回收多少个小区间<br>通常，相同的条件下，堆空间越大，一次GC所需的时间就越长，从而产生的停顿时间就越长。为了更好的控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理的回收若干个小区间，而不是整个堆空间，从而减少一个GC的停顿时间。如图所示：<br><img src="/image/base-jvm-9.png" alt=""></p><h3 id="二-当出现了内存溢出，你怎么排错。"><a href="#二-当出现了内存溢出，你怎么排错。" class="headerlink" title="二. 当出现了内存溢出，你怎么排错。"></a>二. 当出现了内存溢出，你怎么排错。</h3><p>内存溢出可能存在的情况</p><ul><li>OOM</li><li>Stack Overflow</li><li>运行时常量池溢出</li><li>方法区溢出</li></ul><h4 id="1-OOM"><a href="#1-OOM" class="headerlink" title="1. OOM"></a>1. OOM</h4><ul><li><p>原因:即堆区溢出，对象过多导致内存疯长，大于预设置的最大堆容量后报出java heap space</p></li><li><p>解决方法:</p><ul><li>1)首先确认是内存泄露(Memory Leak)还是内存溢出(Memory Overflow);</li><li>2)如果是内存泄漏引起的,查看GC Roots引用链,找出为什么无法被垃圾回收的原因;</li><li>3)如果是内存溢出,检查虚拟机的堆参数(-Xmx最大值和-Xms最小值),对比物理内存看是否可以调大;</li><li>4)由于本人在工作中负责过分布式爬虫的项目，发现内存疯长也可能是堆外内存的问题，和并发线程相关。严重的需要使用jheap dump下内存结构进行分析，利用工具jprofile、eclipse等，后续会有专门的专题理一下这一块的处理办法。</li></ul></li></ul><h4 id="2-Stack-Overflow"><a href="#2-Stack-Overflow" class="headerlink" title="2. Stack Overflow"></a>2. Stack Overflow</h4><p>虚拟机栈和本地方法栈溢出</p><ul><li>原因:在单线程下,虚拟机栈容量太小或者定义了大量的本地变量,会抛出SO;</li><li>解决方法:增大虚拟机栈容量，可以通过-Xss参数来设定栈容量;</li></ul><h4 id="3-PermGen-space"><a href="#3-PermGen-space" class="headerlink" title="3. PermGen space"></a>3. PermGen space</h4><ul><li>原因:代码在运行时创建了大量的常量,超出了常量池上限;</li><li>解决方法:通过修改-XX:PermSize和-XX:MaxPermSize参数来修改方法区大小,从而修改常量池大小;</li></ul><h4 id="4-方法区溢出"><a href="#4-方法区溢出" class="headerlink" title="4. 方法区溢出"></a>4. 方法区溢出</h4><ul><li>原因:在运行时,ClassLoader动态加载了大量的Class信息,超出方法区上限;</li><li>解决方法:通过修改-XX:PermSize和-XX:MaxPermSize参数来修改方法区大小;</li></ul><h4 id="下面罗列一些经常用到的jvm参数"><a href="#下面罗列一些经常用到的jvm参数" class="headerlink" title="下面罗列一些经常用到的jvm参数:"></a>下面罗列一些经常用到的jvm参数:</h4><p>用到的JVM启动参数:</p><ul><li>-Xss2M 设置JVM栈内存大小</li><li>-Xms20M 设置堆内存初始值</li><li>-Xmx20M 设置堆内存最大值</li><li>-Xmn10M 设置堆内存中新生代大小</li><li>-XX:SurvivorRatio=8设置堆内存中新生代Eden 和 Survivor 比例</li><li>-XX:PermSize=10M设置方法区内存初始值</li><li>-XX:MaxPermSize=10M设置方法区内存最大值</li></ul><h3 id="三-JVM内存模型的相关知识了解多少，比如重排序，内存屏障，happen-before，主内存，工作内存等。"><a href="#三-JVM内存模型的相关知识了解多少，比如重排序，内存屏障，happen-before，主内存，工作内存等。" class="headerlink" title="三. JVM内存模型的相关知识了解多少，比如重排序，内存屏障，happen-before，主内存，工作内存等。"></a>三. JVM内存模型的相关知识了解多少，比如重排序，内存屏障，happen-before，主内存，工作内存等。</h3><h4 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h4><p>通常是编译器或运行时环境为了优化程序性能而采取的对指令进行重新排序执行的一种手段。重排序分为两类：编译期重排序和运行期重排序，分别对应编译时和运行时环境。</p><h4 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h4><p>（Memory Barrier，或有时叫做内存栅栏，Memory Fence）是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。</p><h4 id="主内存"><a href="#主内存" class="headerlink" title="主内存"></a>主内存</h4><p>存在于主内存中的变量和对象，可以被所有线程共享</p><h4 id="工作内存"><a href="#工作内存" class="headerlink" title="工作内存"></a>工作内存</h4><p>只存在于各个线程中，被线程私有，线程要读取主内存变量时，必须拷贝一份主内存中的到工作内存，不能直接从主内存中读取。不同线程之间无法直接访问其他线程工作内存中的变量，线程间变量值的传递需要通过主内存来完成。</p><h3 id="四-如何实现内存可见性"><a href="#四-如何实现内存可见性" class="headerlink" title="四. 如何实现内存可见性"></a>四. 如何实现内存可见性</h3><p>要实现共享变量的可见性，必须保证两点</p><ul><li>线程修改后的共享变量值能够及时从工作内存中刷新到主内存中</li><li>其他线程能够及时把共享变量的最新值从主内存更新到自己的工作内存中</li></ul><h4 id="synchronized实现可见性"><a href="#synchronized实现可见性" class="headerlink" title="synchronized实现可见性"></a>synchronized实现可见性</h4><ul><li>线程解锁前，必须把共享变量的最新值刷新到主内存中</li><li>线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主存中重新读取最新的值</li></ul><p>线程执行互斥代码的过程</p><ul><li>获得互斥锁</li><li>清空工作内存</li><li>从主内存拷贝变量的最新副本到工作内存</li><li>执行代码</li><li>将更改后的共享变量的值刷新到主内存中</li><li>释放互斥锁</li></ul><h4 id="volatile实现可见性"><a href="#volatile实现可见性" class="headerlink" title="volatile实现可见性"></a>volatile实现可见性</h4><ul><li>能够保证volatile变量的可见性</li><li>不能保证volatile变量复合操作的原子</li></ul><p>原理：</p><ul><li>通过加入内存屏障和禁止重排序优化来实现的（1.在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；2.在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障）<br>通俗的讲：</li><li>volatile变量在每次被线程访问时，都强迫从主内存中重读该变量的值，而当该变量发生变化时，又会强迫将最新的值刷新到主内存。这样任何时刻，不同的线程总能看到该变量的最新值。</li></ul><p>线程写volatile变量的过程：</p><ul><li>改变线程工作内存中volatile变量副本的值</li><li>将改变后的副本的值从工作内存刷新到主内存<br>线程读volatile变量的过程：</li><li>从主内存中读取volatile变量的最新值到线程的工作内存中</li><li>从工作内存中读取volatile变量的副本</li></ul><h4 id="synchronized-vs-volatile"><a href="#synchronized-vs-volatile" class="headerlink" title="synchronized vs volatile"></a>synchronized vs volatile</h4><ul><li>volatile不需要加锁，比synchronized更轻量级，不会阻塞线程</li><li>synchronized既能保证可见性，又能保证原子性，而volatile只能保证可见性，无法保证原子性</li></ul><h3 id="五-简单说说你了解的类加载器，可以打破双亲委派么，怎么打破。"><a href="#五-简单说说你了解的类加载器，可以打破双亲委派么，怎么打破。" class="headerlink" title="五. 简单说说你了解的类加载器，可以打破双亲委派么，怎么打破。"></a>五. 简单说说你了解的类加载器，可以打破双亲委派么，怎么打破。</h3><p>JDK 默认提供了如下几种ClassLoader</p><ul><li>Bootstrp loader</li><li>ExtClassLoader</li><li>AppClassLoader</li></ul><ol><li>为什么要有三个类加载器，一方面是分工，各自负责各自的区块，另一方面为了实现委托模型。</li><li>java采用了委托模型机制，这个机制简单来讲，就是“类装载器有载入类的需求时，会先请示其Parent使用其搜索路径帮忙载入，如果Parent 找不到,那么才由自己依照自己的搜索路径搜索类”</li></ol><h4 id="为什么要使用这种双亲委托模式呢？"><a href="#为什么要使用这种双亲委托模式呢？" class="headerlink" title="为什么要使用这种双亲委托模式呢？"></a>为什么要使用这种双亲委托模式呢？</h4><p>因为这样可以避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次。<br>考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时被加载，所以用户自定义类是无法加载一个自定义的ClassLoader。</p><p>/<em>思考：假如我们自己写了一个java.lang.String的类，我们是否可以替换调JDK本身的类？</em>/<br>答案是否定的。我们不能实现。为什么呢？我看很多网上解释是说双亲委托机制解决这个问题，其实不是非常的准确。因为双亲委托机制是可以打破的，你完全可以自己写一个classLoader来加载自己写的java.lang.String类，但是你会发现也不会加载成功，具体就是因为针对java.*开头的类，jvm的实现中已经保证了必须由bootstrp来加载。</p><h4 id="定义自已的ClassLoader"><a href="#定义自已的ClassLoader" class="headerlink" title="定义自已的ClassLoader"></a>定义自已的ClassLoader</h4><p>既然JVM已经提供了默认的类加载器，为什么还要定义自已的类加载器呢？</p><p>因为Java中提供的默认ClassLoader，只加载指定目录下的jar和class，如果我们想加载其它位置的类或jar时，比如：我要加载网络上的一个class文件，通过动态加载到内存之后，要调用这个类中的方法实现我的业务逻辑。在这样的情况下，默认的ClassLoader就不能满足我们的需求了，所以需要定义自己的ClassLoader。</p><p>定义自已的类加载器分为两步：</p><ol><li><p>继承java.lang.ClassLoader</p></li><li><p>重写父类的findClass方法</p></li></ol><p>读者可能在这里有疑问，父类有那么多方法，为什么偏偏只重写findClass方法？</p><p>因为JDK已经在loadClass方法中帮我们实现了ClassLoader搜索类的算法，当在loadClass方法中搜索不到类时，loadClass方法就会调用findClass方法来搜索类，所以我们只需重写该方法即可。如没有特殊的要求，一般不建议重写loadClass搜索类的算法。</p><h3 id="六-讲讲JAVA的反射机制。"><a href="#六-讲讲JAVA的反射机制。" class="headerlink" title="六. 讲讲JAVA的反射机制。"></a>六. 讲讲JAVA的反射机制。</h3><p>JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法;对于任意一个对象，都能够调用它的任意方法和属性;这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。</p><p>在java中反射是很重要的，在现在的很多框架中也都运用了反射的概念，比如spring中的aop机制就是利用反射原理，动态代理，其实说起动态代理就必须要说反射。在写java我们使用对象的时候一般都是使用new的方式来创建对象，这些将要在程序中使用的对象在编译期间都已经知道了，但是编译期间和运行期间还不一样。假如有类Person，Student类extends了Person（都有空构造函数），Person person=new Stuednt();在编译的时候person是Person类型的，但是在运行的时候确实Student的，有时候我们在程序运行期间根据类去生成相应的对象然后进行一系列的操作，这就是反射，所谓的反射个人理解就是在JVM运行期间通过查找到相应的类，通过类获取其属性以及方法来创造对象。</p><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p><a href="https://www.cnblogs.com/marcotan/p/4256885.html" target="_blank" rel="noopener">jvm参数设置大全</a></p><p><a href="https://blog.csdn.net/linhu007/article/details/48897597" target="_blank" rel="noopener">浅谈CMS垃圾收集器与G1收集器</a></p><p><a href="https://blog.csdn.net/u014421556/article/details/52396706" target="_blank" rel="noopener">JVM的GC策略</a></p><p><a href="https://www.cnblogs.com/yang-hao/p/5939487.html" target="_blank" rel="noopener">java jvm内存管理/gc策略/参数设置</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;一-垃圾回收算法的实现原理&quot;&gt;&lt;a href=&quot;#一-垃圾回收算法的实现原理&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="面试" scheme="http://www.fufan.me/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="jvm" scheme="http://www.fufan.me/tags/jvm/"/>
    
      <category term=" 面试" scheme="http://www.fufan.me/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>Java面试总结积累（基础篇）之JVM问题(二)</title>
    <link href="http://www.fufan.me/2017/11/10/Java%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E7%A7%AF%E7%B4%AF%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E4%B9%8BJVM%E9%97%AE%E9%A2%98-%E4%BA%8C/"/>
    <id>http://www.fufan.me/2017/11/10/Java面试总结积累（基础篇）之JVM问题-二/</id>
    <published>2017-11-10T02:41:00.000Z</published>
    <updated>2018-11-06T11:44:21.407Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><h3 id="一-JVM中一次完整的GC流程是怎样的，对象如何晋升到老年代，说说你知道的几种主要的JVM参数。"><a href="#一-JVM中一次完整的GC流程是怎样的，对象如何晋升到老年代，说说你知道的几种主要的JVM参数。" class="headerlink" title="一. JVM中一次完整的GC流程是怎样的，对象如何晋升到老年代，说说你知道的几种主要的JVM参数。"></a>一. JVM中一次完整的GC流程是怎样的，对象如何晋升到老年代，说说你知道的几种主要的JVM参数。</h3><h4 id="GC流程"><a href="#GC流程" class="headerlink" title="GC流程"></a>GC流程</h4><p><img src="/image/base-jvm-1.jpg" alt=""></p><ol><li>当现在有一个新的对象产生，那么对象一定需要内存空间，于是现在就需要为该对象进行内存空间的申请；</li><li>首先会判断eden是否有内存空间，如果此时有内存空间，则直接将新对象保存在eden；</li><li>但是如果此时eden的内存空间不足，那么会自动执行一个MinorGC操作，将eden的无用内存空间进行清理，清理之后会继续判断eden的内存空间是否充足？如果内存空间充足，则将新的对象直接在eden进行空间分配；</li><li>如果执行了MinorGC之后发现eden的内存依然不足，那么这个时候会进行survivor判断，如果survivor有剩余空间，则将eden的部分活跃对象保存在survivor，那么随后继续判断eden的内存空间是否充足，如果充足，则在eden进行新对象的空间分配；</li><li>如果此时survivor也已经没有内存空间了，则继续判断老年区，如果此时老年区空间充足，则将survivor中的活跃对象保存到老年代，而后survivor就会存现有空余空间，随后eden将活跃对象保存在survivor之中，而后在eden里为新对象开辟空间；</li><li>如果这个时候老年代也满了，那么这个时候将产生M ajor GC（FullGC），进行老年代的内存清理。</li><li>如果老年代执行了Full GC之后发现依然无法进行对象的保存，就会产生OOM异常“OutOfMemoryError”</li></ol><h4 id="jvm参数"><a href="#jvm参数" class="headerlink" title="jvm参数"></a>jvm参数</h4><ol><li>-Xmx3550m：设置JVM最大堆内存为3550M。</li><li>-Xms3550m：设置JVM初始堆内存为3550M。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</li><li>-Xss128k：设置每个线程的栈大小。JDK5.0以后每个线程栈大小为1M，之前每个线程栈大小为256K。应当根据应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。需要注意的是：当这个值被设置的较大（例如&gt;2MB）时将会在很大程度上降低系统的性能。</li><li>-Xmn2g：设置年轻代大小为2G。在整个堆内存大小确定的情况下，增大年轻代将会减小年老代，反之亦然。此值关系到JVM垃圾回收，对系统性能影响较大，官方推荐配置为整个堆大小的3/8。</li><li>-XX:NewSize=1024m：设置年轻代初始值为1024M。</li><li>-XX:MaxNewSize=1024m：设置年轻代最大值为1024M。</li><li>-XX:PermSize=256m：设置持久代初始值为256M。</li><li>-XX:MaxPermSize=256m：设置持久代最大值为256M。</li><li>-XX:NewRatio=4：设置年轻代（包括1个Eden和2个Survivor区）与年老代的比值。表示年轻代比年老代为1:4。</li><li>-XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的比值。表示2个Survivor区（JVM堆内存年轻代中默认有2个大小相等的Survivor区）与1个Eden区的比值为2:4，即1个Survivor区占整个年轻代大小的1/6。</li><li>-XX:MaxTenuringThreshold=7：表示一个对象如果在Survivor区（救助空间）移动了7次还没有被垃圾回收就进入年老代。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代，对于需要大量常驻内存的应用，这样做可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代存活时间，增加对象在年轻代被垃圾回收的概率，减少Full GC的频率，这样做可以在某种程度上提高服务稳定性。</li></ol><p>疑问解答<br>-Xmn，-XX:NewSize/-XX:MaxNewSize，-XX:NewRatio 3组参数都可以影响年轻代的大小，混合使用的情况下，优先级是什么？<br>如下：</p><ul><li>高优先级：-XX:NewSize/-XX:MaxNewSize</li><li>中优先级：-Xmn（默认等效 -Xmn=-XX:NewSize=-XX:MaxNewSize=?）</li><li>低优先级：-XX:NewRatio</li><li>推荐使用-Xmn参数，原因是这个参数简洁，相当于一次设定 NewSize/MaxNewSIze，而且两者相等，适用于生产环境。-Xmn 配合 -Xms/-Xmx，即可将堆内存布局完成。</li><li>-Xmn参数是在JDK 1.4 开始支持。</li></ul><h3 id="二-你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。"><a href="#二-你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。" class="headerlink" title="二. 你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。"></a>二. 你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。</h3><h4 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h4><p>CMS收集器是一种以获取最短回收停顿时间为目标的收集器。基于“标记-清除”算法实现，它的运作过程如下：</p><p>1）初始标记</p><p>2）并发标记</p><p>3）重新标记</p><p>4）并发清除</p><p>初始标记、从新标记这两个步骤仍然需要“stop the world”，初始标记仅仅只是标记一下GC Roots能直接关联到的对象，熟读很快，并发标记阶段就是进行GC Roots Tracing，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生表动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长点，但远比并发标记的时间短。</p><p>CMS是一款优秀的收集器，主要优点：并发收集、低停顿。</p><p>缺点：</p><p>1）CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。</p><p>2）CMS收集器无法处理浮动垃圾，可能会出现“Concurrent Mode Failure（并发模式故障）”失败而导致Full GC产生。</p><p>浮动垃圾：由于CMS并发清理阶段用户线程还在运行着，伴随着程序运行自然就会有新的垃圾不断产生，这部分垃圾出现的标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC中再清理。这些垃圾就是“浮动垃圾”。</p><p>3）CMS是一款“标记–清除”算法实现的收集器，容易出现大量空间碎片。当空间碎片过多，将会给大对象分配带来很大的麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。</p><h4 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h4><p>G1是一款面向服务端应用的垃圾收集器。</p><ul><li>1、并行于并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。</li><li>2、分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。它能够采用不同的方式去处理新创建的对象和已经存活了一段时间，熬过多次GC的旧对象以获取更好的收集效果。</li><li>3、空间整合：与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。</li><li>4、可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1和ＣＭＳ共同的关注点，但Ｇ１除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，</li><li><p>5、G1运作步骤：</p><pre><code>1、初始标记；2、并发标记；3、最终标记；4、筛选回收；</code></pre><p>上面几个步骤的运作过程和CMS有很多相似之处。初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS的值，让下一个阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这一阶段需要停顿线程，但是耗时很短，并发标记阶段是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段时耗时较长，但可与用户程序并发执行。而最终标记阶段则是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remenbered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这一阶段需要停顿线程，但是可并行执行。最后在筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划。</p></li></ul><h3 id="三-GC策略是如何的，有哪些"><a href="#三-GC策略是如何的，有哪些" class="headerlink" title="三. GC策略是如何的，有哪些"></a>三. GC策略是如何的，有哪些</h3><p><img src="/image/base-jvm-1.jpg" alt=""></p><h4 id="New-Generation的GC策略"><a href="#New-Generation的GC策略" class="headerlink" title="New Generation的GC策略"></a>New Generation的GC策略</h4><ol><li>Serial GC。采用单线程方式，用Copying算法。到这里我们再来说说为什么New Generation会再次被划分成Eden Space和S0、S1，相信聪明的你一定已经想到Copying算法所需要的额外内存空间了吧，S0和S1又称为From Space和To Space。具体细节自己好好想想。</li><li>Parallel Scavenge。将内存空间分段来使用多线程，也是用Copying算法。</li><li>ParNew。比Parallel Scavenge多做了与Old Generation使用CMS GC一起发生时的特殊处理。</li></ol><h4 id="Old-Generation的GC策略"><a href="#Old-Generation的GC策略" class="headerlink" title="Old Generation的GC策略"></a>Old Generation的GC策略</h4><ol><li>Serial GC。当然也是单线程方式，但是实现是将Mark-Sweep和Mark-Compact结合了下，做了点改进。</li><li>Parallel Mark-Sweep、Parallel Mark-Compact。同样也是把Old Generation空间进行划分成regions，只是粒度更细了。为什么用这两个算法，不用我赘述了吧。</li><li>CMS（Concurrent Mark-Sweep） GC。我承认这个GC我真的没怎么看懂，目的是为了实现并发，结果就造成具体实现太麻烦了。有兴趣的朋友去看书吧，文末我说了是哪本书。这里有个地方可以说一下，就是算法使用的还是Mark-Sweep，对于内存碎片的问题，CMS提供了一个内存碎片的整理功能，会在执行几次Full GC以后执行一次。</li></ol><h3 id="4-JVM的垃圾收集器"><a href="#4-JVM的垃圾收集器" class="headerlink" title="4. JVM的垃圾收集器"></a>4. JVM的垃圾收集器</h3><p>JVM给出了3种选择：串行收集器、并行收集器、并发收集器。串行收集器只适用于小数据量的情况，所以生产环境的选择主要是并行收集器和并发收集器。</p><p>默认情况下JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行智能判断。</p><h4 id="串行收集器"><a href="#串行收集器" class="headerlink" title="串行收集器"></a>串行收集器</h4><p>-XX:+UseSerialGC：设置串行收集器。</p><h4 id="并行收集器（吞吐量优先）"><a href="#并行收集器（吞吐量优先）" class="headerlink" title="并行收集器（吞吐量优先）"></a>并行收集器（吞吐量优先）</h4><ol><li>-XX:+UseParallelGC：设置为并行收集器。此配置仅对年轻代有效。即年轻代使用并行收集，而年老代仍使用串行收集。</li><li>-XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时有多少个线程一起进行垃圾回收。此值建议配置与CPU数目相等。</li><li>-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0开始支持对年老代并行收集。</li><li>-XX:MaxGCPauseMillis=100：设置每次年轻代垃圾回收的最长时间（单位毫秒）。如果无法满足此时间，JVM会自动调整年轻代大小，以满足此时间。</li><li>-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动调整年轻代Eden区大小和Survivor区大小的比例，以达成目标系统规定的最低响应时间或者收集频率等指标。此参数建议在使用并行收集器时，一直打开。</li></ol><h4 id="并发收集器（响应时间优先）"><a href="#并发收集器（响应时间优先）" class="headerlink" title="并发收集器（响应时间优先）"></a>并发收集器（响应时间优先）</h4><ol><li>XX:+UseConcMarkSweepGC：即CMS收集，设置年老代为并发收集。CMS收集是JDK1.4后期版本开始引入的新GC算法。它的主要适合场景是对响应时间的重要性需求大于对吞吐量的需求，能够承受垃圾回收线程和应用线程共享CPU资源，并且应用中存在比较多的长生命周期对象。CMS收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存。</li><li>-XX:+UseParNewGC：设置年轻代为并发收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此参数。</li><li>-XX:CMSFullGCsBeforeCompaction=0：由于并发收集器不对内存空间进行压缩和整理，所以运行一段时间并行收集以后会产生内存碎片，内存使用效率降低。此参数设置运行0次Full GC后对内存空间进行压缩和整理，即每次Full GC后立刻开始压缩和整理内存。</li><li>-XX:+UseCMSCompactAtFullCollection：打开内存空间的压缩和整理，在Full GC后执行。可能会影响性能，但可以消除内存碎片。</li><li>-XX:+CMSIncrementalMode：设置为增量收集模式。一般适用于单CPU情况。</li><li>-XX:CMSInitiatingOccupancyFraction=70：表示年老代内存空间使用到70%时就开始执行CMS收集，以确保年老代有足够的空间接纳来自年轻代的对象，避免Full GC的发生。</li></ol><h4 id="其它垃圾回收参数"><a href="#其它垃圾回收参数" class="headerlink" title="其它垃圾回收参数"></a>其它垃圾回收参数</h4><ol><li>-XX:+ScavengeBeforeFullGC：年轻代GC优于Full GC执行。</li><li>-XX:-DisableExplicitGC：不响应 System.gc() 代码。</li><li>-XX:+UseThreadPriorities：启用本地线程优先级API。即使 java.lang.Thread.setPriority() 生效，不启用则无效。</li><li>-XX:SoftRefLRUPolicyMSPerMB=0：软引用对象在最后一次被访问后能存活0毫秒（JVM默认为1000毫秒）。</li><li>-XX:TargetSurvivorRatio=90：允许90%的Survivor区被占用（JVM默认为50%）。提高对于Survivor区的使用率。</li></ol><h4 id="辅助信息参数设置"><a href="#辅助信息参数设置" class="headerlink" title="辅助信息参数设置"></a>辅助信息参数设置</h4><ol><li>-XX:-CITime：打印消耗在JIT编译的时间。</li><li>-XX:ErrorFile=./hs_err_pid.log：保存错误日志或数据到指定文件中。</li><li>-XX:HeapDumpPath=./java_pid.hprof：指定Dump堆内存时的路径。</li><li>-XX:-HeapDumpOnOutOfMemoryError：当首次遭遇内存溢出时Dump出此时的堆内存。</li><li>-XX:OnError=”;”：出现致命ERROR后运行自定义命令。</li><li>-XX:OnOutOfMemoryError=”;”：当首次遭遇内存溢出时执行自定义命令。</li><li>-XX:-PrintClassHistogram：按下 Ctrl+Break 后打印堆内存中类实例的柱状信息，同JDK的 jmap -histo 命令。</li><li>-XX:-PrintConcurrentLocks：按下 Ctrl+Break 后打印线程栈中并发锁的相关信息，同JDK的 jstack -l 命令。</li><li>-XX:-PrintCompilation：当一个方法被编译时打印相关信息。</li><li>-XX:-PrintGC：每次GC时打印相关信息。</li><li>-XX:-PrintGCDetails：每次GC时打印详细信息。</li><li>-XX:-PrintGCTimeStamps：打印每次GC的时间戳。</li><li>-XX:-TraceClassLoading：跟踪类的加载信息。</li><li>-XX:-TraceClassLoadingPreorder：跟踪被引用到的所有类的加载信息。</li><li>-XX:-TraceClassResolution：跟踪常量池。</li><li>-XX:-TraceClassUnloading：跟踪类的卸载信息。</li></ol><h4 id="调优实战"><a href="#调优实战" class="headerlink" title="调优实战"></a>调优实战</h4><h5 id="1-大型网站服务器案例"><a href="#1-大型网站服务器案例" class="headerlink" title="1. 大型网站服务器案例"></a>1. 大型网站服务器案例</h5><p>承受海量访问的动态Web应用<br>服务器配置：8 CPU, 8G MEM, JDK 1.6.X</p><ol><li><p>参数方案：<br>-server -Xmx3550m -Xms3550m -Xmn1256m -Xss128k -XX:SurvivorRatio=6 -XX:MaxPermSize=256m -XX:ParallelGCThreads=8 -XX:MaxTenuringThreshold=0 -XX:+UseConcMarkSweepGC</p></li><li><p>调优说明：</p></li></ol><ul><li>-Xmx 与 -Xms 相同以避免JVM反复重新申请内存。-Xmx 的大小约等于系统内存大小的一半，即充分利用系统资源，又给予系统安全运行的空间。</li><li>-Xmn1256m 设置年轻代大小为1256MB。此值对系统性能影响较大，Sun官方推荐配置年轻代大小为整个堆的3/8。</li><li>-Xss128k 设置较小的线程栈以支持创建更多的线程，支持海量访问，并提升系统性能。</li><li>-XX:SurvivorRatio=6 设置年轻代中Eden区与Survivor区的比值。系统默认是8，根据经验设置为6，则2个Survivor区与1个Eden区的比值为2:6，一个Survivor区占整个年轻代的1/8。</li><li>-XX:ParallelGCThreads=8 配置并行收集器的线程数，即同时8个线程一起进行垃圾回收。此值一般配置为与CPU数目相等。</li><li>-XX:MaxTenuringThreshold=0 设置垃圾最大年龄（在年轻代的存活次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率；如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率。根据被海量访问的动态Web应用之特点，其内存要么被缓存起来以减少直接访问DB，要么被快速回收以支持高并发海量请求，因此其内存对象在年轻代存活多次意义不大，可以直接进入年老代，根据实际应用效果，在这里设置此值为0。</li><li>-XX:+UseConcMarkSweepGC 设置年老代为并发收集。CMS（ConcMarkSweepGC）收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存，适用于应用中存在比较多的长生命周期对象的情况。</li></ul><h5 id="内部集成构建服务器案例"><a href="#内部集成构建服务器案例" class="headerlink" title="内部集成构建服务器案例"></a>内部集成构建服务器案例</h5><p>高性能数据处理的工具应用<br>服务器配置：1 CPU, 4G MEM, JDK 1.6.X</p><ol><li>参数方案：<br>-server -XX:PermSize=196m -XX:MaxPermSize=196m -Xmn320m -Xms768m -Xmx1024m</li><li>调优说明：</li></ol><ul><li>-XX:PermSize=196m -XX:MaxPermSize=196m 根据集成构建的特点，大规模的系统编译可能需要加载大量的Java类到内存中，所以预先分配好大量的持久代内存是高效和必要的。</li><li>-Xmn320m 遵循年轻代大小为整个堆的3/8原则。</li><li>-Xms768m -Xmx1024m 根据系统大致能够承受的堆内存大小设置即可。</li></ul><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p><a href="https://www.cnblogs.com/marcotan/p/4256885.html" target="_blank" rel="noopener">jvm参数设置大全</a></p><p><a href="https://blog.csdn.net/linhu007/article/details/48897597" target="_blank" rel="noopener">浅谈CMS垃圾收集器与G1收集器</a></p><p><a href="https://blog.csdn.net/u014421556/article/details/52396706" target="_blank" rel="noopener">JVM的GC策略</a></p><p><a href="https://www.cnblogs.com/yang-hao/p/5939487.html" target="_blank" rel="noopener">java jvm内存管理/gc策略/参数设置</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;一-JVM中一次完整的GC流程是怎样的，对象如何晋升到老年代，说说你知道的几种主要的JVM参数。&quot;&gt;&lt;a href
      
    
    </summary>
    
      <category term="面试" scheme="http://www.fufan.me/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://www.fufan.me/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="jvm" scheme="http://www.fufan.me/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>Java面试总结积累（基础篇）之JVM问题(一)</title>
    <link href="http://www.fufan.me/2017/11/06/Java%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E7%A7%AF%E7%B4%AF%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E4%B9%8BJVM%E9%97%AE%E9%A2%98-%E4%B8%80/"/>
    <id>http://www.fufan.me/2017/11/06/Java面试总结积累（基础篇）之JVM问题-一/</id>
    <published>2017-11-06T11:36:00.000Z</published>
    <updated>2018-11-06T11:41:23.861Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><h3 id="一-什么情况下会发生栈内存溢出。"><a href="#一-什么情况下会发生栈内存溢出。" class="headerlink" title="一. 什么情况下会发生栈内存溢出。"></a>一. 什么情况下会发生栈内存溢出。</h3><p>栈溢出(StackOverflowError)</p><h4 id="原因："><a href="#原因：" class="headerlink" title="原因："></a>原因：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">栈是每个线程私有的，他的生命周期与线程相同，每个方法在执行的时候都会创建一个栈帧，用来存储局部变量表，操作数栈，动态链接，方法出口灯信息。局部变量表又包含基本数据类型，对象引用类型（局部变量表编译器完成，运行期间不会变化）</span><br><span class="line">所以我们可以理解为栈溢出就是方法执行是创建的栈帧超过了栈的深度。</span><br></pre></td></tr></table></figure><h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我们需要使用参数 -Xss 去调整JVM栈的大小</span><br></pre></td></tr></table></figure><h3 id="二-什么情况下会发生堆内存溢出。"><a href="#二-什么情况下会发生堆内存溢出。" class="headerlink" title="二. 什么情况下会发生堆内存溢出。"></a>二. 什么情况下会发生堆内存溢出。</h3><p>堆溢出(OutOfMemoryError:java heap space)</p><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heap space表示堆空间，堆中主要存储的是对象。如果不断的new对象则会导致堆中的空间溢出</span><br></pre></td></tr></table></figure><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可以通过 -Xmx4096M 调整堆的总大小</span><br></pre></td></tr></table></figure><h3 id="三-JVM的内存结构，Eden和Survivor比例。"><a href="#三-JVM的内存结构，Eden和Survivor比例。" class="headerlink" title="三. JVM的内存结构，Eden和Survivor比例。"></a>三. JVM的内存结构，Eden和Survivor比例。</h3><h4 id="JVM的内存结构"><a href="#JVM的内存结构" class="headerlink" title="JVM的内存结构"></a>JVM的内存结构</h4><p>jvm将管理的内存中分几块，方法区、堆、虚拟机栈、本地方法栈、程序计数器、运行时常量池</p><ol><li>线程私有的块有：虚拟机栈、本地方法栈、程序计数器</li><li>线程共享的块有：方法区、堆、运行时常量池</li></ol><ul><li>方法区：它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据非堆数据<br>堆：heap是java虚拟机所管理内存中最大的一块，我们创建的对象实例都是存储在这里，它也是垃圾回收的主要区域。现在垃圾回收的算法基本用的是分代收集，虚拟机将其分为新生代和老年代，新生代分为eden和survivor，survivor还可以分为from和to，我们可以通过设置jvm参数的方式来对其进行比例分配。我们也可以通过-Xmx和-Xms控制堆的最大和初始化值，一般将其设置为相同的值，避免其重新进行分配，提高性能。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。分配和回收内容请看jvm系列中的blog。</li><li>运行时常量池：运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述等信息外，还有一项信息是常量池（Constant PoolTable），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。</li><li>虚拟机栈：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。线程可以通过访问对象的引用找到访问堆中的对象。有两种情况会抛出异常，一是单个线程的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；如果虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出OutOfMemoryError 异常。</li><li>本地方法栈：本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java 方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native 方法服务。其他同虚拟机栈原理类似。</li><li>程序计数器：程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。</li></ul><h4 id="Eden和Survivor比例"><a href="#Eden和Survivor比例" class="headerlink" title="Eden和Survivor比例"></a>Eden和Survivor比例</h4><p>-XX:NewSize和-XX:MaxNewSize：用于设置年轻代的大小，建议设为整个堆大小的1/3或者1/4,两个值设为一样大。<br>-XX:SurvivorRatio：用于设置Eden和其中一个Survivor的比值，这个值也比较重要。<br>XX:+PrintTenuringDistribution：这个参数用于显示每次Minor GC时Survivor区中各个年龄段的对象的大小。<br>.-XX:InitialTenuringThreshol和-XX:MaxTenuringThreshold</p><h4 id="JVM内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为Eden和Survivor。"><a href="#JVM内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为Eden和Survivor。" class="headerlink" title="JVM内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为Eden和Survivor。"></a>JVM内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为Eden和Survivor。</h4><p>为什么需要把堆分代？不分代不能完成他所做的事情么？其实不分代完全可以，分代的唯一理由就是优化GC性能。你先想想，如果没有分代，那我们所有的对象都在一块，GC的时候我们要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而我们的很多对象都是朝生夕死的，如果分代的话，我们把新创建的对象放到某一地方，当GC的时候先把这块存“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。</p><h5 id="新生代："><a href="#新生代：" class="headerlink" title="新生代："></a>新生代：</h5><ul><li>大多数新生的对象在Eden区分配，当Eden区没有足够空间进行分配时，虚拟机就会进行一次MinorGC。</li><li>在方法中new一个对象，方法调用完毕，对象就无用，这就是典型的新生代对象。（新生对象在Eden区经历过一次MinorGC并且被Survivor容纳的话，对象年龄为1，并且每熬过一次MinorGC，年龄就会加1，直到15，就会晋升到老年代）</li><li>注意动态对象的判定：Survivor空间中相同年龄的对象大小总和大于Survivor空间的一半，大于或者等于该年龄的对象就可以直接进入老年代。</li></ul><h5 id="老年代："><a href="#老年代：" class="headerlink" title="老年代："></a>老年代：</h5><ul><li>在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到老年代中，而且大对象（占用大量连续内存空间的java对象如很长的字符串及数组）直接进入老年代。</li><li>当survivor空间不够用时，需要依赖老年代进行分配担保。</li></ul><h5 id="永久代"><a href="#永久代" class="headerlink" title="永久代"></a>永久代</h5><ul><li>方法区</li><li>主要存放Class和Meta的信息，Class在被加载的时候被放入永久代。 它和存放对象的堆区域不同，GC(Garbage Collection)不会在主程序运行期对永久代进行清理，所以如果你的应用程序会加载很多Class的话,就很可能出现PermGen space错误。</li></ul><h5 id="GC分类"><a href="#GC分类" class="headerlink" title="GC分类"></a>GC分类</h5><ol><li>MinorGC：是指清理新生代</li><li>MajorGC：是指清理老年代（很多MajorGC是由MinorGC触发的）</li><li>FullGC：是指清理整个堆空间包括年轻代和永久代</li></ol><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p><a href="https://www.cnblogs.com/marcotan/p/4256885.html" target="_blank" rel="noopener">jvm参数设置大全</a></p><p><a href="https://blog.csdn.net/linhu007/article/details/48897597" target="_blank" rel="noopener">浅谈CMS垃圾收集器与G1收集器</a></p><p><a href="https://blog.csdn.net/u014421556/article/details/52396706" target="_blank" rel="noopener">JVM的GC策略</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;一-什么情况下会发生栈内存溢出。&quot;&gt;&lt;a href=&quot;#一-什么情况下会发生栈内存溢出。&quot; class=&quot;head
      
    
    </summary>
    
      <category term="面试" scheme="http://www.fufan.me/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://www.fufan.me/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="jvm" scheme="http://www.fufan.me/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>JVM专题之jvm知识点总览</title>
    <link href="http://www.fufan.me/2017/10/31/JVM%E4%B8%93%E9%A2%98%E4%B9%8Bjvm%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E8%A7%88/"/>
    <id>http://www.fufan.me/2017/10/31/JVM专题之jvm知识点总览/</id>
    <published>2017-10-31T02:20:00.000Z</published>
    <updated>2018-11-07T02:20:37.232Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>jvm体系总体分四大块：</p><ul><li>类的加载机制</li><li>jvm内存结构</li><li>GC算法 垃圾回收</li><li>GC分析 命令调优</li></ul><h3 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h3><p>主要关注点：</p><ol><li>什么是类的加载</li><li>类的生命周期</li><li>类加载器</li><li>双亲委派模型</li></ol><h4 id="什么是类的加载"><a href="#什么是类的加载" class="headerlink" title="什么是类的加载"></a>什么是类的加载</h4><p>类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。</p><h4 id="类的生命周期"><a href="#类的生命周期" class="headerlink" title="类的生命周期"></a>类的生命周期</h4><p>类的生命周期包括这几个部分，加载、连接、初始化、使用和卸载，其中前三部是类的加载的过程,如下图；</p><p><img src="/image/jvm-0-0.png" alt=""></p><ol><li>加载，查找并加载类的二进制数据，在Java堆中也创建一个java.lang.Class类的对象</li><li>连接，连接又包含三块内容：验证、准备、初始化。1）验证，文件格式、元数据、字节码、符号引用验证；2）准备，为类的静态变量分配内存，并将其初始化为默认值；3）解析，把类中的符号引用转换为直接引用</li><li>初始化，为类的静态变量赋予正确的初始值</li><li>使用，new出对象程序中使用</li><li>卸载，执行垃圾回收</li></ol><h4 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h4><p><img src="/image/jvm-0-1.png" alt=""></p><ul><li>启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库</li><li>扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载DK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。</li><li>应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器</li></ul><h4 id="类加载机制-1"><a href="#类加载机制-1" class="headerlink" title="类加载机制"></a>类加载机制</h4><ul><li>全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入</li><li>父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类</li><li>缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效</li></ul><h3 id="jvm内存结构"><a href="#jvm内存结构" class="headerlink" title="jvm内存结构"></a>jvm内存结构</h3><p>主要关注点：</p><ul><li>jvm内存结构都是什么</li><li>对象分配规则</li></ul><h4 id="jvm内存结构-1"><a href="#jvm内存结构-1" class="headerlink" title="jvm内存结构"></a>jvm内存结构</h4><p><img src="/image/jvm-0-2.png" alt=""></p><p>方法区和堆是所有线程共享的内存区域；而java栈、本地方法栈和程序计数器是运行是线程私有的内存区域。</p><ul><li>Java堆（Heap）,是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。</li><li>方法区（Method Area）,方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。</li><li>程序计数器（Program Counter Register）,程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。</li><li>JVM栈（JVM Stacks）,与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</li><li>本地方法栈（Native Method Stacks）,本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。</li></ul><h4 id="对象分配规则"><a href="#对象分配规则" class="headerlink" title="对象分配规则"></a>对象分配规则</h4><ul><li>对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。</li><li>大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。</li><li>长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，知道达到阀值对象进入老年区。</li><li>动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。</li><li>空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。</li></ul><h3 id="GC算法-垃圾回收"><a href="#GC算法-垃圾回收" class="headerlink" title="GC算法 垃圾回收"></a>GC算法 垃圾回收</h3><p>主要关注点：</p><ul><li>对象存活判断</li><li>GC算法</li><li>垃圾回收器</li></ul><h4 id="对象存活判断"><a href="#对象存活判断" class="headerlink" title="对象存活判断"></a>对象存活判断</h4><p>判断对象是否存活一般有两种方式：</p><ul><li>引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。</li><li>可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的，不可达对象。</li></ul><h4 id="GC算法"><a href="#GC算法" class="headerlink" title="GC算法"></a>GC算法</h4><p>GC最基础的算法有三种：标记 -清除算法、复制算法、标记-压缩算法，我们常用的垃圾回收器一般都采用分代收集算法。</p><ul><li>标记 -清除算法，“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。</li><li>复制算法，“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。</li><li>标记-压缩算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存</li><li>分代收集算法，“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。</li></ul><h4 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h4><ul><li>Serial收集器，串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。</li><li>ParNew收集器，ParNew收集器其实就是Serial收集器的多线程版本。</li><li>Parallel收集器，Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。</li><li>Parallel Old 收集器，Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法</li><li>CMS收集器，CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。</li><li>G1收集器，G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征</li><li></li></ul><h3 id="GC分析-命令调优"><a href="#GC分析-命令调优" class="headerlink" title="GC分析 命令调优"></a>GC分析 命令调优</h3><p>主要关注点：</p><ul><li>GC日志分析</li><li>调优命令</li><li>调优工具</li></ul><h4 id="GC日志分析"><a href="#GC日志分析" class="headerlink" title="GC日志分析"></a>GC日志分析</h4><p>Young GC日志:</p><p>Full GC日志:</p><h4 id="调优命令"><a href="#调优命令" class="headerlink" title="调优命令"></a>调优命令</h4><p>Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo</p><ul><li>jps，JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。</li><li>jstat，JVM statistics Monitoring是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。</li><li>jmap，JVM Memory Map命令用于生成heap dump文件</li><li>jhat，JVM Heap Analysis Tool命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看</li><li>jstack，用于生成java虚拟机当前时刻的线程快照。</li><li>jinfo，JVM Configuration info 这个命令作用是实时查看和调整虚拟机运行参数。</li></ul><h4 id="调优工具"><a href="#调优工具" class="headerlink" title="调优工具"></a>调优工具</h4><p>常用调优工具分为两类,jdk自带监控工具：jconsole和jvisualvm，第三方有：MAT(Memory Analyzer Tool)、GChisto。</p><ul><li>jconsole，Java Monitoring and Management Console是从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控</li><li>jvisualvm，jdk自带全能工具，可以分析内存快照、线程快照；监控内存变化、GC变化等。</li><li>MAT，Memory Analyzer Tool，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗</li><li>GChisto，一款专业分析gc日志的工具</li><li>jprofile</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;jvm体系总体分四大块：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;类的加载机制&lt;/li&gt;&lt;li&gt;jvm内存结构&lt;/li&gt;&lt;li&gt;GC算法 垃圾
      
    
    </summary>
    
      <category term="java虚拟机" scheme="http://www.fufan.me/categories/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    
      <category term="java虚拟机" scheme="http://www.fufan.me/tags/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>JVM专题（绪论）</title>
    <link href="http://www.fufan.me/2017/10/26/JVM%E7%B3%BB%E5%88%97%EF%BC%88%E7%BB%AA%E8%AE%BA%EF%BC%89/"/>
    <id>http://www.fufan.me/2017/10/26/JVM系列（绪论）/</id>
    <published>2017-10-26T02:17:00.000Z</published>
    <updated>2018-11-07T02:30:53.357Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>作为一个合格的java程序员，对于jvm的熟悉使用是非常有必要的，这个系列将会介绍我们常用jvm的一些原理和常用命令，以及常见的问题的排查及处理。</p><p>由于最近工作需要，顺便整理和学习一下jvm的相关知识，自己工作中遇到的问题，同时借鉴网上一些资料和博客，理一下这部分知识。</p><h3 id="博文目录"><a href="#博文目录" class="headerlink" title="博文目录"></a>博文目录</h3><p>JVM专题之jvm知识点总览</p><p>JVM专题（一）——类加载机制</p><p>JVM专题（二）——JVM内存模型</p><p>JVM专题（三）——GC算法 垃圾收集器</p><p>JVM专题（四）——jvm调优-命令篇</p><p>JVM专题（五）——Java GC 分析</p><p>JVM专题（六）——Java服务GC参数调优案例</p><p>JVM专题（七）——jvm调优-工具篇</p><h2 id="博文参考"><a href="#博文参考" class="headerlink" title="博文参考"></a>博文参考</h2><p><a href="http://www.ityouknow.com/java/2017/03/01/jvm-overview.html" target="_blank" rel="noopener">jvm知识点总览</a></p><p>感谢博客作者的分享，受益匪浅，已吸收。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;作为一个合格的java程序员，对于jvm的熟悉使用是非常有必要的，这个系列将会介绍我们常用jvm的一些原理和常用命令，以及常
      
    
    </summary>
    
      <category term="java虚拟机" scheme="http://www.fufan.me/categories/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    
      <category term="java虚拟机" scheme="http://www.fufan.me/tags/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>常用的vim命令整理（持续更新）</title>
    <link href="http://www.fufan.me/2017/10/02/%E5%B8%B8%E7%94%A8%E7%9A%84vim%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
    <id>http://www.fufan.me/2017/10/02/常用的vim命令整理（持续更新）/</id>
    <published>2017-10-02T12:58:00.000Z</published>
    <updated>2018-11-04T14:46:09.403Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><h2 id="1-插入模式-command-mode"><a href="#1-插入模式-command-mode" class="headerlink" title="1. 插入模式 (command mode)"></a>1. 插入模式 (command mode)</h2><p>命令模式切换至插入状态</p><ul><li>i光标前插入</li><li>I行首插入</li><li>a光标后插入</li><li>A行尾插入</li><li>o行上新行</li><li>O行下新行</li></ul><h2 id="2-命令模式-insert-mode"><a href="#2-命令模式-insert-mode" class="headerlink" title="2. 命令模式 (insert mode)"></a>2. 命令模式 (insert mode)</h2><p>ESC从插入状态切换至命令模式</p><h3 id="光标移动"><a href="#光标移动" class="headerlink" title="光标移动"></a>光标移动</h3><ul><li>h左移</li><li>j下移</li><li>k上移</li><li>l右移</li><li>H到屏幕顶部</li><li>M到屏幕中央</li><li>L到屏幕底部</li><li>0到行首</li><li>$到行尾</li><li>Ctrl+f向前翻屏</li><li>Ctrl+b向后翻屏</li><li>Ctrl+d向前翻半屏</li><li>Ctrl+u向后翻半屏</li></ul><h3 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h3><ul><li>gg回到文件首行,</li><li>G回到文件尾行</li><li>:n和nG光标定位到文件第n行(:20或20G表示光标定位到第20行)</li><li>:set nu 或:set number显示行号,</li><li>:set nonu 取消显示行号</li><li>ctrl+g</li></ul><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><ul><li>x删除光标所在字符(与Delete键相同的方向),</li><li>X删除光标所在字符(与Backspace键相同的方向)</li><li>nx删除光标后n个字符</li><li>dd删除光标所在行</li><li>ndd删除光标所在行以后的n行</li><li>D删除光标到行尾的内容</li><li>dG删除光标所在行到文件末尾的内容</li><li>n1,n2d删除行n1到行n2的内容，包括第n1和n2行都被删除</li><li>s删除一个字符来插入模式</li><li>S删除当前行以插入模式</li></ul><h3 id="复制、剪切、粘贴、替换"><a href="#复制、剪切、粘贴、替换" class="headerlink" title="复制、剪切、粘贴、替换"></a>复制、剪切、粘贴、替换</h3><ul><li>yy或Y复制当前行</li><li>nyy或nY从当前行开始赋值n行</li><li>ggVG全选</li><li>剪切使用dd和ndd，相当于删除</li><li>p在光标所在行之后粘贴</li><li>P在光标所在行之前粘贴</li><li>r替换当前字符后回到命令模式</li><li>R一直替换知道通过ESC回到命令模式</li></ul><h3 id="查找、替换"><a href="#查找、替换" class="headerlink" title="查找、替换"></a>查找、替换</h3><ul><li>\KeyWord回车，n查找下一处</li><li>?KeyWord回车，n查找上一处</li><li>n重复相同方向</li><li>N重复反向方向·</li><li>:s/old/new/g替换整个文件，不确认</li><li>:s/old/new/gc替换整个文件，确认</li><li>:n1,n2s/old/new/g替换n1-n2行中匹配内容，不确认</li></ul><h3 id="撤销"><a href="#撤销" class="headerlink" title="撤销"></a>撤销</h3><p>u</p><h3 id="保存及离开"><a href="#保存及离开" class="headerlink" title="保存及离开"></a>保存及离开</h3><ul><li>:w保存文件</li><li>:w!强制保存</li><li>:w file将修改另外保存到file</li><li>:wq保存文件并退出</li><li>:wq!强制保存文件并退出</li><li>:q不保存退出</li><li>:q!不保存强制退出</li><li>:e!放弃所有修改，从上次保存文件开始再编辑</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;h2 id=&quot;1-插入模式-command-mode&quot;&gt;&lt;a href=&quot;#1-插入模式-command-mode&quot; class
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ssh免密码登录步骤及别名设置</title>
    <link href="http://www.fufan.me/2017/10/02/ssh%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E6%AD%A5%E9%AA%A4%E5%8F%8A%E5%88%AB%E5%90%8D%E8%AE%BE%E7%BD%AE/"/>
    <id>http://www.fufan.me/2017/10/02/ssh免密码登录步骤及别名设置/</id>
    <published>2017-10-02T05:23:00.000Z</published>
    <updated>2018-11-04T14:45:55.388Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><h2 id="ssh免密码登录步骤及别名设置"><a href="#ssh免密码登录步骤及别名设置" class="headerlink" title="ssh免密码登录步骤及别名设置"></a>ssh免密码登录步骤及别名设置</h2><h5 id="1-生成本机的公私钥"><a href="#1-生成本机的公私钥" class="headerlink" title="1. 生成本机的公私钥"></a>1. 生成本机的公私钥</h5><p><code>ssh-keygen -t rsa</code></p><h5 id="2-将公钥复制到目标机器上"><a href="#2-将公钥复制到目标机器上" class="headerlink" title="2. 将公钥复制到目标机器上"></a>2. 将公钥复制到目标机器上</h5><p><code>ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.100</code></p><h5 id="3-设置别名登录"><a href="#3-设置别名登录" class="headerlink" title="3. 设置别名登录"></a>3. 设置别名登录</h5><p><code>vim ~/.ssh/config</code></p><p>添加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Host 100</span><br><span class="line">HostName 192.168.0.100</span><br><span class="line">Port 22</span><br><span class="line">User root</span><br><span class="line">IdentityFile ~/.ssh/id_rsa.pub</span><br><span class="line">IdentitiesOnly yes</span><br></pre></td></tr></table></figure><h5 id="4-登录"><a href="#4-登录" class="headerlink" title="4. 登录"></a>4. 登录</h5><p><code>ssh 100</code></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;h2 id=&quot;ssh免密码登录步骤及别名设置&quot;&gt;&lt;a href=&quot;#ssh免密码登录步骤及别名设置&quot; class=&quot;header
      
    
    </summary>
    
      <category term="linux" scheme="http://www.fufan.me/categories/linux/"/>
    
    
      <category term="linux" scheme="http://www.fufan.me/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>java加密算法基础</title>
    <link href="http://www.fufan.me/2017/06/23/java%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    <id>http://www.fufan.me/2017/06/23/java加密算法基础/</id>
    <published>2017-06-23T13:10:00.000Z</published>
    <updated>2018-11-06T15:54:55.766Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>机密算法分类，基础加密算法基本有四种：</p><ol><li>Base64</li><li>Md5</li><li>Sha</li><li>HMAC</li></ol><p>复杂加密有两种：</p><ol><li>对称加密</li><li>非对称加密</li></ol><h2 id="基础加密"><a href="#基础加密" class="headerlink" title="基础加密"></a>基础加密</h2><h3 id="Base64"><a href="#Base64" class="headerlink" title="Base64"></a>Base64</h3><p>按 照RFC2045的定义，Base64被定义为：Base64内容传送编码被设计用来把任意序列的8位字节描述为一种不易被人直接识别的形式。（The Base64 Content-Transfer-Encoding is designed to represent arbitrary sequences of octets in a form that need not be humanly readable.）<br>常见于邮件、http加密，截取http信息，你就会发现登录操作的用户名、密码字段通过BASE64加密的。</p><p><img src="/image/encrypt-0.jpg" alt=""></p><p>java代码如下：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">     * BASE64解密 </span></span><br><span class="line"><span class="comment">     *  </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] decryptBASE64(String key) <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">new</span> BASE64Decoder()).decodeBuffer(key);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * BASE64加密 </span></span><br><span class="line"><span class="comment">     *  </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">encryptBASE64</span><span class="params">(<span class="keyword">byte</span>[] key)</span> <span class="keyword">throws</span> Exception </span>&#123;  </span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">new</span> BASE64Encoder()).encodeBuffer(key);  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p></p><p>主要就是BASE64Encoder、BASE64Decoder两个类，我们只需要知道使用对应的方法即可。另，BASE加密后产生的字节位数是8的倍数，如果不够位数以=符号填充。</p><h3 id="MD5"><a href="#MD5" class="headerlink" title="MD5"></a>MD5</h3><p>MD5 – message-digest algorithm 5 （信息-摘要算法）缩写，广泛用于加密和解密技术，常用于文件校验。校验？不管文件多大，经过MD5后都能生成唯一的MD5值。好比现在的ISO校验，都 是MD5校验。怎么用？当然是把ISO经过MD5后产生MD5的值。一般下载linux-ISO的朋友都见过下载链接旁边放着MD5的串。就是用来验证文 件是否一致的。</p><p><img src="/image/encrypt-1.jpg" alt=""></p><p>通过java代码实现如下：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">     * MD5加密 </span></span><br><span class="line"><span class="comment">     *  </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] encryptMD5(<span class="keyword">byte</span>[] data) <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">  </span><br><span class="line">        MessageDigest md5 = MessageDigest.getInstance(KEY_MD5);  </span><br><span class="line">        md5.update(data);  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> md5.digest();  </span><br><span class="line">  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p></p><p>通常我们不直接使用上述MD5加密。通常将MD5产生的字节数组交给BASE64再加密一把，得到相应的字符串。</p><h3 id="SHA"><a href="#SHA" class="headerlink" title="SHA"></a>SHA</h3><p>SHA(Secure Hash Algorithm，安全散列算法），数字签名等密码学应用中重要的工具，被广泛地应用于电子商务等信息安全领域。虽然，SHA与MD5通过碰撞法都被破解了， 但是SHA仍然是公认的安全加密算法，较之MD5更为安全。</p><p><img src="/image/encrypt-2.jpg" alt=""></p><p>通过java代码实现如下：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 初始化HMAC密钥 </span></span><br><span class="line"><span class="comment">     *  </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">initMacKey</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;  </span><br><span class="line">        KeyGenerator keyGenerator = KeyGenerator.getInstance(KEY_MAC);  </span><br><span class="line">  </span><br><span class="line">        SecretKey secretKey = keyGenerator.generateKey();  </span><br><span class="line">        <span class="keyword">return</span> encryptBASE64(secretKey.getEncoded());  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * HMAC加密 </span></span><br><span class="line"><span class="comment">     *  </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] encryptHMAC(<span class="keyword">byte</span>[] data, String key) <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">  </span><br><span class="line">        SecretKey secretKey = <span class="keyword">new</span> SecretKeySpec(decryptBASE64(key), KEY_MAC);  </span><br><span class="line">        Mac mac = Mac.getInstance(secretKey.getAlgorithm());  </span><br><span class="line">        mac.init(secretKey);  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> mac.doFinal(data);  </span><br><span class="line">  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p></p><p>BASE64的加密解密是双向的，可以求反解。<br>MD5、SHA以及HMAC是单向加密，任何数据加密后只会产生唯一的一个加密串，通常用来校验数据在传输过程中是否被修改。其中HMAC算法有一个密钥，增强了数据传输过程中的安全性，强化了算法外的不可控因素。<br>单向加密的用途主要是为了校验数据在传输过程中是否被修改。</p><h2 id="复杂加密"><a href="#复杂加密" class="headerlink" title="复杂加密"></a>复杂加密</h2><h3 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h3><h4 id="DES"><a href="#DES" class="headerlink" title="DES"></a>DES</h4><p>DES-Data Encryption Standard,即数据加密算法。是IBM公司于1975年研究成功并公开发表的。DES算法的入口参数有三个:Key、Data、Mode。其中 Key为8个字节共64位,是DES算法的工作密钥;Data也为8个字节64位,是要被加密或被解密的数据;Mode为DES的工作方式,有两种:加密 或解密。<br>DES算法把64位的明文输入块变为64位的密文输出块,它所使用的密钥也是64位。</p><p>其实DES有很多同胞兄弟，如DESede(TripleDES)、AES、Blowfish、RC2、RC4(ARCFOUR)。这里就不过多阐述了，大同小异，只要换掉ALGORITHM换成对应的值，同时做一个代码替换SecretKey secretKey = new SecretKeySpec(key, ALGORITHM);就可以了，此外就是密钥长度不同了。</p><h4 id="PBE"><a href="#PBE" class="headerlink" title="PBE"></a>PBE</h4><p>PBE——Password-based encryption（基于密码加密）。其特点在于口令由用户自己掌管，不借助任何物理媒体；采用随机数（这里我们叫做盐）杂凑多重加密等方法保证数据的安全性。是一种简便的加密方式。</p><h3 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h3><h4 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h4><p>这种算法1978年就出现了，它是第一个既能用于数据加密也能用于数字签名的算法。它易于理解和操作，也很流行。算法的名字以发明者的名字命名：Ron Rivest, AdiShamir 和Leonard Adleman。<br>这种加密算法的特点主要是密钥的变化，上文我们看到DES只有一个密钥。相当于只有一把钥匙，如果这把钥匙丢了，数据也就不安全了。RSA同时有两把钥 匙，公钥与私钥。同时支持数字签名。数字签名的意义在于，对传输过来的数据进行校验。确保数据在传输工程中不被修改。</p><p>流程分析：</p><ol><li>甲方构建密钥对儿，将公钥公布给乙方，将私钥保留。</li><li>甲方使用私钥加密数据，然后用私钥对加密后的数据签名，发送给乙方签名以及加密后的数据；乙方使用公钥、签名来验证待解密数据是否有效，如果有效使用公钥对数据解密。</li><li>乙方使用公钥加密数据，向甲方发送经过加密后的数据；甲方获得加密数据，通过私钥解密。</li></ol><p>简要总结一下，使用公钥加密、私钥解密，完成了乙方到甲方的一次数据传递，通过私钥加密、公钥解密，同时通过私钥签名、公钥验证签名，完成了一次甲方到乙方的数据传递与验证，两次数据传递完成一整套的数据交互！</p><p>类似数字签名，数字信封是这样描述的：</p><ul><li>数字信封<pre><code>数字信封用加密技术来保证只有特定的收信人才能阅读信的内容。 </code></pre></li><li>流程：<br>信息发送方采用对称密钥来加密信息，然后再用接收方的公钥来加密此对称密钥（这部分称为数字信封），再将它和信息一起发送给接收方；接收方先用相应的私钥打开数字信封，得到对称密钥，然后使用对称密钥再解开信息。</li></ul><p>接下来我们分析DH加密算法，一种适基于密钥一致协议的加密算法。</p><h3 id="DH"><a href="#DH" class="headerlink" title="DH"></a>DH</h3><p>Diffie- Hellman算法(D-H算法)，密钥一致协议。是由公开密钥密码体制的奠基人Diffie和Hellman所提出的一种思想。简单的说就是允许两名用 户在公开媒体上交换信息以生成”一致”的、可以共享的密钥。换句话说，就是由甲方产出一对密钥（公钥、私钥），乙方依照甲方公钥产生乙方密钥对（公钥、私 钥）。以此为基线，作为数据传输保密基础，同时双方使用同一种对称加密算法构建本地密钥（SecretKey）对数据加密。这样，在互通了本地密钥 （SecretKey）算法后，甲乙双方公开自己的公钥，使用对方的公钥和刚才产生的私钥加密数据，同时可以使用对方的公钥和自己的私钥对数据解密。不单 单是甲乙双方两方，可以扩展为多方共享数据通讯，这样就完成了网络交互数据的安全通讯！该算法源于中国的同余定理——中国馀数定理。</p><p>流程分析：</p><ol><li>甲方构建密钥对儿，将公钥公布给乙方，将私钥保留；双方约定数据加密算法；乙方通过甲方公钥构建密钥对儿，将公钥公布给甲方，将私钥保留。</li><li>甲方使用私钥、乙方公钥、约定数据加密算法构建本地密钥，然后通过本地密钥加密数据，发送给乙方加密后的数据；乙方使用私钥、甲方公钥、约定数据加密算法构建本地密钥，然后通过本地密钥对数据解密。</li><li>乙方使用私钥、甲方公钥、约定数据加密算法构建本地密钥，然后通过本地密钥加密数据，发送给甲方加密后的数据；甲方使用私钥、乙方公钥、约定数据加密算法构建本地密钥，然后通过本地密钥对数据解密。</li></ol><h2 id="常见加密算法"><a href="#常见加密算法" class="headerlink" title="常见加密算法"></a>常见加密算法</h2><ol><li>DES（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合；</li><li><p>3DES（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高；</p></li><li><p>RC2和 RC4：用变长密钥对大量数据进行加密，比 DES 快；</p></li><li><p>IDEA（International Data Encryption Algorithm）国际数据加密算法：使用 128 位密钥提供非常强的安全性；</p></li><li><p>RSA：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的；</p></li><li><p>DSA（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准）；</p></li><li><p>AES（Advanced Encryption Standard）：高级加密标准，是下一代的加密算法标准，速度快，安全级别高，目前 AES 标准的一个实现是 Rijndael 算法；</p></li><li><p>BLOWFISH，它使用变长的密钥，长度可达448位，运行速度很快；</p></li></ol><p>其它算法，如ElGamal、Deffie-Hellman、新型椭圆曲线算法ECC等。 比如说，MD5，你在一些比较正式而严格的网站下的东西一般都会有MD5值给出，如安全焦点的软件工具，每个都有MD5。严格来说MD5并不能算是一种加密算法，只能说是一种摘要算法（数据摘要算法是密码学算法中非常重要的一个分支，它通过对所有数据提取指纹信息以实现数据签名、数据完整性校验等功能，由于其不可逆性，有时候会被用做敏感信息的加密。数据摘要算法也被称为哈希(Hash)算法、散列算法。）</p><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p><a href="https://blog.csdn.net/jhon_03/article/details/78268218" target="_blank" rel="noopener">各种Java加密算法</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;机密算法分类，基础加密算法基本有四种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Base64&lt;/li&gt;&lt;li&gt;Md5&lt;/li&gt;&lt;li&gt;Sha&lt;
      
    
    </summary>
    
      <category term="加密算法" scheme="http://www.fufan.me/categories/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="加密" scheme="http://www.fufan.me/tags/%E5%8A%A0%E5%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>java多线程系列（七）——JUC锁</title>
    <link href="http://www.fufan.me/2017/06/06/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94JUC%E9%94%81/"/>
    <id>http://www.fufan.me/2017/06/06/java多线程系列（七）——JUC锁/</id>
    <published>2017-06-05T17:47:00.000Z</published>
    <updated>2018-11-05T17:55:14.987Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --><p>下面介绍一下JUC包中可以让我们在多线程并发中使用的锁。</p><p>UC包中的锁，包括：</p><ul><li>Lock接口</li><li>ReadWriteLock接口</li><li>LockSupport阻塞原语</li><li>Condition条件AbstractOwnableSynchronizer/AbstractQueuedSynchronizer/AbstractQueuedLongSynchronizer三个抽象类</li><li>ReentrantLock独占锁</li><li>ReentrantReadWriteLock读写锁</li><li>由于CountDownLatch，CyclicBarrier和Semaphore也是通过AQS来实现的；因此，我也将它们归纳到锁的框架中进行介绍。</li></ul><p>先看看锁的框架图，如下所示。<br><img src="/image/thread-7-0.jpg" alt=""></p><p>下面简述一下每个类或接口</p><h3 id="Lock接口"><a href="#Lock接口" class="headerlink" title="Lock接口"></a>Lock接口</h3><p>JUC包中的 Lock 接口支持那些语义不同(重入、公平等)的锁规则。所谓语义不同，是指锁可是有”公平机制的锁”、”非公平机制的锁”、”可重入的锁”等等。”公平机制”是指”不同线程获取锁的机制是公平的”，而”非公平机制”则是指”不同线程获取锁的机制是非公平的”，”可重入的锁”是指同一个锁能够被一个线程多次获取。</p><h3 id="ReadWriteLock"><a href="#ReadWriteLock" class="headerlink" title="ReadWriteLock"></a>ReadWriteLock</h3><p>ReadWriteLock 接口以和Lock类似的方式定义了一些读取者可以共享而写入者独占的锁。JUC包只有一个类实现了该接口，即 ReentrantReadWriteLock，因为它适用于大部分的标准用法上下文。但程序员可以创建自己的、适用于非标准要求的实现。</p><h3 id="AbstractOwnableSynchronizer-AbstractQueuedSynchronizer-AbstractQueuedLongSynchronizer"><a href="#AbstractOwnableSynchronizer-AbstractQueuedSynchronizer-AbstractQueuedLongSynchronizer" class="headerlink" title="AbstractOwnableSynchronizer/AbstractQueuedSynchronizer/AbstractQueuedLongSynchronizer"></a>AbstractOwnableSynchronizer/AbstractQueuedSynchronizer/AbstractQueuedLongSynchronizer</h3><p>AbstractQueuedSynchronizer就是被称之为AQS的类，它是一个非常有用的超类，可用来定义锁以及依赖于排队阻塞线程的其他同步器；ReentrantLock，ReentrantReadWriteLock，CountDownLatch，CyclicBarrier和Semaphore等这些类都是基于AQS类实现的。AbstractQueuedLongSynchronizer 类提供相同的功能但扩展了对同步状态的 64 位的支持。两者都扩展了类 AbstractOwnableSynchronizer（一个帮助记录当前保持独占同步的线程的简单类）。</p><h3 id="LockSupport"><a href="#LockSupport" class="headerlink" title="LockSupport"></a>LockSupport</h3><ul><li>LockSupport提供“创建锁”和“其他同步类的基本线程阻塞原语”。</li><li>LockSupport的功能和”Thread中的Thread.suspend()和Thread.resume()有点类似”，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。</li></ul><h3 id="Condition"><a href="#Condition" class="headerlink" title="Condition"></a>Condition</h3><ul><li>Condition需要和Lock联合使用，它的作用是代替Object监视器方法，可以通过await(),signal()来休眠/唤醒线程。</li><li>Condition 接口描述了可能会与锁有关联的条件变量。这些变量在用法上与使用 Object.wait 访问的隐式监视器类似，但提供了更强大的功能。需要特别指出的是，单个 Lock 可能与多个 Condition 对象关联。为了避免兼容性问题，Condition 方法的名称与对应的 Object 版本中的不同。</li></ul><h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><p>ReentrantLock是独占锁。所谓独占锁，是指只能被独自占领，即同一个时间点只能被一个线程锁获取到的锁。ReentrantLock锁包括”公平的ReentrantLock”和”非公平的ReentrantLock”。”公平的ReentrantLock”是指”不同线程获取锁的机制是公平的”，而”非公平的　　ReentrantLock”则是指”不同线程获取锁的机制是非公平的”，ReentrantLock是”可重入的锁”。</p><p>ReentrantLock的UML类图如下：<br><img src="/image/thread-7-1.jpg" alt=""></p><ol><li>ReentrantLock实现了Lock接口。</li><li>ReentrantLock中有一个成员变量sync，sync是Sync类型；Sync是一个抽象类，而且它继承于AQS。</li><li>ReentrantLock中有”公平锁类”FairSync和”非公平锁类”NonfairSync，它们都是Sync的子类。ReentrantReadWriteLock中sync对象，是FairSync与NonfairSync中的一种，这也意味着ReentrantLock是”公平锁”或”非公平锁”中的一种，ReentrantLock默认是非公平锁。</li></ol><h3 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h3><p>ReentrantReadWriteLock是读写锁接口ReadWriteLock的实现类，它包括子类ReadLock和WriteLock。ReentrantLock是共享锁，而WriteLock是独占锁。</p><p>ReentrantReadWriteLock的UML类图如下：</p><p><img src="/image/thread-7-2.jpg" alt=""></p><ol><li>ReentrantReadWriteLock实现了ReadWriteLock接口。</li><li>ReentrantReadWriteLock中包含sync对象，读锁readerLock和写锁writerLock。读锁ReadLock和写锁WriteLock都实现了Lock接口。</li><li>和”ReentrantLock”一样，sync是Sync类型；而且，Sync也是一个继承于AQS的抽象类。Sync也包括”公平锁”FairSync和”非公平锁”NonfairSync。</li></ol><h3 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h3><p>CountDownLatch是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。<br>CountDownLatch的UML类图如下：<br><img src="/image/thread-7-3.jpg" alt=""></p><p>CountDownLatch包含了sync对象，sync是Sync类型。CountDownLatch的Sync是实例类，它继承于AQS。</p><h3 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h3><p>CyclicBarrier是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。</p><p>CyclicBarrier的UML类图如下：<br><img src="/image/thread-7-4.jpg" alt=""></p><p>CyclicBarrier是包含了”ReentrantLock对象lock”和”Condition对象trip”，它是通过独占锁实现的。<br>CyclicBarrier和CountDownLatch的区别是：<br>1. CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待。<br>2. CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。</p><h3 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h3><p>Semaphore是一个计数信号量，它的本质是一个”共享锁”。<br>信号量维护了一个信号量许可集。线程可以通过调用acquire()来获取信号量的许可；当信号量中有可用的许可时，线程能获取该许可；否则线程必须等待，直到有可用的许可为止。 线程可以通过release()来释放它所持有的信号量许可。<br>Semaphore的UML类图如下：<br><img src="/image/thread-7-5.jpg" alt=""></p><p>和”ReentrantLock”一样，Semaphore包含了sync对象，sync是Sync类型；而且，Sync也是一个继承于AQS的抽象类。Sync也包括”公平信号量”FairSync和”非公平信号量”NonfairSync。</p><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p><a href="https://www.cnblogs.com/skywang12345/p/java_threads_category.html" target="_blank" rel="noopener">Java多线程系列目录(共43篇)</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 09 2018 14:07:14 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;下面介绍一下JUC包中可以让我们在多线程并发中使用的锁。&lt;/p&gt;&lt;p&gt;UC包中的锁，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Lock接
      
    
    </summary>
    
      <category term="多线程" scheme="http://www.fufan.me/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
    
      <category term="多线程" scheme="http://www.fufan.me/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
</feed>
