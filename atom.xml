<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>A Gemini Boy</title>
  
  <subtitle>welcome to my site</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.fufan.me/"/>
  <updated>2018-12-05T03:54:22.143Z</updated>
  <id>http://www.fufan.me/</id>
  
  <author>
    <name>fae88</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>java多线程系列（八）——执行器Executor并发框架</title>
    <link href="http://www.fufan.me/2018/12/04/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%B3%BB%E5%88%97%EF%BC%88%E5%85%AB%EF%BC%89%E2%80%94%E2%80%94%E6%89%A7%E8%A1%8C%E5%99%A8Executor%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6/"/>
    <id>http://www.fufan.me/2018/12/04/java多线程系列（八）——执行器Executor并发框架/</id>
    <published>2018-12-04T03:53:00.000Z</published>
    <updated>2018-12-05T03:54:22.143Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:54:22 GMT+0800 (China Standard Time) --><p>线程池的架构图如下：<br><img src="/image/thread-8-0.jpg" alt=""></p><h3 id="1-Executor"><a href="#1-Executor" class="headerlink" title="1. Executor"></a>1. Executor</h3><p>它是”执行者”接口，它是来执行任务的。准确的说，Executor提供了execute()接口来执行已提交的 Runnable 任务的对象。Executor存在的目的是提供一种将”任务提交”与”任务如何运行”分离开来的机制。<br>它只包含一个函数接口：</p><h3 id="2-ExecutorService"><a href="#2-ExecutorService" class="headerlink" title="2. ExecutorService"></a>2. ExecutorService</h3><p>xecutorService继承于Executor。它是”执行者服务”接口，它是为”执行者接口Executor”服务而存在的；准确的话，ExecutorService提供了”将任务提交给执行者的接口(submit方法)”，”让执行者执行任务(invokeAll, invokeAny方法)”的接口等等。</p><h3 id="3-AbstractExecutorService"><a href="#3-AbstractExecutorService" class="headerlink" title="3. AbstractExecutorService"></a>3. AbstractExecutorService</h3><p>AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。<br>AbstractExecutorService存在的目的是为ExecutorService中的函数接口提供了默认实现。其实基本上抽象方法的作用一般也就是为了提供默认的实现，不过我们在jdk1.8开始，可以使用接口的默认方法，即default关键字。</p><h3 id="4-ThreadPoolExecutor"><a href="#4-ThreadPoolExecutor" class="headerlink" title="4. ThreadPoolExecutor"></a>4. ThreadPoolExecutor</h3><p>ThreadPoolExecutor就是大名鼎鼎的”线程池”。它继承于AbstractExecutorService抽象类。</p><h4 id="构造方法的核心参数"><a href="#构造方法的核心参数" class="headerlink" title="构造方法的核心参数"></a>构造方法的核心参数</h4><ul><li>corePoolSize：核心线程数量，当有新任务在execute()方法提交时，会执行以下判断：<ul><li>如果运行的线程少于 corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的；</li><li>如果线程池中的线程数量大于等于 corePoolSize 且小于 maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务；</li><li>如果设置的corePoolSize 和 maximumPoolSize相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理；</li><li>如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务；</li></ul></li><li>所以，任务提交时，判断的顺序为 corePoolSize –&gt; workQueue –&gt; maximumPoolSize。</li><li>maximumPoolSize：最大线程数量；</li><li>workQueue：等待队列，当任务提交时，如果线程池中的线程数量大于等于corePoolSize的时候，把该任务封装成一个Worker对象放入等待队列；</li><li>workQueue：保存等待执行的任务的阻塞队列，当提交一个新的任务到线程池以后, 线程池会根据当前线程池中正在运行着的线程的数量来决定对该任务的处理方式，主要有以下几种处理方式:<ul><li>直接切换：这种方式常用的队列是SynchronousQueue，但现在还没有研究过该队列，这里暂时还没法介绍；</li><li>使用无界队列：一般使用基于链表的阻塞队列LinkedBlockingQueue。如果使用这种方式，那么线程池中能够创建的最大线程数就是corePoolSize，而maximumPoolSize就不会起作用了（后面也会说到）。当线程池中所有的核心线程都是RUNNING状态时，这时一个新的任务提交就会放入等待队列中。</li><li>使用有界队列：一般使用ArrayBlockingQueue。使用该方式可以将线程池的最大线程数量限制为maximumPoolSize，这样能够降低资源的消耗，但同时这种方式也使得线程池对线程的调度变得更困难，因为线程池和队列的容量都是有限的值，所以要想使线程池处理任务的吞吐率达到一个相对合理的范围，又想使线程调度相对简单，并且还要尽可能的降低线程池对资源的消耗，就需要合理的设置这两个数量。<ul><li>如果要想降低系统资源的消耗（包括CPU的使用率，操作系统资源的消耗，上下文环境切换的开销等）, 可以设置较大的队列容量和较小的线程池容量, 但这样也会降低线程处理任务的吞吐量。</li><li>如果提交的任务经常发生阻塞，那么可以考虑通过调用 setMaximumPoolSize() 方法来重新设定线程池的容量。</li><li>如果队列的容量设置的较小，通常需要将线程池的容量设置大一点，这样CPU的使用率会相对的高一些。但如果线程池的容量设置的过大，则在提交的任务数量太多的情况下，并发量会增加，那么线程之间的调度就是一个要考虑的问题，因为这样反而有可能降低处理任务的吞吐量。</li></ul></li></ul></li><li>keepAliveTime：线程池维护线程所允许的空闲时间。当线程池中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime；</li><li>threadFactory：它是ThreadFactory类型的变量，用来创建新线程。默认使用Executors.defaultThreadFactory() 来创建线程。使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称。</li><li>handler：它是RejectedExecutionHandler类型的变量，表示线程池的饱和策略。如果阻塞队列满了并且没有空闲的线程，这时如果继续提交任务，就需要采取一种策略处理该任务。线程池提供了4种策略：<ul><li>AbortPolicy：直接抛出异常，这是默认策略；</li><li>CallerRunsPolicy：用调用者所在的线程来执行任务；</li><li>DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；</li><li>DiscardPolicy：直接丢弃任务；</li></ul></li></ul><h4 id="execute"><a href="#execute" class="headerlink" title="execute()"></a>execute()</h4><p>execute()方法用来提交任务，代码如下：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Runnable command)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (command == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * clt记录着runState和workerCount</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">int</span> c = ctl.get();</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * workerCountOf方法取出低29位的值，表示当前活动的线程数；</span></span><br><span class="line"><span class="comment">     * 如果当前活动线程数小于corePoolSize，则新建一个线程放入线程池中；</span></span><br><span class="line"><span class="comment">     * 并把任务添加到该线程中。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (workerCountOf(c) &lt; corePoolSize) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * addWorker中的第二个参数表示限制添加线程的数量是根据corePoolSize来判断还是maximumPoolSize来判断；</span></span><br><span class="line"><span class="comment">         * 如果为true，根据corePoolSize来判断；</span></span><br><span class="line"><span class="comment">         * 如果为false，则根据maximumPoolSize来判断</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (addWorker(command, <span class="keyword">true</span>))</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 如果添加失败，则重新获取ctl值</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        c = ctl.get();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 如果当前线程池是运行状态并且任务添加到队列成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class="line">        <span class="comment">// 重新获取ctl值</span></span><br><span class="line">        <span class="keyword">int</span> recheck = ctl.get();</span><br><span class="line">        <span class="comment">// 再次判断线程池的运行状态，如果不是运行状态，由于之前已经把command添加到workQueue中了，</span></span><br><span class="line">        <span class="comment">// 这时需要移除该command</span></span><br><span class="line">        <span class="comment">// 执行过后通过handler使用拒绝策略对该任务进行处理，整个方法返回</span></span><br><span class="line">        <span class="keyword">if</span> (! isRunning(recheck) &amp;&amp; remove(command))</span><br><span class="line">            reject(command);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 获取线程池中的有效线程数，如果数量是0，则执行addWorker方法</span></span><br><span class="line"><span class="comment">         * 这里传入的参数表示：</span></span><br><span class="line"><span class="comment">         * 1. 第一个参数为null，表示在线程池中创建一个线程，但不去启动；</span></span><br><span class="line"><span class="comment">         * 2. 第二个参数为false，将线程池的有限线程数量的上限设置为maximumPoolSize，添加线程时根据maximumPoolSize来判断；</span></span><br><span class="line"><span class="comment">         * 如果判断workerCount大于0，则直接返回，在workQueue中新增的command会在将来的某个时刻被执行。</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (workerCountOf(recheck) == <span class="number">0</span>)</span><br><span class="line">            addWorker(<span class="keyword">null</span>, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 如果执行到这里，有两种情况：</span></span><br><span class="line"><span class="comment">     * 1. 线程池已经不是RUNNING状态；</span></span><br><span class="line"><span class="comment">     * 2. 线程池是RUNNING状态，但workerCount &gt;= corePoolSize并且workQueue已满。</span></span><br><span class="line"><span class="comment">     * 这时，再次调用addWorker方法，但第二个参数传入为false，将线程池的有限线程数量的上限设置为maximumPoolSize；</span></span><br><span class="line"><span class="comment">     * 如果失败则拒绝该任务</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (!addWorker(command, <span class="keyword">false</span>))</span><br><span class="line">        reject(command);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>简单来说，在执行execute()方法时如果状态一直是RUNNING时，的执行过程如下：</p><p>如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务；<br>如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中；<br>如果workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务；<br>如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。<br>这里要注意一下addWorker(null, false);，也就是创建一个线程，但并没有传入任务，因为任务已经被添加到workQueue中了，所以worker在执行的时候，会直接从workQueue中获取任务。所以，在workerCountOf(recheck) == 0时执行addWorker(null, false);也是为了保证线程池在RUNNING状态下必须要有一个线程来执行任务。</p><p>execute方法执行流程如下：</p><p><img src="/image/thread-8-1.png" alt=""></p><h4 id="addWorker方法"><a href="#addWorker方法" class="headerlink" title="addWorker方法"></a>addWorker方法</h4><p>addWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数 用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">addWorker</span><span class="params">(Runnable firstTask, <span class="keyword">boolean</span> core)</span> </span>&#123;</span><br><span class="line">    retry:</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> c = ctl.get();</span><br><span class="line">        <span class="comment">// 获取运行状态</span></span><br><span class="line">        <span class="keyword">int</span> rs = runStateOf(c);</span><br><span class="line">         </span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 这个if判断</span></span><br><span class="line"><span class="comment">         * 如果rs &gt;= SHUTDOWN，则表示此时不再接收新任务；</span></span><br><span class="line"><span class="comment">         * 接着判断以下3个条件，只要有1个不满足，则返回false：</span></span><br><span class="line"><span class="comment">         * 1. rs == SHUTDOWN，这时表示关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务</span></span><br><span class="line"><span class="comment">         * 2. firsTask为空</span></span><br><span class="line"><span class="comment">         * 3. 阻塞队列不为空</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 首先考虑rs == SHUTDOWN的情况</span></span><br><span class="line"><span class="comment">         * 这种情况下不会接受新提交的任务，所以在firstTask不为空的时候会返回false；</span></span><br><span class="line"><span class="comment">         * 然后，如果firstTask为空，并且workQueue也为空，则返回false，</span></span><br><span class="line"><span class="comment">         * 因为队列中已经没有任务了，不需要再添加线程了</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">// Check if queue empty only if necessary.</span></span><br><span class="line">        <span class="keyword">if</span> (rs &gt;= SHUTDOWN &amp;&amp;</span><br><span class="line">            ! (rs == SHUTDOWN &amp;&amp;</span><br><span class="line">               firstTask == <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">               ! workQueue.isEmpty()))</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            <span class="comment">// 获取线程数</span></span><br><span class="line">            <span class="keyword">int</span> wc = workerCountOf(c);</span><br><span class="line">            <span class="comment">// 如果wc超过CAPACITY，也就是ctl的低29位的最大值（二进制是29个1），返回false；</span></span><br><span class="line">            <span class="comment">// 这里的core是addWorker方法的第二个参数，如果为true表示根据corePoolSize来比较，</span></span><br><span class="line">            <span class="comment">// 如果为false则根据maximumPoolSize来比较。</span></span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            <span class="keyword">if</span> (wc &gt;= CAPACITY ||</span><br><span class="line">                wc &gt;= (core ? corePoolSize : maximumPoolSize))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            <span class="comment">// 尝试增加workerCount，如果成功，则跳出第一个for循环</span></span><br><span class="line">            <span class="keyword">if</span> (compareAndIncrementWorkerCount(c))</span><br><span class="line">                <span class="keyword">break</span> retry;</span><br><span class="line">            <span class="comment">// 如果增加workerCount失败，则重新获取ctl的值</span></span><br><span class="line">            c = ctl.get();  <span class="comment">// Re-read ctl</span></span><br><span class="line">            <span class="comment">// 如果当前的运行状态不等于rs，说明状态已被改变，返回第一个for循环继续执行</span></span><br><span class="line">            <span class="keyword">if</span> (runStateOf(c) != rs)</span><br><span class="line">                <span class="keyword">continue</span> retry;</span><br><span class="line">            <span class="comment">// else CAS failed due to workerCount change; retry inner loop</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">boolean</span> workerStarted = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">boolean</span> workerAdded = <span class="keyword">false</span>;</span><br><span class="line">    Worker w = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 根据firstTask来创建Worker对象</span></span><br><span class="line">        w = <span class="keyword">new</span> Worker(firstTask);</span><br><span class="line">        <span class="comment">// 每一个Worker对象都会创建一个线程</span></span><br><span class="line">        <span class="keyword">final</span> Thread t = w.thread;</span><br><span class="line">        <span class="keyword">if</span> (t != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">            mainLock.lock();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// Recheck while holding lock.</span></span><br><span class="line">                <span class="comment">// Back out on ThreadFactory failure or if</span></span><br><span class="line">                <span class="comment">// shut down before lock acquired.</span></span><br><span class="line">                <span class="keyword">int</span> rs = runStateOf(ctl.get());</span><br><span class="line">                <span class="comment">// rs &lt; SHUTDOWN表示是RUNNING状态；</span></span><br><span class="line">                <span class="comment">// 如果rs是RUNNING状态或者rs是SHUTDOWN状态并且firstTask为null，向线程池中添加线程。</span></span><br><span class="line">                <span class="comment">// 因为在SHUTDOWN时不会在添加新的任务，但还是会执行workQueue中的任务</span></span><br><span class="line">                <span class="keyword">if</span> (rs &lt; SHUTDOWN ||</span><br><span class="line">                    (rs == SHUTDOWN &amp;&amp; firstTask == <span class="keyword">null</span>)) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (t.isAlive()) <span class="comment">// precheck that t is startable</span></span><br><span class="line">                        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalThreadStateException();</span><br><span class="line">                    <span class="comment">// workers是一个HashSet</span></span><br><span class="line">                    workers.add(w);</span><br><span class="line">                    <span class="keyword">int</span> s = workers.size();</span><br><span class="line">                    <span class="comment">// largestPoolSize记录着线程池中出现过的最大线程数量</span></span><br><span class="line">                    <span class="keyword">if</span> (s &gt; largestPoolSize)</span><br><span class="line">                        largestPoolSize = s;</span><br><span class="line">                    workerAdded = <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                mainLock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (workerAdded) &#123;</span><br><span class="line">                <span class="comment">// 启动线程</span></span><br><span class="line">                t.start();</span><br><span class="line">                workerStarted = <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (! workerStarted)</span><br><span class="line">            addWorkerFailed(w);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> workerStarted;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>注意一下这里的t.start()这个语句，启动时会调用Worker类中的run方法，Worker本身实现了Runnable接口，所以一个Worker类型的对象也是一个线程。</p><h4 id="Worker类"><a href="#Worker类" class="headerlink" title="Worker类"></a>Worker类</h4><p>线程池中的每一个线程被封装成一个Worker对象，ThreadPool维护的其实就是一组Worker对象，看一下Worker的定义：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">runWorker</span><span class="params">(Worker w)</span> </span>&#123;</span><br><span class="line">    Thread wt = Thread.currentThread();</span><br><span class="line">    <span class="comment">// 获取第一个任务</span></span><br><span class="line">    Runnable task = w.firstTask;</span><br><span class="line">    w.firstTask = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 允许中断</span></span><br><span class="line">    w.unlock(); <span class="comment">// allow interrupts</span></span><br><span class="line">    <span class="comment">// 是否因为异常退出循环</span></span><br><span class="line">    <span class="keyword">boolean</span> completedAbruptly = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 如果task为空，则通过getTask来获取任务</span></span><br><span class="line">        <span class="keyword">while</span> (task != <span class="keyword">null</span> || (task = getTask()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            w.lock();</span><br><span class="line">            <span class="comment">// If pool is stopping, ensure thread is interrupted;</span></span><br><span class="line">            <span class="comment">// if not, ensure thread is not interrupted.  This</span></span><br><span class="line">            <span class="comment">// requires a recheck in second case to deal with</span></span><br><span class="line">            <span class="comment">// shutdownNow race while clearing interrupt</span></span><br><span class="line">            <span class="keyword">if</span> ((runStateAtLeast(ctl.get(), STOP) ||</span><br><span class="line">                 (Thread.interrupted() &amp;&amp;</span><br><span class="line">                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;</span><br><span class="line">                !wt.isInterrupted())</span><br><span class="line">                wt.interrupt();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                beforeExecute(wt, task);</span><br><span class="line">                Throwable thrown = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    task.run();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (RuntimeException x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> x;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Error x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> x;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Throwable x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> <span class="keyword">new</span> Error(x);</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    afterExecute(task, thrown);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                task = <span class="keyword">null</span>;</span><br><span class="line">                w.completedTasks++;</span><br><span class="line">                w.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        completedAbruptly = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        processWorkerExit(w, completedAbruptly);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>这里说明一下第一个if判断，目的是：</p><ul><li>如果线程池正在停止，那么要保证当前线程是中断状态；</li><li>如果不是的话，则要保证当前线程不是中断状态；</li></ul><p>这里要考虑在执行该if语句期间可能也执行了shutdownNow方法，shutdownNow方法会把状态设置为STOP，回顾一下STOP状态：</p><pre><code>不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态。</code></pre><p>STOP状态要中断线程池中的所有线程，而这里使用Thread.interrupted()来判断是否中断是为了确保在RUNNING或者SHUTDOWN状态时线程是非中断状态的，因为Thread.interrupted()方法会复位中断的状态。</p><p>总结一下runWorker方法的执行过程：</p><ol><li>while循环不断地通过getTask()方法获取任务；</li><li>getTask()方法从阻塞队列中取任务；</li><li>如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态；</li><li>调用task.run()执行任务；</li><li>如果task为null则跳出循环，执行processWorkerExit()方法；</li><li>runWorker方法执行完毕，也代表着Worker中的run方法执行完毕，销毁线程。</li></ol><p>这里的beforeExecute方法和afterExecute方法在ThreadPoolExecutor类中是空的，留给子类来实现。</p><p>completedAbruptly变量来表示在执行任务过程中是否出现了异常，在processWorkerExit方法中会对该变量的值进行判断。</p><h5 id="getTask"><a href="#getTask" class="headerlink" title="getTask"></a>getTask</h5><p>getTask方法用来从阻塞队列中取任务，代码如下：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Runnable <span class="title">getTask</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// timeOut变量的值表示上次从阻塞队列中取任务时是否超时</span></span><br><span class="line">    <span class="keyword">boolean</span> timedOut = <span class="keyword">false</span>; <span class="comment">// Did the last poll() time out?</span></span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> c = ctl.get();</span><br><span class="line">        <span class="keyword">int</span> rs = runStateOf(c);</span><br><span class="line">        <span class="comment">// Check if queue empty only if necessary.</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 如果线程池状态rs &gt;= SHUTDOWN，也就是非RUNNING状态，再进行以下判断：</span></span><br><span class="line"><span class="comment">         * 1. rs &gt;= STOP，线程池是否正在stop；</span></span><br><span class="line"><span class="comment">         * 2. 阻塞队列是否为空。</span></span><br><span class="line"><span class="comment">         * 如果以上条件满足，则将workerCount减1并返回null。</span></span><br><span class="line"><span class="comment">         * 因为如果当前线程池状态的值是SHUTDOWN或以上时，不允许再向阻塞队列中添加任务。</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123;</span><br><span class="line">            decrementWorkerCount();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> wc = workerCountOf(c);</span><br><span class="line">        <span class="comment">// Are workers subject to culling?</span></span><br><span class="line">        <span class="comment">// timed变量用于判断是否需要进行超时控制。</span></span><br><span class="line">        <span class="comment">// allowCoreThreadTimeOut默认是false，也就是核心线程不允许进行超时；</span></span><br><span class="line">        <span class="comment">// wc &gt; corePoolSize，表示当前线程池中的线程数量大于核心线程数量；</span></span><br><span class="line">        <span class="comment">// 对于超过核心线程数量的这些线程，需要进行超时控制</span></span><br><span class="line">        <span class="keyword">boolean</span> timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * wc &gt; maximumPoolSize的情况是因为可能在此方法执行阶段同时执行了setMaximumPoolSize方法；</span></span><br><span class="line"><span class="comment">         * timed &amp;&amp; timedOut 如果为true，表示当前操作需要进行超时控制，并且上次从阻塞队列中获取任务发生了超时</span></span><br><span class="line"><span class="comment">         * 接下来判断，如果有效线程数量大于1，或者阻塞队列是空的，那么尝试将workerCount减1；</span></span><br><span class="line"><span class="comment">         * 如果减1失败，则返回重试。</span></span><br><span class="line"><span class="comment">         * 如果wc == 1时，也就说明当前线程是线程池中唯一的一个线程了。</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))</span><br><span class="line">            &amp;&amp; (wc &gt; <span class="number">1</span> || workQueue.isEmpty())) &#123;</span><br><span class="line">            <span class="keyword">if</span> (compareAndDecrementWorkerCount(c))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 根据timed来判断，如果为true，则通过阻塞队列的poll方法进行超时控制，如果在keepAliveTime时间内没有获取到任务，则返回null；</span></span><br><span class="line"><span class="comment">             * 否则通过take方法，如果这时队列为空，则take方法会阻塞直到队列不为空。</span></span><br><span class="line"><span class="comment">             *</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            Runnable r = timed ?</span><br><span class="line">                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :</span><br><span class="line">                workQueue.take();</span><br><span class="line">            <span class="keyword">if</span> (r != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> r;</span><br><span class="line">            <span class="comment">// 如果 r == null，说明已经超时，timedOut设置为true</span></span><br><span class="line">            timedOut = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException retry) &#123;</span><br><span class="line">            <span class="comment">// 如果获取任务时当前线程发生了中断，则设置timedOut为false并返回循环重试</span></span><br><span class="line">            timedOut = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><ul><li>这里重要的地方是第二个if判断，目的是控制线程池的有效线程数量。由上文中的分析可以知道，在执行execute方法时，如果当前线程池的线程数量超过了corePoolSize且小于maximumPoolSize，并且workQueue已满时，则可以增加工作线程，但这时如果超时没有获取到任务，也就是timedOut为true的情况，说明workQueue已经为空了，也就说明了当前线程池中不需要那么多线程来执行任务了，可以把多于corePoolSize数量的线程销毁掉，保持线程数量在corePoolSize即可。</li><li>什么时候会销毁？当然是runWorker方法执行完之后，也就是Worker中的run方法执行完，由JVM自动回收。</li><li>getTask方法返回null时，在runWorker方法中会跳出while循环，然后会执行processWorkerExit方法。</li></ul><h5 id="processWorkerExit方法"><a href="#processWorkerExit方法" class="headerlink" title="processWorkerExit方法"></a>processWorkerExit方法</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processWorkerExit</span><span class="params">(Worker w, <span class="keyword">boolean</span> completedAbruptly)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 如果completedAbruptly值为true，则说明线程执行时出现了异常，需要将workerCount减1；</span></span><br><span class="line">    <span class="comment">// 如果线程执行时没有出现异常，说明在getTask()方法中已经已经对workerCount进行了减1操作，这里就不必再减了。 </span></span><br><span class="line">    <span class="keyword">if</span> (completedAbruptly) <span class="comment">// If abrupt, then workerCount wasn't adjusted</span></span><br><span class="line">        decrementWorkerCount();</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//统计完成的任务数</span></span><br><span class="line">        completedTaskCount += w.completedTasks;</span><br><span class="line">        <span class="comment">// 从workers中移除，也就表示着从线程池中移除了一个工作线程</span></span><br><span class="line">        workers.remove(w);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 根据线程池状态进行判断是否结束线程池</span></span><br><span class="line">    tryTerminate();</span><br><span class="line">    <span class="keyword">int</span> c = ctl.get();</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 当线程池是RUNNING或SHUTDOWN状态时，如果worker是异常结束，那么会直接addWorker；</span></span><br><span class="line"><span class="comment">     * 如果allowCoreThreadTimeOut=true，并且等待队列有任务，至少保留一个worker；</span></span><br><span class="line"><span class="comment">     * 如果allowCoreThreadTimeOut=false，workerCount不少于corePoolSize。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (runStateLessThan(c, STOP)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!completedAbruptly) &#123;</span><br><span class="line">            <span class="keyword">int</span> min = allowCoreThreadTimeOut ? <span class="number">0</span> : corePoolSize;</span><br><span class="line">            <span class="keyword">if</span> (min == <span class="number">0</span> &amp;&amp; ! workQueue.isEmpty())</span><br><span class="line">                min = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (workerCountOf(c) &gt;= min)</span><br><span class="line">                <span class="keyword">return</span>; <span class="comment">// replacement not needed</span></span><br><span class="line">        &#125;</span><br><span class="line">        addWorker(<span class="keyword">null</span>, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此，processWorkerExit执行完之后，工作线程被销毁，以上就是整个工作线程的生命周期，从execute方法开始，Worker使用ThreadFactory创建新的工作线程，runWorker通过getTask获取任务，然后执行任务，如果getTask返回null，进入processWorkerExit方法，整个线程结束，如图所示：</p><p><img src="/image/thread-8-2.png" alt=""></p><h5 id="tryTerminate方法"><a href="#tryTerminate方法" class="headerlink" title="tryTerminate方法"></a>tryTerminate方法</h5><p>tryTerminate方法根据线程池状态进行判断是否结束线程池，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">tryTerminate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> c = ctl.get();</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 当前线程池的状态为以下几种情况时，直接返回：</span></span><br><span class="line"><span class="comment">         * 1. RUNNING，因为还在运行中，不能停止；</span></span><br><span class="line"><span class="comment">         * 2. TIDYING或TERMINATED，因为线程池中已经没有正在运行的线程了；</span></span><br><span class="line"><span class="comment">         * 3. SHUTDOWN并且等待队列非空，这时要执行完workQueue中的task；</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (isRunning(c) ||</span><br><span class="line">            runStateAtLeast(c, TIDYING) ||</span><br><span class="line">            (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        <span class="comment">// 如果线程数量不为0，则中断一个空闲的工作线程，并返回</span></span><br><span class="line">        <span class="keyword">if</span> (workerCountOf(c) != <span class="number">0</span>) &#123; <span class="comment">// Eligible to terminate</span></span><br><span class="line">            interruptIdleWorkers(ONLY_ONE);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">        mainLock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 这里尝试设置状态为TIDYING，如果设置成功，则调用terminated方法</span></span><br><span class="line">            <span class="keyword">if</span> (ctl.compareAndSet(c, ctlOf(TIDYING, <span class="number">0</span>))) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// terminated方法默认什么都不做，留给子类实现</span></span><br><span class="line">                    terminated();</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="comment">// 设置状态为TERMINATED</span></span><br><span class="line">                    ctl.set(ctlOf(TERMINATED, <span class="number">0</span>));</span><br><span class="line">                    termination.signalAll();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            mainLock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// else retry on failed CAS</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>interruptIdleWorkers(ONLY_ONE);的作用是因为在getTask方法中执行workQueue.take()时，如果不执行中断会一直阻塞。在下面介绍的shutdown方法中，会中断所有空闲的工作线程，如果在执行shutdown时工作线程没有空闲，然后又去调用了getTask方法，这时如果workQueue中没有任务了，调用workQueue.take()时就会一直阻塞。所以每次在工作线程结束时调用tryTerminate方法来尝试中断一个空闲工作线程，避免在队列为空时取任务一直阻塞的情况。</p><h5 id="shutdown方法"><a href="#shutdown方法" class="headerlink" title="shutdown方法"></a>shutdown方法</h5><p>shutdown方法要将线程池切换到SHUTDOWN状态，并调用interruptIdleWorkers方法请求中断所有空闲的worker，最后调用tryTerminate尝试结束线程池。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 安全策略判断</span></span><br><span class="line">        checkShutdownAccess();</span><br><span class="line">        <span class="comment">// 切换状态为SHUTDOWN</span></span><br><span class="line">        advanceRunState(SHUTDOWN);</span><br><span class="line">        <span class="comment">// 中断空闲线程</span></span><br><span class="line">        interruptIdleWorkers();</span><br><span class="line">        onShutdown(); <span class="comment">// hook for ScheduledThreadPoolExecutor</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 尝试结束线程池</span></span><br><span class="line">    tryTerminate();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里思考一个问题：在runWorker方法中，执行任务时对Worker对象w进行了lock操作，为什么要在执行任务的时候对每个工作线程都加锁呢？</p><p>下面仔细分析一下：</p><ul><li>在getTask方法中，如果这时线程池的状态是SHUTDOWN并且workQueue为空，那么就应该返回null来结束这个工作线程，而使线程池进入SHUTDOWN状态需要调用shutdown方法；</li><li>shutdown方法会调用interruptIdleWorkers来中断空闲的线程，interruptIdleWorkers持有mainLock，会遍历workers来逐个判断工作线程是否空闲。但getTask方法中没有mainLock；</li><li>在getTask中，如果判断当前线程池状态是RUNNING，并且阻塞队列为空，那么会调用workQueue.take()进行阻塞；</li><li>如果在判断当前线程池状态是RUNNING后，这时调用了shutdown方法把状态改为了SHUTDOWN，这时如果不进行中断，那么当前的工作线程在调用了workQueue.take()后会一直阻塞而不会被销毁，因为在SHUTDOWN状态下不允许再有新的任务添加到workQueue中，这样一来线程池永远都关闭不了了；</li><li>由上可知，shutdown方法与getTask方法（从队列中获取任务时）存在竞态条件；</li><li>解决这一问题就需要用到线程的中断，也就是为什么要用interruptIdleWorkers方法。在调用workQueue.take()时，如果发现当前线程在执行之前或者执行期间是中断状态，则会抛出InterruptedException，解除阻塞的状态；</li><li>但是要中断工作线程，还要判断工作线程是否是空闲的，如果工作线程正在处理任务，就不应该发生中断；</li><li>所以Worker继承自AQS，在工作线程处理任务时会进行lock，interruptIdleWorkers在进行中断时会使用tryLock来判断该工作线程是否正在处理任务，如果tryLock返回true，说明该工作线程当前未执行任务，这时才可以被中断。</li></ul><h5 id="interruptIdleWorkers方法"><a href="#interruptIdleWorkers方法" class="headerlink" title="interruptIdleWorkers方法"></a>interruptIdleWorkers方法</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">interruptIdleWorkers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    interruptIdleWorkers(<span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">interruptIdleWorkers</span><span class="params">(<span class="keyword">boolean</span> onlyOne)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (Worker w : workers) &#123;</span><br><span class="line">            Thread t = w.thread;</span><br><span class="line">            <span class="keyword">if</span> (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    t.interrupt();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (SecurityException ignore) &#123;</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    w.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (onlyOne)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>nterruptIdleWorkers遍历workers中所有的工作线程，若线程没有被中断tryLock成功，就中断该线程。</p><p>为什么需要持有mainLock？因为workers是HashSet类型的，不能保证线程安全。</p><h5 id="shutdownNow方法"><a href="#shutdownNow方法" class="headerlink" title="shutdownNow方法"></a>shutdownNow方法</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;Runnable&gt; <span class="title">shutdownNow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    List&lt;Runnable&gt; tasks;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        checkShutdownAccess();</span><br><span class="line">        advanceRunState(STOP);</span><br><span class="line">        <span class="comment">// 中断所有工作线程，无论是否空闲</span></span><br><span class="line">        interruptWorkers();</span><br><span class="line">        <span class="comment">// 取出队列中没有被执行的任务</span></span><br><span class="line">        tasks = drainQueue();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    tryTerminate();</span><br><span class="line">    <span class="keyword">return</span> tasks;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>shutdownNow方法与shutdown方法类似，不同的地方在于：</p><ul><li>设置状态为STOP；</li><li>中断所有工作线程，无论是否是空闲的；</li><li>取出阻塞队列中没有被执行的任务并返回。</li></ul><p>shutdownNow方法执行完之后调用tryTerminate方法，该方法在上文已经分析过了，目的就是使线程池的状态设置为TERMINATED。</p><h4 id="线程池的监控"><a href="#线程池的监控" class="headerlink" title="线程池的监控"></a>线程池的监控</h4><p>通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用</p><ul><li>getTaskCount：线程池已经执行的和未执行的任务总数；</li><li>getCompletedTaskCount：线程池已完成的任务数量，该值小于等于taskCount；</li><li>getLargestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过，也就是达到了maximumPoolSize；</li><li>getPoolSize：线程池当前的线程数量；</li><li>getActiveCount：当前线程池中正在执行任务的线程数量。</li></ul><p>通过这些方法，可以对线程池进行监控，在ThreadPoolExecutor类中提供了几个空方法，如beforeExecute方法，afterExecute方法和terminated方法，可以扩展这些方法在执行前或执行后增加一些新的操作，例如统计线程池的执行任务的时间等，可以继承自ThreadPoolExecutor来进行扩展。</p><h3 id="5-ScheduledExecutorService"><a href="#5-ScheduledExecutorService" class="headerlink" title="5. ScheduledExecutorService"></a>5. ScheduledExecutorService</h3><p>ScheduledExecutorService是一个接口，它继承于于ExecutorService。它相当于提供了”延时”和”周期执行”功能的ExecutorService。<br>ScheduledExecutorService提供了相应的函数接口，可以安排任务在给定的延迟后执行，也可以让任务周期的执行。</p><h3 id="6-ScheduledThreadPoolExecutor"><a href="#6-ScheduledThreadPoolExecutor" class="headerlink" title="6. ScheduledThreadPoolExecutor"></a>6. ScheduledThreadPoolExecutor</h3><p>ScheduledThreadPoolExecutor继承于ThreadPoolExecutor，并且实现了ScheduledExecutorService接口。它相当于提供了”延时”和”周期执行”功能的ScheduledExecutorService。<br>ScheduledThreadPoolExecutor类似于Timer，但是在高并发程序中，ScheduledThreadPoolExecutor的性能要优于Timer。</p><h3 id="7-Executors"><a href="#7-Executors" class="headerlink" title="7. Executors"></a>7. Executors</h3><p>Executors是个静态工厂类。它通过静态工厂方法返回ExecutorService、ScheduledExecutorService、ThreadFactory 和 Callable 等类的对象。</p><p>这里要注意，虽然Executors可以用静态方法来创建很多方便的线程池，但是我们在实际工作中发现，因为如果使用像newFixedThreadPool这种方式创建的线程池，会因为队列无限大，导致无法控制而出现内存溢出的问题，所以，我们创建线程池最优雅的方式是通过继承ThreadPoolExecutor，并重写相应的方法来处理。</p><p><strong><em>talk is cheap, let me show the code:</em></strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 任务处理线程池</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">WorkerPool</span> <span class="keyword">extends</span> <span class="title">ThreadPoolExecutor</span> </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="title">WorkerPool</span><span class="params">(<span class="keyword">int</span> coreSize, <span class="keyword">int</span> maxSize, <span class="keyword">long</span> keepAlive, TimeUnit timeUnit, BlockingQueue&lt;Runnable&gt; queue, ThreadFactory threadFactory)</span> </span>&#123;</span><br><span class="line">         <span class="keyword">super</span>(coreSize, maxSize, keepAlive, timeUnit, queue, threadFactory);</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">afterExecute</span><span class="params">(Runnable runnable, Throwable throwable)</span> </span>&#123;</span><br><span class="line">         <span class="keyword">super</span>.afterExecute(runnable, throwable);</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>这是我在项目中用到的手动构建线程池的简单示例，通过这种方式可以调用对应的构造方法，来构建你需要的线程池，包括参数的配置和策略的更换，只要你理解他是如何运行的，就可以轻松驾驭线程池，并发处理业务代码。</p><h2 id="博文参考"><a href="#博文参考" class="headerlink" title="博文参考"></a>博文参考</h2><p><a href="https://www.cnblogs.com/skywang12345/p/java_threads_category.html" target="_blank" rel="noopener">Java多线程系列目录(共43篇)</a></p><p><a href="https://www.cnblogs.com/liuzhihu/p/8177371.html" target="_blank" rel="noopener">深入理解Java线程池：ThreadPoolExecutor</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:54:22 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;线程池的架构图如下：&lt;br&gt;&lt;img src=&quot;/image/thread-8-0.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;&lt;h3 
      
    
    </summary>
    
      <category term="多线程" scheme="http://www.fufan.me/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
    
      <category term="多线程" scheme="http://www.fufan.me/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>python分布式爬虫利器——Scrapy+Scrapy-redis+Scrapyd+ScrapyWeb</title>
    <link href="http://www.fufan.me/2018/12/03/python%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E5%88%A9%E5%99%A8%E2%80%94%E2%80%94Scrapy-Scrapy-redis-Scrapyd-ScrapyWeb/"/>
    <id>http://www.fufan.me/2018/12/03/python分布式爬虫利器——Scrapy-Scrapy-redis-Scrapyd-ScrapyWeb/</id>
    <published>2018-12-03T09:28:08.000Z</published>
    <updated>2018-12-03T09:54:18.295Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>由于最近公司海外项目需要接一个泰国二手车平台的报价信息的客户需求，公网爬虫的话用python来做是最方便的，因此技术选型用Scrapy+Scrapy-redis+Scrapyd+Gerapy。</p><p>优势如下：</p><pre><code>* 简单、易维护* 分布式爬虫，更快（由于海外代理少且贵）* scrapy文档内容丰富* 等等。。</code></pre><ol><li><p>Scrapy：是一个基于Twisted的异步IO框架，有了这个框架，我们就不需要等待当前URL抓取完毕之后在进行下一个URL的抓取，抓取效率可以提高很多。</p></li><li><p>Scrapy-redis：虽然Scrapy框架是异步加多线程的，但是我们只能在一台主机上运行，爬取效率还是有限的，Scrapy-redis库为我们提供了Scrapy分布式的队列，调度器，去重等等功能，有了它，我们就可以将多台主机组合起来，共同完成一个爬取任务，抓取的效率又提高了。</p></li><li><p>Scrapyd：分布式爬虫完成之后，接下来就是代码部署，如果我们有很多主机，那就要逐个登录服务器进行部署，万一代码有所改动……….可以想象，这个过程是多么繁琐。Scrapyd是专门用来进行分布式部署的工具，它提供HTTP接口来帮助我们部署，启动，停止，删除爬虫程序，利用它我们可以很方便的完成Scrapy爬虫项目的部署。</p></li><li><p>ScrapyWeb：是一个基于Scrapyd，Scrapyd API，Django，nodejs搭建的分布式爬虫管理框架。简单点说，就是用上述的Scrapyd工具是在命令行进行操作，而Gerapy将命令行和图形界面进行了对接，我们只需要点击按钮就可完成部署，启动，停止，删除的操作。并且支持节点管理、爬虫监控，邮件发送等功能。</p></li></ol><h3 id="1-创建Scrapy项目"><a href="#1-创建Scrapy项目" class="headerlink" title="1. 创建Scrapy项目"></a>1. 创建Scrapy项目</h3><h3 id="2-添加Scrapy-redis配置"><a href="#2-添加Scrapy-redis配置" class="headerlink" title="2. 添加Scrapy-redis配置"></a>2. 添加Scrapy-redis配置</h3><h3 id="3-安装Scrapyd"><a href="#3-安装Scrapyd" class="headerlink" title="3. 安装Scrapyd"></a>3. 安装Scrapyd</h3><h3 id="4-强大的界面分布式管理scrapy进程——ScrapyWeb"><a href="#4-强大的界面分布式管理scrapy进程——ScrapyWeb" class="headerlink" title="4. 强大的界面分布式管理scrapy进程——ScrapyWeb"></a>4. 强大的界面分布式管理scrapy进程——ScrapyWeb</h3><h2 id="待续……"><a href="#待续……" class="headerlink" title="待续……"></a>待续……</h2><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;由于最近公司海外项目需要接一个泰国二手车平台的报价信息的客户需求，公网爬虫的话用python来做是最方便的，因此技术选型用S
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>学会写脚本系列（二）—— Python之dict(或对象)与json之间的互相转化</title>
    <link href="http://www.fufan.me/2018/11/22/%E5%AD%A6%E4%BC%9A%E5%86%99%E8%84%9A%E6%9C%AC%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94-Python%E4%B9%8Bdict-%E6%88%96%E5%AF%B9%E8%B1%A1-%E4%B8%8Ejson%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BA%92%E7%9B%B8%E8%BD%AC%E5%8C%96/"/>
    <id>http://www.fufan.me/2018/11/22/学会写脚本系列（二）——-Python之dict-或对象-与json之间的互相转化/</id>
    <published>2018-11-22T09:52:00.000Z</published>
    <updated>2018-11-22T09:52:30.480Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>在Python语言中，json数据与dict字典以及对象之间的转化，是必不可少的操作。</p><p>在Python中自带json库。通过import json导入。</p><p>在json模块有2个方法，</p><ul><li>loads()：将json数据转化成dict数据</li><li>dumps()：将dict数据转化成json数据</li><li>load()：读取json文件数据，转成dict数据</li><li>dump()：将dict数据转化成json数据后写入json文件</li></ul><p>示例如下：</p><h3 id="1-dict字典转json数据"><a href="#1-dict字典转json数据" class="headerlink" title="1. dict字典转json数据"></a>1. dict字典转json数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dict_to_json():</span><br><span class="line">    dict = &#123;&#125;</span><br><span class="line">    dict[&apos;name&apos;] = &apos;fufan&apos;</span><br><span class="line">    dict[&apos;age&apos;] = 25</span><br><span class="line">    dict[&apos;sex&apos;] = &apos;male&apos;</span><br><span class="line">    print(dict)  # 输出：&#123;&apos;name&apos;: &apos;fufan&apos;, &apos;age&apos;: 25, &apos;sex&apos;: &apos;male&apos;&#125;</span><br><span class="line">    j = json.dumps(dict)</span><br><span class="line">    print(j)  # 输出：&#123;&quot;name&quot;: &quot;fufan&quot;, &quot;age&quot;: 25, &quot;sex&quot;: &quot;male&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    dict_to_json()</span><br></pre></td></tr></table></figure><h3 id="2-对象转json数据"><a href="#2-对象转json数据" class="headerlink" title="2. 对象转json数据"></a>2. 对象转json数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line"></span><br><span class="line">class Student(object):</span><br><span class="line"></span><br><span class="line">    id = &apos;&apos;</span><br><span class="line">    name = &apos;&apos;</span><br><span class="line">    age = 0</span><br><span class="line">    gender = &apos;&apos;</span><br><span class="line">    phone = &apos;&apos;</span><br><span class="line">    email = &apos;&apos;</span><br><span class="line">    def __init__(self, id, name, age, gender, phone, email):</span><br><span class="line">        self.id = id</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.gender = gender</span><br><span class="line">        self.phone = phone</span><br><span class="line">        self.email = email</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def obj_to_json():</span><br><span class="line">    stu = Student(&apos;fufan&apos;, &apos;fufan&apos;, 28, &apos;male&apos;, &apos;13000000000&apos;, &apos;fufan@51dojo.com&apos;)</span><br><span class="line">    print(type(stu))  # &lt;class &apos;json_test.student.Student&apos;&gt;</span><br><span class="line">    stu = stu.__dict__  # 将对象转成dict字典</span><br><span class="line">    print(type(stu))  # &lt;class &apos;dict&apos;&gt;</span><br><span class="line">    print(stu)  # &#123;&apos;id&apos;: &apos;fufan&apos;, &apos;name&apos;: &apos;fufan&apos;, &apos;age&apos;: 28, &apos;gender&apos;: &apos;male&apos;, &apos;phone&apos;: &apos;13000000000&apos;, &apos;email&apos;: &apos;fufan@51dojo.com&apos;&#125;</span><br><span class="line">    j = json.dumps(obj=stu)</span><br><span class="line">    print(j)  # &#123;&quot;id&quot;: &quot;fufan&quot;, &quot;name&quot;: &quot;fufan&quot;, &quot;age&quot;: 28, &quot;gender&quot;: &quot;male&quot;, &quot;phone&quot;: &quot;13000000000&quot;, &quot;email&quot;: &quot;fufan@51dojo.com&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    obj_to_json()</span><br></pre></td></tr></table></figure><h3 id="3-json数据转成dict字典"><a href="#3-json数据转成dict字典" class="headerlink" title="3. json数据转成dict字典"></a>3. json数据转成dict字典</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">def json_to_dict():</span><br><span class="line">    j = &apos;&#123;&quot;id&quot;: &quot;fufan&quot;, &quot;name&quot;: &quot;fufan&quot;, &quot;age&quot;: 28, &quot;gender&quot;: &quot;male&quot;, &quot;phone&quot;: &quot;13000000000&quot;, &quot;email&quot;: &quot;fufan@51dojo.com&quot;&#125;&apos;</span><br><span class="line">    dict = json.loads(s=j)</span><br><span class="line">    print(dict)  # &#123;&apos;id&apos;: &apos;fufan&apos;, &apos;name&apos;: &apos;fufan&apos;, &apos;age&apos;: 28, &apos;gender&apos;: &apos;male&apos;, &apos;phone&apos;: &apos;13000000000&apos;, &apos;email&apos;: &apos;fufan@51dojo.com&apos;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    json_to_dict()</span><br></pre></td></tr></table></figure><h3 id="4-json数据转成对象"><a href="#4-json数据转成对象" class="headerlink" title="4. json数据转成对象"></a>4. json数据转成对象</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line"></span><br><span class="line">class Student(object):</span><br><span class="line"></span><br><span class="line">    id = &apos;&apos;</span><br><span class="line">    name = &apos;&apos;</span><br><span class="line">    age = 0</span><br><span class="line">    gender = &apos;&apos;</span><br><span class="line">    phone = &apos;&apos;</span><br><span class="line">    email = &apos;&apos;</span><br><span class="line"></span><br><span class="line">def json_to_obj():</span><br><span class="line">    j = &apos;&#123;&quot;id&quot;: &quot;fufan&quot;, &quot;name&quot;: &quot;fufan&quot;, &quot;age&quot;: 28, &quot;gender&quot;: &quot;male&quot;, &quot;phone&quot;: &quot;13000000000&quot;, &quot;email&quot;: &quot;fufan@51dojo.com&quot;&#125;&apos;</span><br><span class="line">    dict = json.loads(s=j)</span><br><span class="line">    stu = Student()</span><br><span class="line">    stu.__dict__ = dict</span><br><span class="line">    print(&apos;id: &apos; + stu.id + &apos; name: &apos; + stu.name + &apos; age: &apos; + str(stu.age) + &apos; gender: &apos; + str(</span><br><span class="line">        stu.gender) + &apos; phone: &apos; + stu.phone + &apos; email: &apos; + stu.email)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    json_to_obj()</span><br></pre></td></tr></table></figure><h3 id="5-dump-方法的使用"><a href="#5-dump-方法的使用" class="headerlink" title="5. dump()方法的使用"></a>5. dump()方法的使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line"></span><br><span class="line">def dict_to_json_write_file():</span><br><span class="line">    dict = &#123;&#125;</span><br><span class="line">    dict[&apos;name&apos;] = &apos;fufan&apos;</span><br><span class="line">    dict[&apos;age&apos;] = 26</span><br><span class="line">    dict[&apos;gender&apos;] = &apos;male&apos;</span><br><span class="line">    print(dict)  # &#123;&apos;name&apos;: &apos;fufan&apos;, &apos;age&apos;: 26, &apos;gender&apos;: &apos;male&apos;&#125;</span><br><span class="line">    with open(&apos;test.json&apos;, &apos;w&apos;) as f:</span><br><span class="line">        json.dump(dict, f)  # 会在目录下生成一个test.json的文件，文件内容是dict数据转成的json数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    dict_to_json_write_file()</span><br></pre></td></tr></table></figure><h3 id="6-load-的使用"><a href="#6-load-的使用" class="headerlink" title="6. load()的使用"></a>6. load()的使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line"></span><br><span class="line">def json_file_to_dict():</span><br><span class="line">    with open(&apos;test.json&apos;, &apos;r&apos;) as f:</span><br><span class="line">        dict = json.load(fp=f)</span><br><span class="line">        print(dict)  # &#123;&apos;name&apos;: &apos;fufan&apos;, &apos;age&apos;: 26, &apos;gender&apos;: &apos;male&apos;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    json_file_to_dict()</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;在Python语言中，json数据与dict字典以及对象之间的转化，是必不可少的操作。&lt;/p&gt;&lt;p&gt;在Python中自带js
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Spring获取bean的几种方式</title>
    <link href="http://www.fufan.me/2018/11/21/Spring%E8%8E%B7%E5%8F%96bean%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
    <id>http://www.fufan.me/2018/11/21/Spring获取bean的几种方式/</id>
    <published>2018-11-21T07:08:42.000Z</published>
    <updated>2018-11-21T07:09:22.255Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>Spring获取bean的几种方式</p><ol><li>在初始化时保存ApplicationContext对象</li><li>通过Spring提供的utils类获取ApplicationContext对象</li><li>继承自抽象类ApplicationObjectSupport</li><li>继承自抽象类WebApplicationObjectSupport</li><li>实现接口ApplicationContextAware （推荐）</li><li>通过Spring提供的ContextLoader</li></ol><h4 id="在初始化时保存ApplicationContext对象"><a href="#在初始化时保存ApplicationContext对象" class="headerlink" title="在初始化时保存ApplicationContext对象"></a>在初始化时保存ApplicationContext对象</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ApplicationContext ac = new FileSystemXmlApplicationContext(&quot;applicationContext.xml&quot;); </span><br><span class="line">ac.getBean(&quot;userService&quot;);//比如：&lt;bean id=&quot;userService&quot; class=&quot;com.cloud.service.impl.UserServiceImpl&quot;&gt;&lt;/bean&gt;</span><br></pre></td></tr></table></figure><p>这样的方式适用于採用Spring框架的独立应用程序，须要程序通过配置文件手工初始化Spring的情况。</p><h4 id="通过Spring提供的工具类获取ApplicationContext对象"><a href="#通过Spring提供的工具类获取ApplicationContext对象" class="headerlink" title="通过Spring提供的工具类获取ApplicationContext对象"></a>通过Spring提供的工具类获取ApplicationContext对象</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ApplicationContext ac1 = WebApplicationContextUtils.getRequiredWebApplicationContext(ServletContext sc); </span><br><span class="line">ApplicationContext ac2 = WebApplicationContextUtils.getWebApplicationContext(ServletContext sc); </span><br><span class="line">ac1.getBean(&quot;beanId&quot;); </span><br><span class="line">ac2.getBean(&quot;beanId&quot;);</span><br></pre></td></tr></table></figure><p>这样的方式适合于採用Spring框架的B/S系统，通过ServletContext对象获取ApplicationContext对象。然后在通过它获取须要的类实例。上面两个工具方式的差别是，前者在获取失败时抛出异常。后者返回null。</p><h4 id="继承自抽象类ApplicationObjectSupport"><a href="#继承自抽象类ApplicationObjectSupport" class="headerlink" title="继承自抽象类ApplicationObjectSupport"></a>继承自抽象类ApplicationObjectSupport</h4><p>抽象类ApplicationObjectSupport提供getApplicationContext()方法。能够方便的获取ApplicationContext。</p><p>Spring初始化时。会通过该抽象类的setApplicationContext(ApplicationContext context)方法将ApplicationContext 对象注入。</p><h4 id="继承自抽象类WebApplicationObjectSupport"><a href="#继承自抽象类WebApplicationObjectSupport" class="headerlink" title="继承自抽象类WebApplicationObjectSupport"></a>继承自抽象类WebApplicationObjectSupport</h4><p>类似上面方法。调用getWebApplicationContext()获取WebApplicationContext</p><h4 id="实现接口ApplicationContextAware"><a href="#实现接口ApplicationContextAware" class="headerlink" title="实现接口ApplicationContextAware"></a>实现接口ApplicationContextAware</h4><p>实现该接口的setApplicationContext(ApplicationContext context)方法，并保存ApplicationContext 对象。Spring初始化时，会通过该方法将ApplicationContext对象注入。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">@Slf4j</span><br><span class="line">public class ApplicationContextProvider implements ApplicationContextAware &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 上下文对象实例</span><br><span class="line">     */</span><br><span class="line">    private ApplicationContext applicationContext;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123;</span><br><span class="line">        this.applicationContext = applicationContext;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public ApplicationContext getApplicationContext() &#123;</span><br><span class="line">        return applicationContext;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 通过name获取 Bean.</span><br><span class="line">     * @param name</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public Object getBean(String name)&#123;</span><br><span class="line">        return getApplicationContext().getBean(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 通过class获取Bean.</span><br><span class="line">     * @param clazz</span><br><span class="line">     * @param &lt;T&gt;</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public &lt;T&gt; T getBean(Class&lt;T&gt; clazz)&#123;</span><br><span class="line">        return getApplicationContext().getBean(clazz);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 通过name,以及Clazz返回指定的Bean</span><br><span class="line">     * @param name</span><br><span class="line">     * @param clazz</span><br><span class="line">     * @param &lt;T&gt;</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public &lt;T&gt; T getBean(String name,Class&lt;T&gt; clazz)&#123;</span><br><span class="line">        return getApplicationContext().getBean(name, clazz);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此方法在工作中用的比较多，也是比较好的一种方法</p><h4 id="通过Spring提供的ContextLoader"><a href="#通过Spring提供的ContextLoader" class="headerlink" title="通过Spring提供的ContextLoader"></a>通过Spring提供的ContextLoader</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WebApplicationContext wac = ContextLoader.getCurrentWebApplicationContext();</span><br><span class="line">wac.getBean(beanID);</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;Spring获取bean的几种方式&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在初始化时保存ApplicationContext对象&lt;/li&gt;&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>学会写脚本系列（一）—— Python Requests包的使用</title>
    <link href="http://www.fufan.me/2018/11/19/%E5%AD%A6%E4%BC%9A%E5%86%99%E8%84%9A%E6%9C%AC%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94-Python-Requests%E5%8C%85%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://www.fufan.me/2018/11/19/学会写脚本系列（一）——-Python-Requests包的使用/</id>
    <published>2018-11-19T09:39:00.000Z</published>
    <updated>2018-11-22T09:40:11.818Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>由于公司的需求，平时需要测试一些公网爬虫，不过java在写小demo的时候太重的，所以必须要学点python、js、shell等语言来写一些脚本。所以平时抽空需要准备一些工具脚本，来支持临时测试。</p><p>今天我介绍用python来做批量跑http请求的脚本，刚好搜到了requests这个包，感觉用起来还挺方便的，具体的文档的话可以参考<a href="http://docs.python-requests.org/zh_CN/latest/" target="_blank" rel="noopener">中文官方文档</a>和<a href="http://www.python-requests.org/en/master/" target="_blank" rel="noopener">英文官方文档</a></p><p>requests是python的一个HTTP客户端库，跟urllib，urllib2类似，那为什么要用requests而不用urllib2呢？官方文档中是这样说明的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python的标准库urllib2提供了大部分需要的HTTP功能，但是API太逆天了，一个简单的功能就需要一大堆代码。</span><br></pre></td></tr></table></figure><p>官方网站设计的原则如下：</p><ul><li>Beautiful is better than ugly.(美丽优于丑陋)</li><li>Explicit is better than implicit.(清楚优于含糊)</li><li>Simple is better than complex.(简单优于复杂)</li><li>Complex is better than complicated.(复杂优于繁琐)</li><li>Readability counts.(重要的是可读性)</li></ul><h3 id="1-安装Request"><a href="#1-安装Request" class="headerlink" title="1. 安装Request"></a>1. 安装Request</h3><ul><li>pip安装<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure></li></ul><ul><li>源码安装<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone     git://github.com/kennethreitz/requests.git</span><br><span class="line">$ cd requests</span><br><span class="line">$ python setup.py install</span><br></pre></td></tr></table></figure></li></ul><ul><li>pycharm安装</li></ul><h3 id="2-快速上手"><a href="#2-快速上手" class="headerlink" title="2. 快速上手"></a>2. 快速上手</h3><p>既然官网的文档写的那么详细了，我这里就直接上例子了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">def do_http_test():</span><br><span class="line"></span><br><span class="line"># 请求url</span><br><span class="line">    url = &apos;https://s.weibo.com/ajax_User/follow&apos;</span><br><span class="line">    # header头，Cookie可以放在这里</span><br><span class="line">    headers = &#123;&apos;content-type&apos;: &quot;application/x-www-form-urlencoded&quot;,</span><br><span class="line">               &apos;Referer&apos;: &apos;https://s.weibo.com/user?q=%E6%B8%B8%E6%88%8F&apos;,</span><br><span class="line">               &apos;Cookie&apos;: &apos;SUB=_2A2528mffDeRhGeBJ4lUR9S3EyzyIHXVVht4XrDV8PUNbmtBeLUfekW9NRjmhG0VwLiyjpeOPdOk01GeypRYWWaEf&apos;&#125;</span><br><span class="line"></span><br><span class="line">    # post请求的请求data</span><br><span class="line">    payload = &#123;&apos;uid&apos;: &apos;5126161537&apos;, &apos;type&apos;: &apos;followed&apos;, &apos;action_code&apos;: &apos;71&apos;&#125;</span><br><span class="line"></span><br><span class="line">    # 具体调用的.post方法</span><br><span class="line">    r = requests.post(url, data = payload, headers = headers)</span><br><span class="line"></span><br><span class="line">    # 打印结果</span><br><span class="line">    print(r.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    do_http_test()</span><br></pre></td></tr></table></figure><h3 id="3-高级用法"><a href="#3-高级用法" class="headerlink" title="3. 高级用法"></a>3. 高级用法</h3><p>未完待续……</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;由于公司的需求，平时需要测试一些公网爬虫，不过java在写小demo的时候太重的，所以必须要学点python、js、shel
      
    
    </summary>
    
      <category term="python" scheme="http://www.fufan.me/categories/python/"/>
    
    
      <category term="python" scheme="http://www.fufan.me/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>聚簇索引和非聚簇索引</title>
    <link href="http://www.fufan.me/2018/11/16/%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E5%92%8C%E9%9D%9E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95/"/>
    <id>http://www.fufan.me/2018/11/16/聚簇索引和非聚簇索引/</id>
    <published>2018-11-16T09:37:00.000Z</published>
    <updated>2018-11-16T09:37:40.595Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>1、大多数表都应该有聚簇索引或使用分区来降低对表尾页的竞争，在一个高事务的环境中，对最后一页的封锁严重影响系统的吞吐量。<br>2、在聚簇索引下，数据在物理上按顺序排在数据页上，重复值也排在一起，因而在那些包含范围检查 (between、&lt;、&lt;=、&gt;、&gt;=)或使用group by或orderby的查询时，一旦找到具有范围中第一个键值的行，具有后续索引值的行保证物理上毗连在一起而不必进一步搜索，避免了大范围扫描，可以大 大提高查询速度。<br>3、在一个频繁发生插入操作的表上建立聚簇索引时，不要建在具有单调上升值的列(如IDENTITY)上，否则会经常引起封锁冲突。<br>4、在聚簇索引中不要包含经常修改的列，因为码值修改后，数据行必须移动到新的位置。<br>5、选择聚簇索引应基于where子句和连接操作的类型。</p><p>不知从什么角度来对比，只能说说各自的特点，希望对你有用。</p><h4 id="1、聚簇索引"><a href="#1、聚簇索引" class="headerlink" title="1、聚簇索引"></a>1、聚簇索引</h4><p>a) 一个索引项直接对应实际数据记录的存储页，可谓“直达”<br>b) 主键缺省使用它<br>c) 索引项的排序和数据行的存储排序完全一致，利用这一点，想修改数据的存储顺序，可以通过改变主键的方法（撤销原有主键，另找也能满足主键要求的一个字段或一组字段，重建主键）<br>d) 一个表只能有一个聚簇索引（理由：数据一旦存储，顺序只能有一种）</p><h4 id="2、非聚簇索引"><a href="#2、非聚簇索引" class="headerlink" title="2、非聚簇索引"></a>2、非聚簇索引</h4><p>a) 不能“直达”，可能链式地访问多级页表后，才能定位到数据页<br>b) 一个表可以有多个非聚簇索引</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;1、大多数表都应该有聚簇索引或使用分区来降低对表尾页的竞争，在一个高事务的环境中，对最后一页的封锁严重影响系统的吞吐量。&lt;b
      
    
    </summary>
    
      <category term="数据库" scheme="http://www.fufan.me/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="http://www.fufan.me/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>从session到token</title>
    <link href="http://www.fufan.me/2018/11/14/%E4%BB%8Esession%E5%88%B0token/"/>
    <id>http://www.fufan.me/2018/11/14/从session到token/</id>
    <published>2018-11-14T06:15:00.000Z</published>
    <updated>2018-11-14T07:34:31.747Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><h3 id="很久以前"><a href="#很久以前" class="headerlink" title="很久以前"></a>很久以前</h3><p>30年前，互联网刚起步的时候，大部分的web请求基本都是在浏览网页，既然是浏览，作为一个服务器， 为什么要记住谁在一段时间里都浏览了什么文档呢？</p><h3 id="开始记录session"><a href="#开始记录session" class="headerlink" title="开始记录session"></a>开始记录session</h3><p>但是好日子没持续多久， 很快大家就不满足于静态的Html 文档了， 交互式的Web应用开始兴起， 尤其是论坛， 在线购物等网站。那么必须记住哪些人登录系统， 哪些人往自己的购物车中放了商品， 也就是说必须把每个人区分开。</p><p>由于HTTP协议的无状态特性， 我必须加点小手段，才能完成会话管理。</p><p>所以在这个时候，服务器端一般会使用sessionId（会话标识）来标识该用户在一段时间内的请求，其实就是一个随机的字符串。这样每次请求过来，服务器端需要区分谁是谁。</p><h3 id="沉重的负担"><a href="#沉重的负担" class="headerlink" title="沉重的负担"></a>沉重的负担</h3><p>由于互联网的飞速发展，web请求量剧增，导致服务器压力增大，同时开销也增大。比如每个人只需要保存自己的session id，而服务器需要保存所有人的session id 。</p><p>虽然可以通过分布式集群扩展服务能力，但是这里又会出现session分布的问题。比如说我用两个机器组成了一个集群， 小F通过机器A登录了系统， 那session id会保存在机器A上， 假设小F的下一次请求被转发到机器B怎么办？ 机器B可没有小F的 session id啊。</p><p>虽然session sticky、缓存可以在一定程度上解决该问题，但是都会存在单点故障、机器宕机的问题。导致可靠性降低，同时增大了服务器的架构复杂度，不便于后期的扩展和维护。</p><h3 id="时间换空间"><a href="#时间换空间" class="headerlink" title="时间换空间"></a>时间换空间</h3><p>同时，session的安全性也是一个隐患，不怀好意的人可以通过伪造sessionId来请求。</p><p>渐渐地，很多网站开始使用JWT、UUID的方式登录或者保存用户状态信息。</p><p><a href="https://jwt.io/" target="_blank" rel="noopener">JWT</a>是json web token缩写。它将用户信息加密到token里，服务器不保存任何用户信息。服务器通过使用保存的密钥验证token的正确性，只要正确即通过验证。</p><ul><li>优点是在分布式系统中，很好地解决了单点登录问题，很容易解决了session共享的问题。</li><li>缺点是无法作废已颁布的令牌/不易应对数据过期。</li></ul><p>这样的话，就无状态的用token来替代了session，用CPU的计算时间来替换session的存储空间</p><p>JWT 的实践其实还是挺简单。安全性也是得到了保证，后端只需要保存着密匙，其他数据可以保存在token，由前端携带，这样可以减低后端的内心消耗。<br>虽然token是加密的，但是携带的验证数据还是不要是敏感数据.</p><h3 id="思想的迁移"><a href="#思想的迁移" class="headerlink" title="思想的迁移"></a>思想的迁移</h3><p>目前公司爬虫业务也有类似的问题，我们每一个任务的taskId是通过生成一个UUID来绑定和溯源的，这样可以保证全局唯一性，是很好的对分布式系统任务分离的一个实践。UUID生成的规则:</p><p><img src="/image/session-token-0.png" alt=""></p><p>如图所示，这里第1位不可用，前41位表示时间，中间10位用来表示工作机器的id，后12位的序列号.<br>其中时间比较好理解，工作机器id则是机器标识，序列号是一个自增序列。有多少位表示在这一个单位时间内，此机器最多可以支持2^12个并发。在进入下一个时间单位后，序列号归0。</p><p>虽然这种模式再生产上单日百万量级的服务已经实践了一年多，微服务的切分也是达到了40-50个之多，但是会发现有一个问题，就是token里未带任何任务相关的信息，而随着我们的业务量的增长，遇到的单点故障及其他复杂问题也增加（特别是aliyun中redis中间件常常会出现闪断等问题，包括db、oss、ots等都会有类似的情况）。所以要完全解决这种方式的话，就必须要有主备环境，随时切换，以应对单点故障带来对服务的影响（毕竟是24*7的服务，出一次事故对客户带来损失巨大）。</p><p>而切换环境的瞬间，情况复杂度也是非常复杂的，因为你首先要保证之前的任务是正常在老环境里跑的，而新的任务也要按比例分流到新环境中来，但是需要让用户是无感知切换的话，入口是不能变的。所以我们就会考虑后端其他的微服务如何去将gateway中生成的taskId分配到哪个环境中。</p><p>因为环境完全是两套，假设我们分为C区任务和D区任务，而如果能够在taskId中添加一位来表示是哪个区的话，就可以路由到哪个环境中去正常的执行下去。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;很久以前&quot;&gt;&lt;a href=&quot;#很久以前&quot; class=&quot;headerlink&quot; title=&quot;很久以前&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="分布式" scheme="http://www.fufan.me/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="jwt" scheme="http://www.fufan.me/tags/jwt/"/>
    
  </entry>
  
  <entry>
    <title>JVM专题（八）---强、软、弱、虚的知识点总结</title>
    <link href="http://www.fufan.me/2018/11/13/Java%E5%9B%9B%E7%A7%8D%E5%BC%95%E7%94%A8-%E5%BC%BA%E3%80%81%E8%BD%AF%E3%80%81%E5%BC%B1%E3%80%81%E8%99%9A%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    <id>http://www.fufan.me/2018/11/13/Java四种引用-强、软、弱、虚的知识点总结/</id>
    <published>2018-11-13T09:47:00.000Z</published>
    <updated>2018-11-14T03:27:48.331Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>本文会按照以下思路进行：<br><a href="#1">（1）Java的四种对象引用的基本概念</a><br><br><a href="#2">（2）四种对象引用的差异对比</a><br><br><a href="#3">（3）对象可及性的判断以及与垃圾回收机制的关系</a><br><br><a href="#4">（4）引用队列ReferenceQueue的介绍</a><br><br><a href="#5">（5）WeakHashMap的相关介绍</a><br></p><h3 id="1">Java的四种对象引用的基本概念</h3><p>从JDK1.2版本开始，把对象的引用分为四种级别，从而使程序更加灵活的控制对象的生命周期。这四种级别由高到低依次为：强引用、软引用、弱引用和虚引用。</p><h4 id="1、强引用"><a href="#1、强引用" class="headerlink" title="1、强引用"></a>1、强引用</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Object obj =new Object();</span><br></pre></td></tr></table></figure><p>上述Object这类对象就具有强引用，属于不可回收的资源，垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠回收具有强引用的对象，来解决内存不足的问题。</p><p>值得注意的是：如果想中断或者回收强引用对象，可以显式地将引用赋值为null，这样的话JVM就会在合适的时间，进行垃圾回收。</p><p>下图是堆区的内存示意图，分为新生代，老生代，而垃圾回收主要也是在这部分区域中进行。</p><p><img src="/image/java_reference-0.png" alt=""></p><h4 id="2、软引用（SoftReference）"><a href="#2、软引用（SoftReference）" class="headerlink" title="2、软引用（SoftReference）"></a>2、软引用（SoftReference）</h4><p>如果一个对象只具有软引用，那么它的性质属于可有可无的那种。如果此时内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。</p><p>软引用可用来实现内存敏感的告诉缓存。软引用可以和一个引用队列联合使用，如果软件用所引用的对象被垃圾回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Object obj = new Object();</span><br><span class="line">       ReferenceQueue queue = new ReferenceQueue();</span><br><span class="line">       SoftReference reference = new SoftReference(obj, queue);</span><br><span class="line">       //强引用对象滞空，保留软引用</span><br><span class="line">       obj = null;</span><br></pre></td></tr></table></figure><p>当内存不足时，软引用对象被回收时，reference.get()为null，此时软引用对象的作用已经发挥完毕，这时将其添加进ReferenceQueue 队列中</p><p>如果要判断哪些软引用对象已经被清理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SoftReference ref = null;</span><br><span class="line">        while ((ref = (SoftReference) queue.poll()) != null) &#123;</span><br><span class="line">            //清除软引用对象</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h4 id="3、弱引用-WeakReference"><a href="#3、弱引用-WeakReference" class="headerlink" title="3、弱引用(WeakReference)"></a>3、弱引用(WeakReference)</h4><p>如果一个对象具有弱引用，那其的性质也是可有可无的状态。</p><p>而弱引用和软引用的区别在于：弱引用的对象拥有更短的生命周期，只要垃圾回收器扫描到它，不管内存空间充足与否，都会回收它的内存。</p><p>同样的弱引用也可以和引用队列一起使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Object obj = new Object();</span><br><span class="line">        ReferenceQueue queue = new ReferenceQueue();</span><br><span class="line">        WeakReference reference = new WeakReference(obj, queue);</span><br><span class="line">        //强引用对象滞空，保留软引用</span><br><span class="line">        obj = null;</span><br></pre></td></tr></table></figure><h4 id="4、虚引用（PhantomReference）"><a href="#4、虚引用（PhantomReference）" class="headerlink" title="4、虚引用（PhantomReference）"></a>4、虚引用（PhantomReference）</h4><p>虚引用和前面的软引用、弱引用不同，它并不影响对象的生命周期。如果一个对象与虚引用关联，则跟没有引用与之关联一样，在任何时候都可能被垃圾回收器回收。</p><p>注意：虚引用必须和引用队列关联使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之关联的引用队列中。</p><p>程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Object obj = new Object();</span><br><span class="line">        ReferenceQueue queue = new ReferenceQueue();</span><br><span class="line">        PhantomReference reference = new PhantomReference(obj, queue);</span><br><span class="line">        //强引用对象滞空，保留软引用</span><br><span class="line">        obj = null;</span><br></pre></td></tr></table></figure><p>引用总结</p><p>1.对于强引用，平时在编写代码时会经常使用。</p><p>2.而其他三种类型的引用，使用得最多就是软引用和弱引用，这两种既有相似之处又有区别，他们都来描述非必须对象。</p><p>3.被软引用关联的对象只有在内存不足时才会被回收，而被弱引用关联的对象在JVM进行垃圾回收时总会被回收。</p><p><img src="/image/java_reference-1.png" alt=""></p><h3 id="2">四种对象引用的差异对比</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">强引用 &gt; 软引用 &gt; 弱引用 &gt; 虚引用</span><br></pre></td></tr></table></figure><p><img src="/image/java_reference-2.png" alt=""></p><p>最后总结成一张表格：</p><table><thead><tr><th>引用类型</th><th>被垃圾回收时间</th><th>用途</th><th>生存时间</th></tr></thead><tbody><tr><td>强引用</td><td>从来不会</td><td>对象的一般状态</td><td>JVM停止运行时终止</td></tr><tr><td>软引用</td><td>在内存不足时</td><td>对象缓存</td><td>内存不足时终止</td></tr><tr><td>弱引用</td><td>在垃圾回收时</td><td>对象缓存</td><td>垃圾回收时终止</td></tr><tr><td>虚引用</td><td>Unkonwn</td><td>Unkonwn</td><td>Unkonwn</td></tr></tbody></table><h3 id="3">对象可及性的判断</h3><p>在很多的时候，一个对象并不是从根集直接引用的，而是一个对象被其他对象引用，甚至同时被几个对象所引用，从而构成一个以根集为顶的树形结构。</p><p><img src="/image/java_reference-3.png" alt=""></p><p>在这个树形的引用链中，箭头的方向代表了引用的方向，所指向的对象是被引用对象。由图可以看出，从根集到一个对象可以由很多条路径。</p><p>比如到达对象5的路径就有① -&gt; ⑤，③ -&gt;⑦两条路径。由此带来了一个问题，那就是某个对象的可及性如何判断：</p><p>（1）单条引用路径可及性判断：</p><p>在这条路径中，最弱的一个引用决定对象的可及性。</p><p>（2）多条引用路径可及性判断：</p><p>几条路径中，最强的一条的引用决定对象的可及性。</p><p>比如，我们假设图2中引用①和③为强引用，⑤为软引用，⑦为弱引用，对于对象5按照这两个判断原则，路径①-⑤取最弱的引用⑤，因此该路径对对象5的引用为软引用。同样，③-⑦为弱引用。在这两条路径之间取最强的引用，于是对象5是一个软可及对象。</p><p>另外两个重要的点：</p><p>**1. 强可达的对象一定不会被清理</p><ol start="2"><li>JVM保证抛出out of memory之前，清理所有的软引用对象**</li></ol><h3 id="4">引用队列ReferenceQueue的介绍</h3><p>引用队列配合Reference的子类等使用,当引用对象所指向的对象被垃圾回收后,该Reference则被追加到引用队列的末尾.</p><h3 id="5">WeakHashMap的相关介绍</h3><p>在Java集合中有一种特殊的Map类型即WeakHashMap,在这种Map中存放了键对象的弱引用,当一个键对象被垃圾回收器回收时,那么相应的值对象的引用会从Map中删除.</p><p>WeakHashMap能够节约储存空间,可用来缓存那些非必须存在的数据.</p><p>而WeakHashMap是主要通过expungeStaleEntries()这个方法来实现的,而WeakHashMap也内置了一个ReferenceQueue,来获取键对象的引用情况.</p><p>这个方法,相当于遍历ReferenceQueue然后,将已经被回收的键对象,对应的值对象滞空.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">private void expungeStaleEntries() &#123;</span><br><span class="line">        for (Object x; (x = queue.poll()) != null; ) &#123;</span><br><span class="line">            synchronized (queue) &#123;</span><br><span class="line">                @SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">                    Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) x;</span><br><span class="line">                int i = indexFor(e.hash, table.length);</span><br><span class="line"></span><br><span class="line">                Entry&lt;K,V&gt; prev = table[i];</span><br><span class="line">                Entry&lt;K,V&gt; p = prev;</span><br><span class="line">                while (p != null) &#123;</span><br><span class="line">                    Entry&lt;K,V&gt; next = p.next;</span><br><span class="line">                    if (p == e) &#123;</span><br><span class="line">                        if (prev == e)</span><br><span class="line">                            table[i] = next;</span><br><span class="line">                        else</span><br><span class="line">                            prev.next = next;</span><br><span class="line">                        // Must not null out e.next;</span><br><span class="line">                        // stale entries may be in use by a HashIterator</span><br><span class="line">                        //通过滞空,来帮助垃圾回收</span><br><span class="line">                        e.value = null; </span><br><span class="line">                        size--;</span><br><span class="line">                        break;</span><br><span class="line">                    &#125;</span><br><span class="line">                    prev = p;</span><br><span class="line">                    p = next;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>而且需要注意的是:</p><p>expungeStaleEntries()并不是自动调用的,需要外部对WeakHashMap对象进行查询或者操作,才会进行自动释放的操作</p><p>来一张总结图:</p><p><img src="/image/java_reference-4.png" alt=""></p><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p><a href="https://blog.csdn.net/l540675759/article/details/73733763" target="_blank" rel="noopener">Java四种引用—强、软、弱、虚的知识点总结</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;本文会按照以下思路进行：&lt;br&gt;&lt;a href=&quot;#1&quot;&gt;（1）Java的四种对象引用的基本概念&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;a
      
    
    </summary>
    
      <category term="jvm" scheme="http://www.fufan.me/categories/jvm/"/>
    
    
      <category term="jvm" scheme="http://www.fufan.me/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>QPS/TPS/并发量/系统吞吐量的概念</title>
    <link href="http://www.fufan.me/2018/11/11/QPS-TPS-%E5%B9%B6%E5%8F%91%E9%87%8F-%E7%B3%BB%E7%BB%9F%E5%90%9E%E5%90%90%E9%87%8F%E7%9A%84%E6%A6%82%E5%BF%B5/"/>
    <id>http://www.fufan.me/2018/11/11/QPS-TPS-并发量-系统吞吐量的概念/</id>
    <published>2018-11-11T07:52:32.000Z</published>
    <updated>2018-11-11T07:53:00.332Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><h3 id="系统吞吐量的关键参数"><a href="#系统吞吐量的关键参数" class="headerlink" title="系统吞吐量的关键参数"></a>系统吞吐量的关键参数</h3><p>一个系统的吞度量（承压能力）与request对CPU的消耗、外部接口、IO等等紧密关联。单个reqeust 对CPU消耗越高，外部系统接口、IO影响速度越慢。系统吞吐能力越低，反之越高。</p><ul><li><p>QPS: 每秒钟处理完请求的次数；注意这里是处理完。具体是指发出请求到服务器处理完成功返回结果。可以理解在server中有个counter，每处理一个请求加1，1秒后counter=QPS。</p></li><li><p>TPS：每秒钟处理完的事务次数，一般TPS是对整个系统来讲的。一个应用系统1s能完成多少事务处理，一个事务在分布式处理中，可能会对应多个请求，对于衡量单个接口服务的处理能力，用QPS比较多。</p></li><li><p>并发量：系统能同时处理的请求数</p></li><li><p>RT：响应时间，处理一次请求所需要的平均处理时间</p></li></ul><p>计算关系：</p><ul><li><p>QPS = 并发量 / 平均响应时间</p></li><li><p>并发量 = QPS * 平均响应时间</p></li></ul><p>一个典型的上班签到系统，早上8点上班。7点半到8点这30分钟的时间里用户会登录签到系统进行签到。公司员工为1000人，平均每一个员上登录签到系统的时长为5分钟。能够用以下的方法计算：</p><p>QPS = 1000/(30<em>60) 事务/秒<br>平均响应时间为 = 5 </em>60 秒<br>并发数= QPS<em>平均响应时间 = 1000/(30 </em>60) <em>(5 </em>60)=166.7</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;系统吞吐量的关键参数&quot;&gt;&lt;a href=&quot;#系统吞吐量的关键参数&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>centos安装python3.6（亲测爬坑）</title>
    <link href="http://www.fufan.me/2018/11/03/centos%E5%AE%89%E8%A3%85python3-6%EF%BC%88%E4%BA%B2%E6%B5%8B%E7%88%AC%E5%9D%91%EF%BC%89/"/>
    <id>http://www.fufan.me/2018/11/03/centos安装python3-6（亲测爬坑）/</id>
    <published>2018-11-03T09:26:00.000Z</published>
    <updated>2018-12-03T09:27:35.374Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><h4 id="1-安装可能用到的依赖"><a href="#1-安装可能用到的依赖" class="headerlink" title="1. 安装可能用到的依赖"></a>1. 安装可能用到的依赖</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y openssl-devel bzip2-devel expat-devel gdbm-devel readline-devel sqlite-devel zlib-devel</span><br></pre></td></tr></table></figure><h4 id="2-下载Python3-6-5源码"><a href="#2-下载Python3-6-5源码" class="headerlink" title="2. 下载Python3.6.5源码"></a>2. 下载Python3.6.5源码</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz</span><br></pre></td></tr></table></figure><h4 id="3-解压到当前目录"><a href="#3-解压到当前目录" class="headerlink" title="3. 解压到当前目录"></a>3. 解压到当前目录</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar -xzvf Python-3.6.5.tgz</span><br></pre></td></tr></table></figure><h4 id="4-进入解压后的目录"><a href="#4-进入解压后的目录" class="headerlink" title="4. 进入解压后的目录"></a>4. 进入解压后的目录</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> Python-3.6.5</span><br></pre></td></tr></table></figure><h4 id="5-安装到-usr-local-python目录，不用事先创建python目录"><a href="#5-安装到-usr-local-python目录，不用事先创建python目录" class="headerlink" title="5. 安装到/usr/local/python目录，不用事先创建python目录"></a>5. 安装到/usr/local/python目录，不用事先创建python目录</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./configure --prefix=/usr/<span class="built_in">local</span>/python</span><br></pre></td></tr></table></figure><h4 id="6-编译"><a href="#6-编译" class="headerlink" title="6. 编译"></a>6. 编译</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ make</span><br></pre></td></tr></table></figure><h4 id="7-安装"><a href="#7-安装" class="headerlink" title="7. 安装"></a>7. 安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ make altinstall</span><br></pre></td></tr></table></figure><h4 id="8-进入-usr-bin目录"><a href="#8-进入-usr-bin目录" class="headerlink" title="8. 进入/usr/bin目录"></a>8. 进入/usr/bin目录</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /usr/bin</span><br></pre></td></tr></table></figure><h4 id="9-重命名python2的快捷方式"><a href="#9-重命名python2的快捷方式" class="headerlink" title="9. 重命名python2的快捷方式"></a>9. 重命名python2的快捷方式</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mv python python.bak</span><br><span class="line">$ mv pip pip.bak</span><br></pre></td></tr></table></figure><h4 id="10-创建python3与pip3软连接"><a href="#10-创建python3与pip3软连接" class="headerlink" title="10. 创建python3与pip3软连接"></a>10. 创建python3与pip3软连接</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ln -s /usr/<span class="built_in">local</span>/python/bin/python3.6 /usr/bin/python</span><br><span class="line">$ ln -s /usr/<span class="built_in">local</span>/python/bin/pip3.6 /usr/bin/pip</span><br></pre></td></tr></table></figure><h4 id="10-修改环境变量"><a href="#10-修改环境变量" class="headerlink" title="10. 修改环境变量"></a>10. 修改环境变量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vi ~/.bash_profile</span><br><span class="line"><span class="comment"># 然后在.bash_profile中添加一行 export PATH=$PATH:/usr/local/python/bin，保存</span></span><br><span class="line">$ <span class="built_in">source</span> ~/.bash_profile</span><br></pre></td></tr></table></figure><h4 id="11-测试是否安装成功"><a href="#11-测试是否安装成功" class="headerlink" title="11. 测试是否安装成功"></a>11. 测试是否安装成功</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@server83 ~]<span class="comment"># python -V</span></span><br><span class="line">Python 3.6.5</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@server83 ~]<span class="comment"># pip -V</span></span><br><span class="line">pip 18.1 from /usr/<span class="built_in">local</span>/python/lib/python3.6/site-packages/pip (python 3.6)</span><br></pre></td></tr></table></figure><h4 id="12-修改yum的配置"><a href="#12-修改yum的配置" class="headerlink" title="12. 修改yum的配置"></a>12. 修改yum的配置</h4><p>由于通过此方法来安装会导致yum的执行命令有问题，需要修改yum的python版本配置</p><ul><li>问题出现原因：<br>yum包管理是使用python2.x写的，将python2.x升级到python3.1.3以后，由于python版本语法兼容性导致问题出现</li></ul><ul><li>解决办法：</li></ul><ol><li>修改yum配置文件，将python版本指向以前的旧版本</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vi /usr/bin/yum</span><br><span class="line"><span class="comment">#!/usr/bin/python2.7</span></span><br></pre></td></tr></table></figure><ol start="2"><li>修改urlgrabber-ext-down文件，更改python版本</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vi /usr/libexec/urlgrabber-ext-down</span><br><span class="line"><span class="comment">#!/usr/bin/python2.7</span></span><br></pre></td></tr></table></figure><h4 id="13-升级pip"><a href="#13-升级pip" class="headerlink" title="13. 升级pip"></a>13. 升级pip</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install --upgrade pip</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;h4 id=&quot;1-安装可能用到的依赖&quot;&gt;&lt;a href=&quot;#1-安装可能用到的依赖&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
      <category term="python" scheme="http://www.fufan.me/categories/python/"/>
    
    
      <category term="python" scheme="http://www.fufan.me/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Java常用集合源码分析之map遍历效率比较（六）</title>
    <link href="http://www.fufan.me/2018/06/19/Java%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8Bmap%E9%81%8D%E5%8E%86%E6%95%88%E7%8E%87%E6%AF%94%E8%BE%83%EF%BC%88%E5%85%AD%EF%BC%89/"/>
    <id>http://www.fufan.me/2018/06/19/Java常用集合源码分析之map遍历效率比较（六）/</id>
    <published>2018-06-19T14:21:00.000Z</published>
    <updated>2018-11-11T14:21:41.799Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><h3 id="遍历方式"><a href="#遍历方式" class="headerlink" title="遍历方式"></a>遍历方式</h3><h4 id="1-遍历key"><a href="#1-遍历key" class="headerlink" title="1. 遍历key"></a>1. 遍历key</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (String key : map.keySet()) &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-遍历value"><a href="#2-遍历value" class="headerlink" title="2. 遍历value"></a>2. 遍历value</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (String value : map.values()) &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-遍历key-value"><a href="#3-遍历key-value" class="headerlink" title="3. 遍历key+value"></a>3. 遍历key+value</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for (Entry&lt;String, String&gt; entry: map.entrySet()) &#123;</span><br><span class="line"></span><br><span class="line">    key = entry.getKey();</span><br><span class="line"></span><br><span class="line">    value = entry.getValue();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="如果你使用HashMap"><a href="#如果你使用HashMap" class="headerlink" title="如果你使用HashMap"></a>如果你使用HashMap</h3><ol><li>同时遍历key和value时，keySet与entrySet方法的性能差异取决于key的复杂度，总体来说还是推荐使用entrySet。换言之，取决于HashMap查找value的开销。entrySet一次性取出所有key和value的操作是有性能开销的，当这个损失小于HashMap查找value的开销时，entrySet的性能优势就会体现出来。例如上述对比测试中，当key是最简单的数值字符串时，keySet可能反而会更高效，耗时比entrySet少10%。总体来说还是推荐使用entrySet。因为当key很简单时，其性能或许会略低于keySet，但却是可控的；而随着key的复杂化，entrySet的优势将会明显体现出来。当然，我们可以根据实际情况进行选择</li><li>只遍历key时，keySet方法更为合适，因为entrySet将无用的value也给取出来了，浪费了性能和空间。在上述测试结果中，keySet比entrySet方法耗时少23%。</li><li>只遍历value时，使用vlaues方法是最佳选择，entrySet会略好于keySet方法。</li></ol><h3 id="如果你使用TreeMap"><a href="#如果你使用TreeMap" class="headerlink" title="如果你使用TreeMap"></a>如果你使用TreeMap</h3><ol><li>同时遍历key和value时，entrySet的性能远远高于keySet。这是由TreeMap的查询效率决定的，也就是说，TreeMap查找value的开销较大，明显高于entrySet一次性取出所有key和value的开销。因此，遍历TreeMap时强烈推荐使用entrySet方法。</li><li>只遍历key时，keySet方法更为合适，因为entrySet将无用的value也给取出来了，浪费了性能和空间。在上述测试结果中，keySet比entrySet方法耗时少24%。</li><li>只遍历value时，使用vlaues方法是最佳选择，entrySet也明显优于keySet方法。</li></ol><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;遍历方式&quot;&gt;&lt;a href=&quot;#遍历方式&quot; class=&quot;headerlink&quot; title=&quot;遍历方式&quot;&gt;&lt;/a
      
    
    </summary>
    
    
      <category term="集合" scheme="http://www.fufan.me/tags/%E9%9B%86%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>JVM专题（四）—— 图解垃圾回收</title>
    <link href="http://www.fufan.me/2018/06/09/JVM%E4%B8%93%E9%A2%98%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94-%E5%9B%BE%E8%A7%A3%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <id>http://www.fufan.me/2018/06/09/JVM专题（四）——-图解垃圾回收/</id>
    <published>2018-06-09T09:00:00.000Z</published>
    <updated>2018-11-09T09:01:08.471Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>对于调优之前，我们必须要了解其运行原理，java 的垃圾收集Garbage Collection 通常被称为“GC”，它诞生于1960年 MIT 的 Lisp 语言，经过半个多世纪，目前已经十分成熟了。因此本篇主要从这三个方面来了解:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 哪些对象需要被回收？</span><br><span class="line"></span><br><span class="line">2. 什么时候回收？</span><br><span class="line"></span><br><span class="line">3. 如何回收？</span><br></pre></td></tr></table></figure><h3 id="一、谁要被回收"><a href="#一、谁要被回收" class="headerlink" title="一、谁要被回收"></a>一、谁要被回收</h3><p>java虚拟机在执行java程序的过程中会把它所管理的内存划分为若干个不同是数据区域，这些区域有各自各自的用途。主要包含以下几个部分组成：<br><img src="/image/jvm-4-1.png" alt=""><br><img src="/image/jvm-4-0.png" alt=""></p><h4 id="1、程序计数器"><a href="#1、程序计数器" class="headerlink" title="1、程序计数器"></a>1、程序计数器</h4><p>程序计数器占用的内存空间我们可以忽略不计，它是每个线程所执行的字节码的行号指示器。</p><h4 id="2、虚拟机栈"><a href="#2、虚拟机栈" class="headerlink" title="2、虚拟机栈"></a>2、虚拟机栈</h4><p>java的虚拟机栈是线程私有的，生命周期和线程相同。它描述的是方法执行的内存模型。同时用于存储局部变量、操作数栈、动态链接、方法出口等。</p><h4 id="3、本地方法栈"><a href="#3、本地方法栈" class="headerlink" title="3、本地方法栈"></a>3、本地方法栈</h4><p>本地方法栈，类似虚拟机栈，它调用的是是native方法。</p><h4 id="4、堆"><a href="#4、堆" class="headerlink" title="4、堆"></a>4、堆</h4><p>堆是jvm中管理内存中最大一块。它是被共享，存放对象实例。也被称为“gc堆”。垃圾回收的主要管理区域</p><h4 id="5、方法区"><a href="#5、方法区" class="headerlink" title="5、方法区"></a>5、方法区</h4><p>方法区也是共享的内存区域。它主要存储已被虚拟机加载的类信息、常量、静态变量、即时编译器（jit）编译后的代码数据。</p><p>以上就是jvm在运行时期主要的内存组成，我们看到常见的内存使用不但存在于堆中，还会存在于其他区域，虽然堆的管理对程序的管理至关重要，但我们不能只局限于这一个区域，特别是当出现内存泄露的时候，我们除了要排查堆内存的情况，还得考虑虚拟机栈的以及方法区域的情况。</p><p>知道了要对谁以及那些区域进行内存管理，我还需要知道什么时候对这些区域进行垃圾回收。</p><h3 id="二、什么时候回收"><a href="#二、什么时候回收" class="headerlink" title="二、什么时候回收"></a>二、什么时候回收</h3><p>在垃圾回收之前，我们必须确定的一件事就是对象是否存活？这就牵扯到了判断对象是否存活的算法了。</p><h4 id="引用计数算法："><a href="#引用计数算法：" class="headerlink" title="引用计数算法："></a>引用计数算法：</h4><p>给对象中添加一个引用计数器，每当有一个地方引用它时，计数器+1，当引用失效，计数器-1.任何时刻计数器为0的对象就是不可能再被使用的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给对象中添加一个引用计数器，每当有一个地方引用它时，计数器+1，当引用失效，计数器-1.任何时刻计数器为0的对象就是不可能再被使用的。</span><br></pre></td></tr></table></figure><h4 id="可达性分析算法："><a href="#可达性分析算法：" class="headerlink" title="可达性分析算法："></a>可达性分析算法：</h4><p>通过一系列称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GCRoots没有任何引用链相连的时候，则证明此对象是不可用的。</p><p>比如如下，右侧的对象是到GCRoot时不可达的，可以判定为可回收对象。</p><p><img src="/image/jvm-4-2.png" alt=""></p><p>在java中，可以作为GCRoot的对象包括以下几种：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">* 虚拟机栈中引用的对象。</span><br><span class="line"></span><br><span class="line">* 方法区中静态属性引用的对象。</span><br><span class="line"></span><br><span class="line">* 方法区中常量引用的对象。</span><br><span class="line"></span><br><span class="line">* 本地方法中JNI引用的对象。</span><br></pre></td></tr></table></figure><p>基于以上，我们可以知道，当当前对象到GCRoot中不可达时候，即会满足被垃圾回收的可能。</p><p>那么是不是这些对象就非死不可，也不一定，此时只能宣判它们存在于一种“缓刑”的阶段，要真正的宣告一个对象死亡。至少要经历两次标记：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">第一次：对象可达性分析之后，发现没有与GCRoots相连接，此时会被第一次标记并筛选。</span><br><span class="line"></span><br><span class="line">第二次：对象没有覆盖finalize（）方法，或者finalize（）方法已经被虚拟机调用过，此时会被认定为没必要执行。</span><br><span class="line">    (大致描述一下finalize流程：当对象变成(GC Roots)不可达时，GC会判断该对象是否覆盖了finalize方法，若未覆盖，则直接将其回收。否则，若对象未执行过finalize方法，将其放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法。执行finalize方法完毕后，GC会再次判断该对象是否可达，若不可达，则进行回收，否则，对象“复活”。)</span><br></pre></td></tr></table></figure><h3 id="三、如何回收"><a href="#三、如何回收" class="headerlink" title="三、如何回收"></a>三、如何回收</h3><p>上述的两点讲解之后，我们大概明白了，哪些对象会被回收，以及回收的依据是什么，但回收的这个工作实现起来并不简单，首先它需要扫描所有的对象，鉴别谁能够被回收，其次在扫描期间需要 ”stop the world“ 对象能被冻结，不然你刚扫描，他的引用信息有变化，你就等于白做了。</p><h4 id="分代回收"><a href="#分代回收" class="headerlink" title="分代回收"></a>分代回收</h4><p>我们从一个object1来说明其在分代垃圾回收算法中的回收轨迹。</p><p>1、object1新建，出生于新生代的Eden区域。</p><p><img src="/image/jvm-4-3.png" alt=""><br>2、minor GC，object1 还存活，移动到Fromsuvivor空间，此时还在新生代。<br><img src="/image/jvm-4-4.png" alt=""></p><p>3、minor GC，object1 仍然存活，此时会通过复制算法，将object1移动到ToSuv区域，此时object1的年龄age+1。<br><img src="/image/jvm-4-5.png" alt=""></p><p>4、minor GC，object1 仍然存活，此时survivor中和object1同龄的对象并没有达到survivor的一半，所以此时通过复制算法，将fromSuv和Tosuv 区域进行互换，存活的对象被移动到了Tosuv。<br><img src="/image/jvm-4-6.png" alt=""></p><p>5、minor GC，object1 仍然存活，此时survivor中和object1同龄的对象已经达到survivor的一半以上（toSuv的区域已经满了），object1被移动到了老年代区域。<br><img src="/image/jvm-4-7.png" alt=""></p><p>6、object1存活一段时间后，发现此时object1不可达GcRoots，而且此时老年代空间比率已经超过了阈值,触发了majorGC（也可以认为是fullGC，但具体需要垃圾收集器来联系），此时object1被回收了。fullGC会触发 stop the world。<br><img src="/image/jvm-4-8.png" alt=""></p><p>在以上的新生代中，我们有提到对象的age，对象存活于survivor状态下，不会立即晋升为老生代对象，以避免给老生代造成过大的影响，它们必须要满足以下条件才可以晋升：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、minor gc 之后，存活于survivor 区域的对象的age会+1，当超过（默认）15的时候，转移到老年代。</span><br><span class="line"></span><br><span class="line">2、动态对象，如果survivor空间中相同年龄所有的对象大小的综合和大于survivor空间的一半，年级大于或等于该年级的对象就可以直接进入老年代。</span><br></pre></td></tr></table></figure><p>以上采用分代垃圾收集的思想，对一个对象从存活到死亡所经历的历程。期间，在新生代的时刻，会用到复制算法，在老年代时，有可能会用到标记-清楚算法（mark-sweep）算法或者标记-整理算法，这些都是垃圾回收算法基于不同区域的实现，我们看下这几种回收算法的实现原理。</p><h3 id="四、垃圾收集器"><a href="#四、垃圾收集器" class="headerlink" title="四、垃圾收集器"></a>四、垃圾收集器</h3><p>垃圾收集器是内存回收的具体实现，不同的厂商提供的垃圾收集器有很大的差别，一般的垃圾收集器都会作用于不同的分代，需要搭配使用。以下是各种垃圾收集器的组合方式：</p><p><img src="/image/jvm-4-9.png" alt=""></p><p><img src="/image/jvm-4-10.png" alt=""></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;对于调优之前，我们必须要了解其运行原理，java 的垃圾收集Garbage Collection 通常被称为“GC”，它诞生
      
    
    </summary>
    
    
      <category term="jvm" scheme="http://www.fufan.me/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>java常用集合源码分析之ArrayList遍历方式以及效率比较（五）</title>
    <link href="http://www.fufan.me/2018/06/08/java%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BArrayList%E9%81%8D%E5%8E%86%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E6%95%88%E7%8E%87%E6%AF%94%E8%BE%83%EF%BC%88%E4%BA%94%EF%BC%89/"/>
    <id>http://www.fufan.me/2018/06/08/java常用集合源码分析之ArrayList遍历方式以及效率比较（五）/</id>
    <published>2018-06-08T13:51:00.000Z</published>
    <updated>2018-11-11T13:53:57.516Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><h3 id="一、遍历方式"><a href="#一、遍历方式" class="headerlink" title="一、遍历方式"></a>一、遍历方式</h3><p>ArrayList支持三种遍历方式。</p><p>1、第一种，随机访问，它是通过索引值去遍历</p><p>2、第二种，foreach语句</p><p>3、第三种，Iterator迭代器方式</p><p>迭代器是一种模式，它可以使得对于序列类型的数据结构的遍历行为与被遍历的对象分离，即我们无需关心该序列的底层结构是什么样子的。只要拿到这个对象,使用迭代器就可以遍历这个对象的内部。</p><h3 id="二、几种遍历方式效率的比较"><a href="#二、几种遍历方式效率的比较" class="headerlink" title="二、几种遍历方式效率的比较"></a>二、几种遍历方式效率的比较</h3><p>从实验结果来看，在遍历ArrayList中，效率最高的是普通for循环遍历，foreach遍历和Iterator方式之间关系不明确，但在增大运行次数时，iterator效率高于foreach。</p><h3 id="三、效率分析"><a href="#三、效率分析" class="headerlink" title="三、效率分析"></a>三、效率分析</h3><h4 id="1-为什么基本的for循环效率高于Iterator遍历？"><a href="#1-为什么基本的for循环效率高于Iterator遍历？" class="headerlink" title="1. 为什么基本的for循环效率高于Iterator遍历？"></a>1. 为什么基本的for循环效率高于Iterator遍历？</h4><p>ArrayList实现了RandomAccess接口，RandomAccess接口为ArrayList带来了什么好处呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">As a rule of thumb, a List implementation should implement this interface if, for typical instances of the class, this loop:</span><br><span class="line"></span><br><span class="line">     for (int i=0, n=list.size(); i &lt; n; i++)</span><br><span class="line">         list.get(i);</span><br><span class="line"> </span><br><span class="line">runs faster than this loop:</span><br><span class="line"></span><br><span class="line">     for (Iterator i=list.iterator(); i.hasNext(); )</span><br><span class="line">         i.next();</span><br></pre></td></tr></table></figure><p>从描述中，可以看出实现RandomAccess接口的集合类，使用for循环的效率会比Iterator高。<br>RandomAccess接口为ArrayList带来的好处：</p><ul><li>1、可以快速随机访问集合。</li><li>2、使用快速随机访问（for循环）效率可以高于Iterator。</li></ul><h4 id="2-为什么foreach循环效率与Iterator效率有点相似"><a href="#2-为什么foreach循环效率与Iterator效率有点相似" class="headerlink" title="2. 为什么foreach循环效率与Iterator效率有点相似"></a>2. 为什么foreach循环效率与Iterator效率有点相似</h4><p>从底层实现中可以看出：</p><ul><li>foreach不是关键字，它的关键字是for，它的语句是由iterator实现的。</li><li>forEach就是为了让用iterator循环访问的形式简单，写起来更方便。</li></ul><h3 id="四、扩展"><a href="#四、扩展" class="headerlink" title="四、扩展"></a>四、扩展</h3><h4 id="1、基本的for循环的效率一定比iterator迭代器的高吗？"><a href="#1、基本的for循环的效率一定比iterator迭代器的高吗？" class="headerlink" title="1、基本的for循环的效率一定比iterator迭代器的高吗？"></a>1、基本的for循环的效率一定比iterator迭代器的高吗？</h4><p>不一定，主要还要看集合的数据结构组成。例如，ArrayList和LinkedList中就不同</p><ul><li>ArrayList实现了RandomAccess随机访问接口，因此它对随机访问的速度快，而基本的for循环中的get()方法，采用的即是随机访问的方法，因而在ArrayList中，for循环速度快。</li><li>LinkedList采取的是顺序访问方式，iterator中的next()方法，采用的即是顺序访问方法，因此在LinkedList中，使用iterator的速度较快。</li></ul><h4 id="2、for、foreach、iterator之间的差别"><a href="#2、for、foreach、iterator之间的差别" class="headerlink" title="2、for、foreach、iterator之间的差别"></a>2、for、foreach、iterator之间的差别</h4><h5 id="1）形式差别"><a href="#1）形式差别" class="headerlink" title="1）形式差别"></a>1）形式差别</h5><h5 id="2）条件差别"><a href="#2）条件差别" class="headerlink" title="2）条件差别"></a>2）条件差别</h5><ul><li>for：需要知道集合或数组的大小，而且需要是有序的，不然无法遍历；</li><li>foreach、iterator：都不需要知道集合或数组的大小，他们都是得到集合内的每个元素然后进行处理。</li></ul><h5 id="3）多态差别"><a href="#3）多态差别" class="headerlink" title="3）多态差别"></a>3）多态差别</h5><ul><li>for、foreach：都需要先知道集合的类型，甚至是集合内元素的类型，即需要访问内部的成员，不能实现态；</li><li>iterator：是一个接口类型，它不关心集合或者数组的类型，而且它还能随时修改和删除集合的元素。</li></ul><h5 id="4）用法差别"><a href="#4）用法差别" class="headerlink" title="4）用法差别"></a>4）用法差别</h5><ul><li>for循环：一般用来处理比较简单的有序的，可预知大小的集合或数组</li><li>foreach：可用于遍历任何集合或数组，而且操作简单易懂，他唯一的不好就是需要了解集合内部类型</li><li>iterator：是最强大的，它可以随时修改或者删除集合内部的元素，并且是在不需要知道元素和集合的类型的情况下进行的（原因可参考第三点：多态差别），当你需要对不同的容器实现同样的遍历方式时，迭代器是最好的选择！</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;一、遍历方式&quot;&gt;&lt;a href=&quot;#一、遍历方式&quot; class=&quot;headerlink&quot; title=&quot;一、遍历方
      
    
    </summary>
    
      <category term="集合" scheme="http://www.fufan.me/categories/%E9%9B%86%E5%90%88/"/>
    
    
      <category term="集合" scheme="http://www.fufan.me/tags/%E9%9B%86%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>Java8语法特性讲解（三）—— Examples：Strings, Numbers, Math and Files</title>
    <link href="http://www.fufan.me/2018/05/12/Java8%E8%AF%AD%E6%B3%95%E7%89%B9%E6%80%A7%E8%AE%B2%E8%A7%A3%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94-Examples%EF%BC%9AStrings-Numbers-Math-and-Files-1/"/>
    <id>http://www.fufan.me/2018/05/12/Java8语法特性讲解（三）——-Examples：Strings-Numbers-Math-and-Files-1/</id>
    <published>2018-05-11T17:21:00.000Z</published>
    <updated>2018-11-11T17:21:52.570Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><h3 id="Slicing-Strings"><a href="#Slicing-Strings" class="headerlink" title="Slicing Strings"></a>Slicing Strings</h3><p>Two new methods are available on the String class: join and chars. The first method joins any number of strings into a single string with the given delimiter:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String.join(&quot;:&quot;, &quot;foobar&quot;, &quot;foo&quot;, &quot;bar&quot;);</span><br><span class="line">// =&gt; foobar:foo:bar</span><br></pre></td></tr></table></figure><p>The second method chars creates a stream for all characters of the string, so you can use stream operations upon those characters:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;foobar:foo:bar&quot;</span><br><span class="line">    .chars()</span><br><span class="line">    .distinct()</span><br><span class="line">    .mapToObj(c -&gt; String.valueOf((char)c))</span><br><span class="line">    .sorted()</span><br><span class="line">    .collect(Collectors.joining());</span><br><span class="line">// =&gt; :abfor</span><br></pre></td></tr></table></figure><p>Not only strings but also regex patterns now benefit from streams. Instead of splitting strings into streams for each character we can split strings for any pattern and create a stream to work upon as shown in this example:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Pattern.compile(&quot;:&quot;)</span><br><span class="line">    .splitAsStream(&quot;foobar:foo:bar&quot;)</span><br><span class="line">    .filter(s -&gt; s.contains(&quot;bar&quot;))</span><br><span class="line">    .sorted()</span><br><span class="line">    .collect(Collectors.joining(&quot;:&quot;));</span><br><span class="line">// =&gt; bar:foobar</span><br></pre></td></tr></table></figure><p>Additionally regex patterns can be converted into predicates. Those predicates can for example be used to filter a stream of strings:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Pattern pattern = Pattern.compile(&quot;.*@gmail\\.com&quot;);</span><br><span class="line">Stream.of(&quot;bob@gmail.com&quot;, &quot;alice@hotmail.com&quot;)</span><br><span class="line">    .filter(pattern.asPredicate())</span><br><span class="line">    .count();</span><br><span class="line">// =&gt; 1</span><br></pre></td></tr></table></figure><p>The above pattern accepts any string which ends with @gmail.com and is then used as a Java 8 Predicate to filter a stream of email addresses.</p><h3 id="Crunching-Numbers"><a href="#Crunching-Numbers" class="headerlink" title="Crunching Numbers"></a>Crunching Numbers</h3><p>Java 8 adds additional support for working with unsigned numbers. Numbers in Java had always been signed. Let’s look at Integer for example:</p><p>An int represents a maximum of 2³² binary digits. Numbers in Java are per default signed, so the last binary digit represents the sign (0 = positive, 1 = negative). Thus the maximum positive signed int is 2³¹ - 1 starting with the decimal zero.</p><p>You can access this value via Integer.MAX_VALUE:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(Integer.MAX_VALUE);      // 2147483647</span><br><span class="line">System.out.println(Integer.MAX_VALUE + 1);  // -2147483648</span><br></pre></td></tr></table></figure><p>Java 8 adds support for parsing unsigned ints. Let’s see how this works:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">long maxUnsignedInt = (1l &lt;&lt; 32) - 1;</span><br><span class="line">String string = String.valueOf(maxUnsignedInt);</span><br><span class="line">int unsignedInt = Integer.parseUnsignedInt(string, 10);</span><br><span class="line">String string2 = Integer.toUnsignedString(unsignedInt, 10);</span><br></pre></td></tr></table></figure><p>As you can see it’s now possible to parse the maximum possible unsigned number 2³² - 1 into an integer. And you can also convert this number back into a string representing the unsigned number.</p><p>This wasn’t possible before with parseInt as this example demonstrates:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">    Integer.parseInt(string, 10);</span><br><span class="line">&#125;</span><br><span class="line">catch (NumberFormatException e) &#123;</span><br><span class="line">    System.err.println(&quot;could not parse signed int of &quot; + maxUnsignedInt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The number is not parseable as a signed int because it exceeds the maximum of 2³¹ - 1.</p><h3 id="Do-the-Math"><a href="#Do-the-Math" class="headerlink" title="Do the Math"></a>Do the Math</h3><p>The utility class Math has been enhanced by a couple of new methods for handling number overflows. What does that mean? We’ve already seen that all number types have a maximum value. So what happens when the result of an arithmetic operation doesn’t fit into its size?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(Integer.MAX_VALUE);      // 2147483647</span><br><span class="line">System.out.println(Integer.MAX_VALUE + 1);  // -2147483648</span><br></pre></td></tr></table></figure><p>As you can see a so called integer overflow happens which is normally not the desired behavior.</p><p>Java 8 adds support for strict math to handle this problem. Math has been extended by a couple of methods who all ends with exact, e.g. addExact. Those methods handle overflows properly by throwing an ArithmeticException when the result of the operation doesn’t fit into the number type:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">    Math.addExact(Integer.MAX_VALUE, 1);</span><br><span class="line">&#125;</span><br><span class="line">catch (ArithmeticException e) &#123;</span><br><span class="line">    System.err.println(e.getMessage());</span><br><span class="line">    // =&gt; integer overflow</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The same exception might be thrown when trying to convert longs to int via toIntExact:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">    Math.toIntExact(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line">catch (ArithmeticException e) &#123;</span><br><span class="line">    System.err.println(e.getMessage());</span><br><span class="line">    // =&gt; integer overflow</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Working-with-Files"><a href="#Working-with-Files" class="headerlink" title="Working with Files"></a>Working with Files</h3><p>The utility class Files was first introduced in Java 7 as part of Java NIO. The JDK 8 API adds a couple of additional methods which enables us to use functional streams with files. Let’s deep-dive into a couple of code samples.</p><h4 id="Listing-files"><a href="#Listing-files" class="headerlink" title="Listing files"></a>Listing files</h4><p>The method Files.list streams all paths for a given directory, so we can use stream operations like filter and sorted upon the contents of the file system.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">try (Stream&lt;Path&gt; stream = Files.list(Paths.get(&quot;&quot;))) &#123;</span><br><span class="line">    String joined = stream</span><br><span class="line">        .map(String::valueOf)</span><br><span class="line">        .filter(path -&gt; !path.startsWith(&quot;.&quot;))</span><br><span class="line">        .sorted()</span><br><span class="line">        .collect(Collectors.joining(&quot;; &quot;));</span><br><span class="line">    System.out.println(&quot;List: &quot; + joined);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The above example lists all files for the current working directory, then maps each path to it’s string representation. The result is then filtered, sorted and finally joined into a string. If you’re not yet familiar with functional streams you should read my Java 8 Stream Tutorial.</p><p>You might have noticed that the creation of the stream is wrapped into a try/with statement. Streams implement AutoCloseable and in this case we really have to close the stream explicitly since it’s backed by IO operations.</p><pre><code>The returned stream encapsulates a DirectoryStream. If timely disposal of file system resources is required, the try-with-resources construct should be used to ensure that the stream&apos;s close method is invoked after the stream operations are completed.</code></pre><h4 id="Finding-files"><a href="#Finding-files" class="headerlink" title="Finding files"></a>Finding files</h4><p>The next example demonstrates how to find files in a directory or it’s sub-directories.</p><p>Path start = Paths.get(“”);<br>int maxDepth = 5;<br>try (Stream<path></path>stream = Files.find(start, maxDepth, (path, attr) -&gt;<br>String.valueOf(path).endsWith(“.js”))) {<br>String joined = stream<br>.sorted()<br>.map(String::valueOf)<br>.collect(Collectors.joining(“; “));<br>System.out.println(“Found: “ + joined);<br>}</p><p>The method find accepts three arguments: The directory path start is the initial starting point and maxDepth defines the maximum folder depth to be searched. The third argument is a matching predicate and defines the search logic. In the above example we search for all JavaScript files (filename ends with .js).</p><p>We can achieve the same behavior by utilizing the method Files.walk. Instead of passing a search predicate this method just walks over any file.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Path start = Paths.get(&quot;&quot;);</span><br><span class="line">int maxDepth = 5;</span><br><span class="line">try (Stream&lt;Path&gt; stream = Files.walk(start, maxDepth)) &#123;</span><br><span class="line">    String joined = stream</span><br><span class="line">        .map(String::valueOf)</span><br><span class="line">        .filter(path -&gt; path.endsWith(&quot;.js&quot;))</span><br><span class="line">        .sorted()</span><br><span class="line">        .collect(Collectors.joining(&quot;; &quot;));</span><br><span class="line">    System.out.println(&quot;walk(): &quot; + joined);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In this example we use the stream operation filter to achieve the same behavior as in the previous example.</p><h4 id="Reading-and-writing-files"><a href="#Reading-and-writing-files" class="headerlink" title="Reading and writing files"></a>Reading and writing files</h4><p>Reading text files into memory and writing strings into a text file in Java 8 is finally a simple task. No messing around with readers and writers. The method Files.readAllLines reads all lines of a given file into a list of strings. You can simply modify this list and write the lines into another file via Files.write:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; lines = Files.readAllLines(Paths.get(&quot;res/nashorn1.js&quot;));</span><br><span class="line">lines.add(&quot;print(&apos;foobar&apos;);&quot;);</span><br><span class="line">Files.write(Paths.get(&quot;res/nashorn1-modified.js&quot;), lines);</span><br></pre></td></tr></table></figure><p>Please keep in mind that those methods are not very memory-efficient because the whole file will be read into memory. The larger the file the more heap-size will be used.</p><p>As an memory-efficient alternative you could use the method Files.lines. Instead of reading all lines into memory at once, this method reads and streams each line one by one via functional streams.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">try (Stream&lt;String&gt; stream = Files.lines(Paths.get(&quot;res/nashorn1.js&quot;))) &#123;</span><br><span class="line">    stream</span><br><span class="line">        .filter(line -&gt; line.contains(&quot;print&quot;))</span><br><span class="line">        .map(String::trim)</span><br><span class="line">        .forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>If you need more fine-grained control you can instead construct a new buffered reader:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Path path = Paths.get(&quot;res/nashorn1.js&quot;);</span><br><span class="line">try (BufferedReader reader = Files.newBufferedReader(path)) &#123;</span><br><span class="line">    System.out.println(reader.readLine());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Or in case you want to write to a file simply construct a buffered writer instead:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Path path = Paths.get(&quot;res/output.js&quot;);</span><br><span class="line">try (BufferedWriter writer = Files.newBufferedWriter(path)) &#123;</span><br><span class="line">    writer.write(&quot;print(&apos;Hello World&apos;);&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Buffered readers also have access to functional streams. The method lines construct a functional stream upon all lines denoted by the buffered reader:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Path path = Paths.get(&quot;res/nashorn1.js&quot;);</span><br><span class="line">try (BufferedReader reader = Files.newBufferedReader(path)) &#123;</span><br><span class="line">    long countPrints = reader</span><br><span class="line">        .lines()</span><br><span class="line">        .filter(line -&gt; line.contains(&quot;print&quot;))</span><br><span class="line">        .count();</span><br><span class="line">    System.out.println(countPrints);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://github.com/winterbe/java8-tutorial" target="_blank" rel="noopener">code in GITHUB</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;Slicing-Strings&quot;&gt;&lt;a href=&quot;#Slicing-Strings&quot; class=&quot;header
      
    
    </summary>
    
    
      <category term="java" scheme="http://www.fufan.me/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>分布式锁的实现方式（一）——数据库和Redis锁</title>
    <link href="http://www.fufan.me/2018/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CRedis%E9%94%81/"/>
    <id>http://www.fufan.me/2018/04/07/分布式锁的实现方式（一）——数据库和Redis锁/</id>
    <published>2018-04-07T02:29:00.000Z</published>
    <updated>2018-11-07T06:07:36.483Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>分布式锁一般有三种实现方式：1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁。4.基于consul的分布式锁。</p><p>在之前的java多线程系列中（java多线程系列（三）——锁），我已经学习到了各种各样的锁在jdk中的使用。如今大部分互联网系统都是分布式系统，所以实现支持具体业务的高可用分布式锁是我们经常要做的事情。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><h4 id="什么是锁"><a href="#什么是锁" class="headerlink" title="什么是锁"></a>什么是锁</h4><ul><li>在单进程的系统中，当存在多个线程可以同时改变某个变量（可变共享变量）时，就需要对变量或代码块做同步，使其在修改这种变量时能够线性执行消除并发修改变量。</li><li>而同步的本质是通过锁来实现的。为了实现多个线程在一个时刻同一个代码块只能有一个线程可执行，那么需要在某个地方做个标记，这个标记必须每个线程都能看到，当标记不存在时可以设置该标记，其余后续线程发现已经有标记了则等待拥有标记的线程结束同步代码块取消标记后再去尝试设置标记。这个标记可以理解为锁。</li><li>不同地方实现锁的方式也不一样，只要能满足所有线程都能看得到标记即可。如 Java 中 synchronize 是在对象头设置标记，Lock 接口的实现类基本上都只是某一个 volitile 修饰的 int 型变量其保证每个线程都能拥有对该 int 的可见性和原子修改，linux 内核中也是利用互斥量或信号量等内存数据做标记。</li><li>除了利用内存数据做锁其实任何互斥的都能做锁（只考虑互斥情况），如流水表中流水号与时间结合做幂等校验可以看作是一个不会释放的锁，或者使用某个文件是否存在作为锁等。只需要满足在对标记进行修改能保证原子性和内存可见性即可。</li></ul><h4 id="什么是分布式？"><a href="#什么是分布式？" class="headerlink" title="什么是分布式？"></a>什么是分布式？</h4><p>分布式的 CAP 理论告诉我们:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。</span><br></pre></td></tr></table></figure><p></p><p>目前很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。基于 CAP理论，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证最终一致性。</p><p>在许多的场景中，我们为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。很多时候我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，通过 Java 提供的并发 API 我们可以解决，但是在分布式环境下，就没有那么简单啦。</p><ul><li>分布式与单机情况下最大的不同在于其不是多线程而是多进程。</li><li>多线程由于可以共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一台物理机上，因此需要将标记存储在一个所有进程都能看到的地方。</li></ul><h4 id="什么是分布式锁？"><a href="#什么是分布式锁？" class="headerlink" title="什么是分布式锁？"></a>什么是分布式锁？</h4><ul><li>当在分布式模型下，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数。</li><li>与单机模式下的锁不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。（我觉得分布式情况下之所以问题变得复杂，主要就是需要考虑到网络的延时和不可靠。。。一个大坑）</li><li>分布式锁还是可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如 Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行。</li></ul><h4 id="我们需要怎样的分布式锁？"><a href="#我们需要怎样的分布式锁？" class="headerlink" title="我们需要怎样的分布式锁？"></a>我们需要怎样的分布式锁？</h4><ul><li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器-上的一个线程执行。</li><li>这把锁要是一把可重入锁（避免死锁）</li><li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li><li>这把锁最好是一把公平锁（根据业务需求考虑要不要这条）</li><li>有高可用的获取锁和释放锁功能</li><li>获取锁和释放锁的性能要好</li></ul><h3 id="基于数据库做分布式锁"><a href="#基于数据库做分布式锁" class="headerlink" title="基于数据库做分布式锁"></a>基于数据库做分布式锁</h3><h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p>基于表主键唯一做分布式锁</p><p><strong><em>思路：</em></strong> 利用主键唯一的特性，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可。</p><p>上面这种简单的实现有以下几个问题：</p><ul><li>这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</li><li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li><li>这把锁只能是非阻塞的，因为数据的 insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li><li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li><li>这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁。</li><li>在 MySQL 数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象。</li></ul><p>当然，我们也可以有其他方式解决上面的问题。</p><ul><li>数据库是单点？搞两个数据库，数据之前双向同步，一旦挂掉快速切换到备库上。</li><li>没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。</li><li>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。</li><li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li><li>非公平的？再建一张中间表，将等待锁的线程全记录下来，并根据创建时间排序，只有最先创建的允许获取锁。</li><li>比较好的办法是在程序中生产主键进行防重。</li></ul><h4 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h4><p>基于表字段版本号做分布式锁</p><p>这个策略源于 mysql 的 mvcc 机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断 sql 每次进行判断，增加了数据库操作的次数，在高并发的要求下，对数据库连接的开销也是无法忍受的。</p><h4 id="基于数据库排他锁做分布式锁"><a href="#基于数据库排他锁做分布式锁" class="headerlink" title="基于数据库排他锁做分布式锁"></a>基于数据库排他锁做分布式锁</h4><p>在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁 (注意： InnoDB 引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给要执行的方法字段名添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。)。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。</p><p>我们可以认为获得排他锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，通过connection.commit()操作来释放锁。</p><p>这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。</p><ul><li>阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。</li><li>锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。</li></ul><p>但是还是无法直接解决数据库单点和可重入问题。</p><p>这里还可能存在另外一个问题，虽然我们对方法字段名使用了唯一索引，并且显示使用 for update 来使用行级锁。但是，MySQL 会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。。。</p><p>还有一个问题，就是我们要使用排他锁来进行分布式锁的 lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆。</p><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><ul><li><p>优点：简单，易于理解</p></li><li><p>缺点：会有各种各样的问题（操作数据库需要一定的开销，使用数据库的行级锁并不一定靠谱，性能不靠谱）</p></li></ul><h3 id="基于-Redis-做分布式锁"><a href="#基于-Redis-做分布式锁" class="headerlink" title="基于 Redis 做分布式锁"></a>基于 Redis 做分布式锁</h3><h4 id="使用redis的setNX命令实现分布式锁"><a href="#使用redis的setNX命令实现分布式锁" class="headerlink" title="使用redis的setNX命令实现分布式锁　　"></a>使用redis的setNX命令实现分布式锁</h4><h5 id="实现的原理"><a href="#实现的原理" class="headerlink" title="实现的原理"></a>实现的原理</h5><p>Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系。redis的SETNX命令可以方便的实现分布式锁。</p><h5 id="基本命令解析"><a href="#基本命令解析" class="headerlink" title="基本命令解析"></a>基本命令解析</h5><p>1）setNX（SET if Not eXists）</p><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETNX key value</span><br></pre></td></tr></table></figure><p>将 key 的值设为 value ，当且仅当 key 不存在。</p><p>若给定的 key 已经存在，则 SETNX 不做任何动作。</p><p>SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写</p><p>返回值：<br>设置成功，返回 1 。<br>设置失败，返回 0 。</p><p>所以我们使用执行下面的命令<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETNX lock.foo &lt;current Unix time + lock timeout + 1&gt;</span><br></pre></td></tr></table></figure><p></p><ul><li>如返回1，则该客户端获得锁，把lock.foo的键值设置为时间值表示该键已被锁定，该客户端最后可以通过DEL lock.foo来释放该锁。</li><li>如返回0，表明该锁已被其他客户端取得，这时我们可以先返回或进行重试等对方完成或等待锁超时。</li></ul><p>2）getSET</p><p>语法：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GETSET key value</span><br></pre></td></tr></table></figure><p></p><p>将给定 key 的值设为 value ，并返回 key 的旧值(old value)。</p><p>当 key 存在但不是字符串类型时，返回一个错误。</p><p>返回值：</p><p>返回给定 key 的旧值。<br>当 key 没有旧值时，也即是， key 不存在时，返回 nil 。</p><p>3）get<br>语法：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET key</span><br></pre></td></tr></table></figure><p></p><p>返回值：</p><p>当 key 不存在时，返回 nil ，否则，返回 key 的值。<br>如果 key 不是字符串类型，那么返回一个错误</p><h5 id="解决死锁问题"><a href="#解决死锁问题" class="headerlink" title="解决死锁问题"></a>解决死锁问题</h5><p>如果一个持有锁的客户端失败或崩溃了不能释放锁，该怎么解决？</p><ul><li>设置超时时间来解决</li></ul><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><ol><li><a href="http://www.cnblogs.com/seesun2012/p/9214653.html" target="_blank" rel="noopener">Java分布式锁看这篇就够了</a></li></ol><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;分布式锁一般有三种实现方式：1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁。4.
      
    
    </summary>
    
      <category term="分布式" scheme="http://www.fufan.me/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="分布式" scheme="http://www.fufan.me/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="锁" scheme="http://www.fufan.me/tags/%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>Kafka学习笔记（三）——kafka设计的要点</title>
    <link href="http://www.fufan.me/2018/04/02/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94kafka%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%A6%81%E7%82%B9/"/>
    <id>http://www.fufan.me/2018/04/02/Kafka学习笔记（三）——kafka设计的要点/</id>
    <published>2018-04-02T10:36:00.000Z</published>
    <updated>2018-11-08T10:37:39.328Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><h2 id="kafka的特点"><a href="#kafka的特点" class="headerlink" title="kafka的特点"></a>kafka的特点</h2><h3 id="1、吞吐量"><a href="#1、吞吐量" class="headerlink" title="1、吞吐量"></a>1、吞吐量</h3><p>高吞吐是kafka需要实现的核心目标之一，为此kafka做了以下一些设计：</p><ol><li>数据磁盘持久化：消息不在内存中cache，直接写入到磁盘，充分利用磁盘的顺序读写性能</li><li>zero-copy：减少IO操作步骤</li><li>数据批量发送</li><li>数据压缩</li><li>Topic划分为多个partition，提高parallelism</li></ol><h3 id="2、负载均衡"><a href="#2、负载均衡" class="headerlink" title="2、负载均衡"></a>2、负载均衡</h3><ol><li>producer根据用户指定的算法，将消息发送到指定的partition</li><li>存在多个partiiton，每个partition有自己的replica，每个replica分布在不同的Broker节点上</li><li>多个partition需要选取出lead partition，lead partition负责读写，并由zookeeper负责fail over</li><li>通过zookeeper管理broker与consumer的动态加入与离开</li></ol><h3 id="3、拉取系统"><a href="#3、拉取系统" class="headerlink" title="3、拉取系统"></a>3、拉取系统</h3><p>由于kafka broker会持久化数据，broker没有内存压力，因此，consumer非常适合采取pull的方式消费数据，具有以下几点好处：</p><ol><li>简化kafka设计</li><li>consumer根据消费能力自主控制消息拉取速度</li><li>consumer根据自身情况自主选择消费模式，例如批量，重复消费，从尾端开始消费等</li></ol><h3 id="4、可扩展性"><a href="#4、可扩展性" class="headerlink" title="4、可扩展性"></a>4、可扩展性</h3><p>当需要增加broker结点时，新增的broker会向zookeeper注册，而producer及consumer会根据注册在zookeeper上的watcher感知这些变化，并及时作出调整。</p><h2 id="kafka的使用场景"><a href="#kafka的使用场景" class="headerlink" title="kafka的使用场景"></a>kafka的使用场景</h2><h3 id="1、消息队列"><a href="#1、消息队列" class="headerlink" title="1、消息队列"></a>1、消息队列</h3><p>比起大多数的消息系统来说，Kafka有更好的吞吐量，内置的分区，冗余及容错性，这让Kafka成为了一个很好的大规模消息处理应用的解决方案。消息系统一般吞吐量相对较低，但是需要更小的端到端延时，并尝尝依赖于Kafka提供的强大的持久性保障。在这个领域，Kafka足以媲美传统消息系统，如ActiveMR或RabbitMQ。</p><h3 id="2、行为跟踪"><a href="#2、行为跟踪" class="headerlink" title="2、行为跟踪"></a>2、行为跟踪</h3><p>Kafka的另一个应用场景是跟踪用户浏览页面、搜索及其他行为，以发布-订阅的模式实时记录到对应的topic里。那么这些结果被订阅者拿到后，就可以做进一步的实时处理，或实时监控，或放到hadoop/离线数据仓库里处理。</p><h3 id="3、元信息监控"><a href="#3、元信息监控" class="headerlink" title="3、元信息监控"></a>3、元信息监控</h3><p>作为操作记录的监控模块来使用，即汇集记录一些操作信息，可以理解为运维性质的数据监控吧。</p><h3 id="4、日志收集"><a href="#4、日志收集" class="headerlink" title="4、日志收集"></a>4、日志收集</h3><p>日志收集方面，其实开源产品有很多，包括Scribe、Apache Flume。很多人使用Kafka代替日志聚合（log aggregation）。日志聚合一般来说是从服务器上收集日志文件，然后放到一个集中的位置（文件服务器或HDFS）进行处理。然而Kafka忽略掉文件的细节，将其更清晰地抽象成一个个日志或事件的消息流。这就让Kafka处理过程延迟更低，更容易支持多数据源和分布式数据处理。比起以日志为中心的系统比如Scribe或者Flume来说，Kafka提供同样高效的性能和因为复制导致的更高的耐用性保证，以及更低的端到端延迟。</p><h2 id="kafka性能"><a href="#kafka性能" class="headerlink" title="kafka性能"></a>kafka性能</h2><p><img src="/image/kafka-2-0.png" alt=""></p><p>为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件.每个分区都是有序的，不可变的记录序列，不断追加到结构化的提交日志中。分区中的记录每个分配一个连续的id号，称为offset(偏移量)，用于唯一标识分区内的每条记录。</p><p>实际上，保留在每个消费者基础上的唯一元数据是该消费者在日志中的抵消或位置。这个偏移量是由消费者控制的：消费者通常会在读取记录时线性地推进其偏移量，但实际上，由于位置由消费者控制，因此它可以按任何喜欢的顺序消费记录。例如，消费者可以重置为较旧的offset(偏移量)以重新处理来自过去的数据，或者跳至最近的记录并从“now”开始消费。随你喜欢爱怎么读怎么读,而且这些操作对集群或其他消费者没有太大影响。</p><p>这样的操作也就说kafka不用考虑加锁的问题,不存在消费完就要删除信息的问题,有效的保证了高吞吐率,这样没有锁竞争，充分发挥了横向的扩展性，吞吐量极高。这也就形成了分布式消费的概念。</p><p><img src="/image/kafka-2-1.png" alt=""></p><p>这里要注意，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关,</p><p>当然kafka也提供了删除旧数据的策略:</p><ol><li><p>时间,可以自己设置一个储存的最大时间.</p></li><li><p>partition大小,可以给分区设置最大储存值.</p><p><img src="/image/kafka-2-2.png" alt=""></p><h3 id="consumer"><a href="#consumer" class="headerlink" title="consumer"></a>consumer</h3><p>p0=&gt;p3三个partition,而partition中的每个message只能被组（Consumer group）中的一个consumer（consumer 线程)消费.也就说一个partition只能被一个消费者消费（一个消费者可以同时消费多个partition）</p></li></ol><p>如果consumer从多个partition读到数据，不保证数据间的顺序性，kafka只保证在一个partition上数据是有序的，但多个partition，根据你读的顺序会有不同</p><h3 id="producer"><a href="#producer" class="headerlink" title="producer"></a>producer</h3><h4 id="Kakfa-Broker-Leader选举"><a href="#Kakfa-Broker-Leader选举" class="headerlink" title="Kakfa Broker Leader选举"></a>Kakfa Broker Leader选举</h4><p>kafka集群是受zookeeper来管理的,这里需要将所有的kafka broker节点一起注册到zookeeper上,而这个过程中只有一个kafka broker能注册成功,在zookeeper上注册一个临时节点,这个kafka broker叫kafka broker Controller,其他的叫kafka broker follower,一旦这个kafka broker Controller发生宕机,临时节点会消失,其他的kafka broker follower会在竞争去zookeeper上注册,产生一个新Leader.(注:Kafka集群中broker之间的关系,不是主从关系，各个broker在集群中地位一样，我们可以随意的增加或删除任何一个broker节点。),还有一种情况是有Controller下的一个follower宕机了,这时Controller会去读取这个follower在zookeeper上所有的partition leader信息(host:port),并且找到这些partition的备份们,让他们选一个成为这个partition的leader.如果该partition的所有的备份都宕机了，则将新的leader设置为-1，等待恢复，等待任一个备份“活”过来，并且选它作为Leader.</p><h4 id="在Producer向kafka-broker推送message"><a href="#在Producer向kafka-broker推送message" class="headerlink" title="在Producer向kafka broker推送message"></a>在Producer向kafka broker推送message</h4><p>kafka在所有broker中产生一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比Zookeeper Queue的方式更高效）通知需为此作出响应的Broker。</p><p>每个partition(分区)都有一台服务器充当“leader”，零个或多个服务器充当“follower”。leader处理分区的所有读取和写入请求，而follower被动地复制leader。如果leader失败，其中一个follower将自动成为新leader。每个服务器都充当其中一些分区的leader和其他人的follower，因此负载在集群内平衡良好。</p><h4 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h4><p>消息生产者,就是向 kafka broker发消息的客户端。 Producer 采用异步 push 方式, 极大提高 Kafka 系统的吞吐率(可以通过参数控制是采用同步还是异步方式)。 producer 端 , 可以将消息 buffer 起来 , 当消息的条数达到一定阀值时 , 批量发送给 broker 。</p><p>小数据 IO 太多,会拖慢整体的网络延迟,批量延迟发送事实上提升了网络效率。不过 这也有一定的隐患,比如说当 producer 失效时,那些尚未发送的消息将会丢失。</p><p>producer将会和Topic下所有partition leader保持 socket 连接 ; 消息由 producer 直接 通过 socket 发送到 broker, 中间不会经过任何 ” 路由层 “. 事实上 , 消息被路由到哪个 partition 上 , 由 producer 客户端决定。 partition leader的位置 (host:port)注册在 zookeeper 中 ,producer 作为 zookeeper client,已经注册了 watch 用来监听 partition leader的变更事件。</p><p><img src="/image/kafka-2-3.png" alt=""></p><p>如上图kafka集群有四个broker,一个topic有四个partition,并且每一个partition都有一个follower(其实就是备份);一个消息流输入之后会先储存一个topic在不同的partition leader中(并行写入),然后在由partition leader同步到各自的备份中.</p><p><img src="/image/kafka-2-5.png" alt=""></p><p>我们加两个broker5,6,这个时候partition的变化</p><h3 id="partition-分区-机制的优势"><a href="#partition-分区-机制的优势" class="headerlink" title="partition(分区)机制的优势:"></a>partition(分区)机制的优势:</h3><p>当Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。也就是我们上面说的机制，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。<strong>所以说kafka可以水平扩展，也就是扩展partition。</strong>segment</p><p>一个partition可以实现跨服务器,可以一个分区占有一个服务器.</p><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p><a href="https://blog.csdn.net/mr_hou2016/article/details/79653242" target="_blank" rel="noopener">日志收集为什么用kafka</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;h2 id=&quot;kafka的特点&quot;&gt;&lt;a href=&quot;#kafka的特点&quot; class=&quot;headerlink&quot; title=&quot;k
      
    
    </summary>
    
      <category term="kafka" scheme="http://www.fufan.me/categories/kafka/"/>
    
    
      <category term="kafka" scheme="http://www.fufan.me/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka学习笔记（二）——Kafka shell命令</title>
    <link href="http://www.fufan.me/2018/03/26/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94Kafka-shell%E5%91%BD%E4%BB%A4/"/>
    <id>http://www.fufan.me/2018/03/26/Kafka学习笔记（二）——Kafka-shell命令/</id>
    <published>2018-03-26T10:17:00.000Z</published>
    <updated>2018-11-08T10:18:12.049Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>排查问题的时候可能会用到终端的一些命令，下面列举一下常用的一些命令</p><h3 id="启动zookeeper"><a href="#启动zookeeper" class="headerlink" title="启动zookeeper"></a>启动zookeeper</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties &amp;</span><br></pre></td></tr></table></figure><h3 id="启动kafka"><a href="#启动kafka" class="headerlink" title="启动kafka"></a>启动kafka</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure><h3 id="停止kafka"><a href="#停止kafka" class="headerlink" title="停止kafka"></a>停止kafka</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure><h3 id="停止zookeeper"><a href="#停止zookeeper" class="headerlink" title="停止zookeeper"></a>停止zookeeper</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-server-stop.sh</span><br></pre></td></tr></table></figure><h3 id="创建topic"><a href="#创建topic" class="headerlink" title="创建topic"></a>创建topic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</span><br></pre></td></tr></table></figure><h3 id="展示topic"><a href="#展示topic" class="headerlink" title="展示topic"></a>展示topic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure><h3 id="描述topic"><a href="#描述topic" class="headerlink" title="描述topic"></a>描述topic</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic</span><br></pre></td></tr></table></figure><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list 130.51.23.95:9092 --topic my-replicated-topic</span><br></pre></td></tr></table></figure><h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --zookeeper 130.51.23.95:2181 --topic test --from-beginning</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;排查问题的时候可能会用到终端的一些命令，下面列举一下常用的一些命令&lt;/p&gt;&lt;h3 id=&quot;启动zookeeper&quot;&gt;&lt;a h
      
    
    </summary>
    
    
      <category term="kafka" scheme="http://www.fufan.me/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka学习笔记（一）——Kafka入门</title>
    <link href="http://www.fufan.me/2018/03/18/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94Kafka%E5%85%A5%E9%97%A8/"/>
    <id>http://www.fufan.me/2018/03/18/Kafka学习笔记（一）——Kafka入门/</id>
    <published>2018-03-18T10:32:00.000Z</published>
    <updated>2018-11-08T10:17:19.016Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>Apache Kafka：一个分布式流处理平台</p><ul><li><p>| 对比指标 | kafka | activemq | rabbitmq | rocketmq |<br>| — | — | — | — | — |<br>| 背景 | Kafka 是LinkedIn 开发的一个高性能、分布式的消息系统，广泛用于日志收集、流式数据处理、在线和离线消息分发等场景 | ActiveMQ是一种开源的，实现了JMS1.1规范的，面向消息(MOM)的中间件， 为应用程序提供高效的、可扩展的、稳定的和安全的企业级消息通信。 | RabbitMQ是一个由erlang开发的AMQP协议（Advanced Message Queue ）的开源实现。 | RocketMQ是阿里巴巴在2012年开源的分布式消息中间件，目前已经捐赠给Apache基金会，已经于2016年11月成为 Apache 孵化项目 |<br>|开发语言 | Java、Scala | Java | Erlang | Java |<br>|协议支持 | 自己实现的一套 | JMS协议 | AMQP | JMS、MQTT |<br>|持久化 | 支持 | 支持 | 支持 | 支持 |<br>| producer容错 | 在kafka中提供了acks配置选项, acks=0 生产者在成功写入悄息之前不会等待任何来自服务器的响应 acks=1 只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应 acks=all 只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应,这种模式最安全 | 发送失败后即可重试 | 有ack模型。 ack模型可能重复消息 ，事务模型保证完全一致 | 和kafka类似 |<br>| 吞吐量 | kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高 | | rabbitMQ在吞吐量方面稍逊于kafka，他们的出发点不一样，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作；基于存储的可靠性的要求存储可以采用内存或者硬盘。 | kafka在topic数量不多的情况下吞吐量比rocketMq高，在topic数量多的情况下rocketMq比kafka高 |<br>| 负载均衡 | kafka采用zookeeper对集群中的broker、consumer进行管理，可以注册topic到zookeeper上；通过zookeeper的协调机制，producer保存对应topic的broker信息，可以随机或者轮询发送到broker上；并且producer可以基于语义指定分片，消息发送到broker的某分片上 | | rabbitMQ的负载均衡需要单独的loadbalancer进行支持 | NamerServer进行负载均衡<br>|</p></li></ul><p><img src="/image/kafka-0-0.jpg" alt=""></p><h3 id="相关名词"><a href="#相关名词" class="headerlink" title="相关名词"></a>相关名词</h3><ul><li>Producer :消息生产者，向Broker发送消息的客户端</li><li>Consumer :消息消费者，从Broker读取消息的客户端,消费者&lt;=消息的分区数量</li><li>broker :消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群</li><li>topic : 主题，Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic</li><li>Partition : 分区，物理上的概念，一个topic可以分为多个partition，每个partition内部是有序的，kafka默认根据key%partithon确定消息发送到具体的partition</li><li>ConsumerGroup : 每个Consumer属于一个特定的Consumer Group，一条消息可以发送到多个不同的Consumer Group，但是一个Consumer Group中只能有一个Consumer能够消费该消息</li></ul><h4 id="Topic-和-Partition"><a href="#Topic-和-Partition" class="headerlink" title="Topic 和 Partition"></a>Topic 和 Partition</h4><p>一个Topic中的消息会按照指定的规则(默认是key的hash值%分区的数量，当然你也可以自定义)，发送到某一个分区上面；<br>每一个分区都是一个顺序的、不可变的消息队列，并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的<br>消费者所持有的元数据就是这个偏移量，也就是消费者在这个log（分区）中的位置。这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加</p><p><img src="/image/kafka-0-1.jpg" alt=""></p><h4 id="Consumer-和-Partition"><a href="#Consumer-和-Partition" class="headerlink" title="Consumer 和 Partition"></a>Consumer 和 Partition</h4><p>通常来讲，消息模型可以分为两种， 队列和发布-订阅式。队列的处理方式 是一个消费者组从队列的一端拉取数据，这个数据消费完就没了。在发布-订阅模型中，消息被广播给所有的消费者，接受到消息的消费者都能处理此消息。在Kafka模型中抽象出来了：消费者组（consumer group）<br>消费者组（consumer group）：每个组中有若干个消费者，如果所有的消费者都在一个组中，那么这个就变成了队列模型；如果笑消费者在不同的组中，这就成了发布-订阅模型<br>一个分区里面的数据只会由一个分组中的消费者处理，同分组的其他消费者不会重复处理<br>消费者组中的消费者数量&lt;=分区数量，如果大于分区数量，多出来的消费者会处于收不到消息的状态，造成不必要的浪费。</p><p><img src="/image/kafka-0-2.jpg" alt=""></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;Apache Kafka：一个分布式流处理平台&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;| 对比指标 | kafka | activem
      
    
    </summary>
    
      <category term="kafka" scheme="http://www.fufan.me/categories/kafka/"/>
    
    
      <category term="kafka" scheme="http://www.fufan.me/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Consul学习笔记（一）——安装和命令使用</title>
    <link href="http://www.fufan.me/2018/02/28/Consul%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%AE%89%E8%A3%85%E5%92%8C%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"/>
    <id>http://www.fufan.me/2018/02/28/Consul学习笔记（一）——安装和命令使用/</id>
    <published>2018-02-28T10:14:00.000Z</published>
    <updated>2018-11-08T10:14:33.306Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>由于公司目前工作当中微服务用到了consul集群来作为分布式系统中间件，用到了他内置了服务注册与发现框 架、分布一致性协议实现、健康检查、Key/Value存储、多数据中心方案。不再需要依赖其他工具（比如ZooKeeper等）。使用起来也较 为简单。</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Consul 是 HashiCorp 公司推出的开源工具，用于实现分布式系统的服务发现与配置。与其他分布式服务注册与发现的方案，Consul的方案更“一站式”，内置了服务注册与发现框 架、分布一致性协议实现、健康检查、Key/Value存储、多数据中心方案，不再需要依赖其他工具（比如ZooKeeper等）。使用起来也较 为简单。Consul使用Go语言编写，因此具有天然可移植性(支持Linux、windows和Mac OS X)；安装包仅包含一个可执行文件，方便部署，与Docker等轻量级容器可无缝配合 。</p><ul><li>Service Discovery (服务发现)</li><li>Health Check (健康检查)</li><li>Multi Datacenter (多数据中心)</li><li>Key/Value Storage</li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>mac：64bit（查看mac位数：打开终端–&gt;”uname -a”）<br>consul_0.6.4_darwin_amd64.zip和consul_0.6.4_web_ui.zip，从consul官网<a href="https://www.consul.io/downloads.html进行下载就好（选择好OS和位数）" target="_blank" rel="noopener">https://www.consul.io/downloads.html进行下载就好（选择好OS和位数）</a></p><p>1、解压consul_0.6.4_darwin_amd64.zip<br>2、将解压后的二进制文件consul（上边画红框的部分拷贝到/usr/local/bin下）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp consul /usr/local/bin/</span><br></pre></td></tr></table></figure><p>说明：使用sudo是因为权限问题。</p><p>3、查看是否安装成功</p><p>调用其命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> fufan@fufans-MacBook-Pro-2  ~  consul help</span><br><span class="line">Usage: consul [--version] [--help] &lt;command&gt; [&lt;args&gt;]</span><br><span class="line"></span><br><span class="line">Available commands are:</span><br><span class="line">    agent          Runs a Consul agent</span><br><span class="line">    catalog        Interact with the catalog</span><br><span class="line">    connect        Interact with Consul Connect</span><br><span class="line">    event          Fire a new event</span><br><span class="line">    exec           Executes a command on Consul nodes</span><br><span class="line">    force-leave    Forces a member of the cluster to enter the &quot;left&quot; state</span><br><span class="line">    info           Provides debugging information for operators.</span><br><span class="line">    intention      Interact with Connect service intentions</span><br><span class="line">    join           Tell Consul agent to join cluster</span><br><span class="line">    keygen         Generates a new encryption key</span><br><span class="line">    keyring        Manages gossip layer encryption keys</span><br><span class="line">    kv             Interact with the key-value store</span><br><span class="line">    leave          Gracefully leaves the Consul cluster and shuts down</span><br><span class="line">    lock           Execute a command holding a lock</span><br><span class="line">    maint          Controls node or service maintenance mode</span><br><span class="line">    members        Lists the members of a Consul cluster</span><br><span class="line">    monitor        Stream logs from a Consul agent</span><br><span class="line">    operator       Provides cluster-level tools for Consul operators</span><br><span class="line">    reload         Triggers the agent to reload configuration files</span><br><span class="line">    rtt            Estimates network round trip time between nodes</span><br><span class="line">    snapshot       Saves, restores and inspects snapshots of Consul server state</span><br><span class="line">    validate       Validate config files/directories</span><br><span class="line">    version        Prints the Consul version</span><br><span class="line">    watch          Watch for changes in Consul</span><br></pre></td></tr></table></figure><h3 id="consul相关知识点"><a href="#consul相关知识点" class="headerlink" title="consul相关知识点"></a>consul相关知识点</h3><ol><li>Agent</li></ol><ul><li>Agent 是一个守护进程</li><li>运行在Consul集群的每个成员上</li><li>有Client 和 Server 两种模式</li><li>所有Agent都可以被调用DNS或者HTTP API,并负责检查和维护同步</li></ul><ol start="2"><li>Client</li></ol><ul><li>Client 将所有RPC请求转发至Server</li><li>Client 是相对无状态的</li><li>Client 唯一做的就是参与LAN Gossip Pool</li><li>Client 只消耗少量的资源和少量的网络带宽</li></ul><ol start="3"><li>Server</li></ol><ul><li>参与 Raft quorum(一致性判断)</li><li>响应RPC查询请求</li><li>维护集群的状态</li><li>转发查询到Leader 或 远程数据中心</li></ul><ol start="4"><li>Datacenter数据中心</li></ol><ul><li>私有的</li><li>低延迟</li><li>高带宽</li></ul><ol start="5"><li>Consensus (一致性)</li></ol><p>Consul 使用consensus protocol 来提供CAP(一致性,高可用,分区容错性)</p><ol start="5"><li>Gossip</li></ol><p>一种协议: 用来保证 最终一致性 , 即: 无法保证在某个时刻, 所有节点状态一致, 但可以保证”最终”一致</p><h3 id="注册服务"><a href="#注册服务" class="headerlink" title="注册服务"></a>注册服务</h3><ul><li>服务可以通过提供服务定义或通过对HTTP API进行适当的调用来注册。</li><li>服务定义是注册服务最常用的方式，所以我们将在这一步中使用这种方法。 我们将建立在上一步中介绍的代理配置。</li><li>首先，为Consul配置创建一个目录。 Consul将所有配置文件加载到配置目录中，因此Unix系统上的一个通用约定是将目录命名为/etc/consul.d（.d后缀意味着“该目录包含一组配置文件”）。</li></ul><p>建立服务配置目录:mkdir /etc/consul.d<br>添加文件:echo ‘{“service”: {“name”: “web”, “tags”: [“rails”], “port”: 80}}’ | sudo tee /etc/consul.d/web.json</p><ul><li>以开发模式启动:consul agent -dev -config-dir=/etc/consul.d</li><li>以服务方式启动:consul agent -server -bootstrap-expect 2 -data-dir ./tmp/consul -node=n1 -bind=192.168.109.241 -ui-dir ./dist -dc=dc1</li><li>以客户端方式启动:consul agent -data-dir ./tmp/consul -ui-dir ./dist -bind=192.168.109.204 -dc=dc1</li></ul><h3 id="加入集群"><a href="#加入集群" class="headerlink" title="加入集群"></a>加入集群</h3><p>将新节点添加到集群:consul join 192.168.100.101(其中101这个节点是master)</p><p>显示成员:consul members</p><h3 id="查看UI管理页面"><a href="#查看UI管理页面" class="headerlink" title="查看UI管理页面"></a>查看UI管理页面</h3><p><a href="http://192.168.0.70:8500/ui" target="_blank" rel="noopener">http://192.168.0.70:8500/ui</a></p><p><img src="/image/consul-0-1.png" alt=""></p><h3 id="常用命令参数"><a href="#常用命令参数" class="headerlink" title="常用命令参数"></a>常用命令参数</h3><p>consul agent 命令的常用选项，如下：</p><ul><li>-data-dir<ul><li>作用：指定agent储存状态的数据目录</li><li>这是所有agent都必须的</li><li>对于server尤其重要，因为他们必须持久化集群的状态</li></ul></li><li>-config-dir<ul><li>作用：指定service的配置文件和检查定义所在的位置</li><li>通常会指定为”某一个路径/consul.d”（通常情况下，.d表示一系列配置文件存放的目录）</li></ul></li><li>-config-file<ul><li>作用：指定一个要装载的配置文件</li><li>该选项可以配置多次，进而配置多个配置文件（后边的会合并前边的，相同的值覆盖）</li></ul></li><li>-dev<ul><li>作用：创建一个开发环境下的server节点</li><li>该参数配置下，不会有任何持久化操作，即不会有任何数据写入到磁盘</li><li>这种模式不能用于生产环境（因为第二条）</li></ul></li><li>-bootstrap-expect<ul><li>作用：该命令通知consul server我们现在准备加入的server节点个数，该参数是为了延迟日志复制的启动直到我们指定数量的server节点成功的加入后启动。</li></ul></li><li>-node<ul><li>作用：指定节点在集群中的名称</li><li>该名称在集群中必须是唯一的（默认采用机器的host）</li><li>推荐：直接采用机器的IP</li></ul></li><li>-bind<ul><li>作用：指明节点的IP地址</li><li>有时候不指定绑定IP，会报Failed to get advertise address: Multiple private IPs found. Please configure one. 的异常</li></ul></li><li>-server<ul><li>作用：指定节点为server</li><li>每个数据中心（DC）的server数推荐至少为1，至多为5</li><li>所有的server都采用raft一致性算法来确保事务的一致性和线性化，事务修改了集群的状态，且集群的状态保存在每一台server上保证可用性</li><li>server也是与其他DC交互的门面（gateway）</li></ul></li><li>-client<ul><li>作用：指定节点为client，指定客户端接口的绑定地址，包括：HTTP、DNS、RPC</li><li>默认是127.0.0.1，只允许回环接口访问</li><li>若不指定为-server，其实就是-client</li></ul></li><li>-join<ul><li>作用：将节点加入到集群</li></ul></li><li>-datacenter（老版本叫-dc，-dc已经失效）<ul><li>作用：指定机器加入到哪一个数据中心中</li></ul></li></ul><h3 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h3><p><img src="/image/consul-0-1.png" alt=""></p><p>此部分过程同redis集群、zookeeper集群类似</p><h3 id="问题踩坑"><a href="#问题踩坑" class="headerlink" title="问题踩坑"></a>问题踩坑</h3><ul><li>google</li><li>github issues</li></ul><h3 id="参考博文："><a href="#参考博文：" class="headerlink" title="参考博文："></a>参考博文：</h3><ul><li>Consul官方文档：<a href="https://www.consul.io/intro/getting-started/install.html" target="_blank" rel="noopener">https://www.consul.io/intro/getting-started/install.html</a></li><li>Consul 系列博文：<a href="http://www.cnblogs.com/java-zhao/archive/2016/04/13/5387105.html" target="_blank" rel="noopener">http://www.cnblogs.com/java-zhao/archive/2016/04/13/5387105.html</a></li><li>使用consul实现分布式服务注册和发现：<a href="http://www.tuicool.com/articles/M3QFven" target="_blank" rel="noopener">http://www.tuicool.com/articles/M3QFven</a></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;由于公司目前工作当中微服务用到了consul集群来作为分布式系统中间件，用到了他内置了服务注册与发现框 架、分布一致性协议实
      
    
    </summary>
    
      <category term="consul" scheme="http://www.fufan.me/categories/consul/"/>
    
    
      <category term="consul" scheme="http://www.fufan.me/tags/consul/"/>
    
  </entry>
  
  <entry>
    <title>Redis学习笔记（二）——redis安装</title>
    <link href="http://www.fufan.me/2018/02/15/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94redis%E5%AE%89%E8%A3%85/"/>
    <id>http://www.fufan.me/2018/02/15/Redis学习笔记（二）——redis安装/</id>
    <published>2018-02-15T03:05:00.000Z</published>
    <updated>2018-11-08T10:13:22.293Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --><p>由于公司开发笔记本用的是mac，所以我这里介绍一下在mac和linux环境下的redis安装</p><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p>1、下载源码，解压缩后编译源码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> $ wget http://download.redis.io/releases/redis-2.8.3.tar.gz</span><br><span class="line">$ tar xzf redis-2.8.3.tar.gz</span><br><span class="line">$ cd redis-2.8.3</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure><p>2、编译完成后，在Src目录下，有四个可执行文件redis-server、redis-benchmark、redis-cli和redis.conf。然后拷贝到一个目录下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/redis</span><br><span class="line">cp redis-server  /usr/redis</span><br><span class="line">cp redis-benchmark /usr/redis</span><br><span class="line">cp redis-cli  /usr/redis</span><br><span class="line">cp redis.conf  /usr/redis</span><br><span class="line">cd /usr/redis</span><br></pre></td></tr></table></figure><p>3、启动Redis服务。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ redis-server   redis.conf</span><br></pre></td></tr></table></figure><p></p><p>4、然后用客户端测试一下是否启动成功。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli</span><br><span class="line">redis&gt; set foo bar</span><br><span class="line">OK</span><br><span class="line">redis&gt; get foo</span><br><span class="line">&quot;bar&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h2><h3 id="brew-安装"><a href="#brew-安装" class="headerlink" title="brew 安装"></a>brew 安装</h3><p>1、使用brew命令安装redis<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install redis</span><br></pre></td></tr></table></figure><p></p><p>2、启动redis</p><p>后台方式启动，brew services start redis。这样启动的好处是把控制台关掉后，redis仍然是启动的。当然，如果没有这样的需求，也可以这样启动<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server /usr/local/etc/redis.conf</span><br></pre></td></tr></table></figure><p></p><p>3、关闭redis<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew services stop redis</span><br></pre></td></tr></table></figure><p></p><p>4、使用控制台连接redis</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli</span><br><span class="line"></span><br><span class="line">redis-cli -h 127.0.0.1 -p</span><br></pre></td></tr></table></figure><h2 id="redis-conf配置说明"><a href="#redis-conf配置说明" class="headerlink" title="redis.conf配置说明"></a>redis.conf配置说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br></pre></td><td class="code"><pre><span class="line"># Redis配置文件样例</span><br><span class="line"></span><br><span class="line"># Note on units: when memory size is needed, it is possible to specifiy</span><br><span class="line"># it in the usual form of 1k 5GB 4M and so forth:</span><br><span class="line">#</span><br><span class="line"># 1k =&gt; 1000 bytes</span><br><span class="line"># 1kb =&gt; 1024 bytes</span><br><span class="line"># 1m =&gt; 1000000 bytes</span><br><span class="line"># 1mb =&gt; 1024*1024 bytes</span><br><span class="line"># 1g =&gt; 1000000000 bytes</span><br><span class="line"># 1gb =&gt; 1024*1024*1024 bytes</span><br><span class="line">#</span><br><span class="line"># units are case insensitive so 1GB 1Gb 1gB are all the same.</span><br><span class="line"></span><br><span class="line"># Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程</span><br><span class="line"># 启用守护进程后，Redis会把pid写到一个pidfile中，在/var/run/redis.pid</span><br><span class="line">daemonize no</span><br><span class="line"></span><br><span class="line"># 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定</span><br><span class="line">pidfile /var/run/redis.pid</span><br><span class="line"></span><br><span class="line"># 指定Redis监听端口，默认端口为6379</span><br><span class="line"># 如果指定0端口，表示Redis不监听TCP连接</span><br><span class="line">port 6379</span><br><span class="line"></span><br><span class="line"># 绑定的主机地址</span><br><span class="line"># 你可以绑定单一接口，如果没有绑定，所有接口都会监听到来的连接</span><br><span class="line"># bind 127.0.0.1</span><br><span class="line"></span><br><span class="line"># Specify the path for the unix socket that will be used to listen for</span><br><span class="line"># incoming connections. There is no default, so Redis will not listen</span><br><span class="line"># on a unix socket when not specified.</span><br><span class="line">#</span><br><span class="line"># unixsocket /tmp/redis.sock</span><br><span class="line"># unixsocketperm 755</span><br><span class="line"></span><br><span class="line"># 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能</span><br><span class="line">timeout 0</span><br><span class="line"></span><br><span class="line"># 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose</span><br><span class="line"># debug (很多信息, 对开发／测试比较有用)</span><br><span class="line"># verbose (many rarely useful info, but not a mess like the debug level)</span><br><span class="line"># notice (moderately verbose, what you want in production probably)</span><br><span class="line"># warning (only very important / critical messages are logged)</span><br><span class="line">loglevel verbose</span><br><span class="line"></span><br><span class="line"># 日志记录方式，默认为标准输出，如果配置为redis为守护进程方式运行，而这里又配置为标准输出，则日志将会发送给/dev/null</span><br><span class="line">logfile stdout</span><br><span class="line"></span><br><span class="line"># To enable logging to the system logger, just set &apos;syslog-enabled&apos; to yes,</span><br><span class="line"># and optionally update the other syslog parameters to suit your needs.</span><br><span class="line"># syslog-enabled no</span><br><span class="line"></span><br><span class="line"># Specify the syslog identity.</span><br><span class="line"># syslog-ident redis</span><br><span class="line"></span><br><span class="line"># Specify the syslog facility.  Must be USER or between LOCAL0-LOCAL7.</span><br><span class="line"># syslog-facility local0</span><br><span class="line"></span><br><span class="line"># 设置数据库的数量，默认数据库为0，可以使用select &lt;dbid&gt;命令在连接上指定数据库id</span><br><span class="line"># dbid是从0到‘databases’-1的数目</span><br><span class="line">databases 16</span><br><span class="line"></span><br><span class="line">################################ SNAPSHOTTING  #################################</span><br><span class="line"># 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合</span><br><span class="line"># Save the DB on disk:</span><br><span class="line">#</span><br><span class="line">#   save &lt;seconds&gt; &lt;changes&gt;</span><br><span class="line">#</span><br><span class="line">#   Will save the DB if both the given number of seconds and the given</span><br><span class="line">#   number of write operations against the DB occurred.</span><br><span class="line">#</span><br><span class="line">#   满足以下条件将会同步数据:</span><br><span class="line">#   900秒（15分钟）内有1个更改</span><br><span class="line">#   300秒（5分钟）内有10个更改</span><br><span class="line">#   60秒内有10000个更改</span><br><span class="line">#   Note: 可以把所有“save”行注释掉，这样就取消同步操作了</span><br><span class="line"></span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line"></span><br><span class="line"># 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大</span><br><span class="line">rdbcompression yes</span><br><span class="line"></span><br><span class="line"># 指定本地数据库文件名，默认值为dump.rdb</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line"></span><br><span class="line"># 工作目录.</span><br><span class="line"># 指定本地数据库存放目录，文件名由上一个dbfilename配置项指定</span><br><span class="line"># </span><br><span class="line"># Also the Append Only File will be created inside this directory.</span><br><span class="line"># </span><br><span class="line"># 注意，这里只能指定一个目录，不能指定文件名</span><br><span class="line">dir ./</span><br><span class="line"></span><br><span class="line">################################# REPLICATION #################################</span><br><span class="line"></span><br><span class="line"># 主从复制。使用slaveof从 Redis服务器复制一个Redis实例。注意，该配置仅限于当前slave有效</span><br><span class="line"># so for example it is possible to configure the slave to save the DB with a</span><br><span class="line"># different interval, or to listen to another port, and so on.</span><br><span class="line"># 设置当本机为slav服务时，设置master服务的ip地址及端口，在Redis启动时，它会自动从master进行数据同步</span><br><span class="line"># slaveof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 当master服务设置了密码保护时，slav服务连接master的密码</span><br><span class="line"># 下文的“requirepass”配置项可以指定密码</span><br><span class="line"># masterauth &lt;master-password&gt;</span><br><span class="line"></span><br><span class="line"># When a slave lost the connection with the master, or when the replication</span><br><span class="line"># is still in progress, the slave can act in two different ways:</span><br><span class="line">#</span><br><span class="line"># 1) if slave-serve-stale-data is set to &apos;yes&apos; (the default) the slave will</span><br><span class="line">#    still reply to client requests, possibly with out of data data, or the</span><br><span class="line">#    data set may just be empty if this is the first synchronization.</span><br><span class="line">#</span><br><span class="line"># 2) if slave-serve-stale data is set to &apos;no&apos; the slave will reply with</span><br><span class="line">#    an error &quot;SYNC with master in progress&quot; to all the kind of commands</span><br><span class="line">#    but to INFO and SLAVEOF.</span><br><span class="line">#</span><br><span class="line">slave-serve-stale-data yes</span><br><span class="line"></span><br><span class="line"># Slaves send PINGs to server in a predefined interval. It&apos;s possible to change</span><br><span class="line"># this interval with the repl_ping_slave_period option. The default value is 10</span><br><span class="line"># seconds.</span><br><span class="line">#</span><br><span class="line"># repl-ping-slave-period 10</span><br><span class="line"></span><br><span class="line"># The following option sets a timeout for both Bulk transfer I/O timeout and</span><br><span class="line"># master data or ping response timeout. The default value is 60 seconds.</span><br><span class="line">#</span><br><span class="line"># It is important to make sure that this value is greater than the value</span><br><span class="line"># specified for repl-ping-slave-period otherwise a timeout will be detected</span><br><span class="line"># every time there is low traffic between the master and the slave.</span><br><span class="line">#</span><br><span class="line"># repl-timeout 60</span><br><span class="line"></span><br><span class="line">################################## SECURITY ###################################</span><br><span class="line"></span><br><span class="line"># Warning: since Redis is pretty fast an outside user can try up to</span><br><span class="line"># 150k passwords per second against a good box. This means that you should</span><br><span class="line"># use a very strong password otherwise it will be very easy to break.</span><br><span class="line"># 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过auth &lt;password&gt;命令提供密码，默认关闭</span><br><span class="line"># requirepass foobared</span><br><span class="line"></span><br><span class="line"># Command renaming.</span><br><span class="line">#</span><br><span class="line"># It is possilbe to change the name of dangerous commands in a shared</span><br><span class="line"># environment. For instance the CONFIG command may be renamed into something</span><br><span class="line"># of hard to guess so that it will be still available for internal-use</span><br><span class="line"># tools but not available for general clients.</span><br><span class="line">#</span><br><span class="line"># Example:</span><br><span class="line">#</span><br><span class="line"># rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52</span><br><span class="line">#</span><br><span class="line"># It is also possilbe to completely kill a command renaming it into</span><br><span class="line"># an empty string:</span><br><span class="line">#</span><br><span class="line"># rename-command CONFIG &quot;&quot;</span><br><span class="line"></span><br><span class="line">################################### LIMITS ####################################</span><br><span class="line"></span><br><span class="line"># 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，</span><br><span class="line"># 如果设置maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max Number of clients reached错误信息</span><br><span class="line"># maxclients 128</span><br><span class="line"></span><br><span class="line"># Don&apos;t use more memory than the specified amount of bytes.</span><br><span class="line"># When the memory limit is reached Redis will try to remove keys with an</span><br><span class="line"># EXPIRE set. It will try to start freeing keys that are going to expire</span><br><span class="line"># in little time and preserve keys with a longer time to live.</span><br><span class="line"># Redis will also try to remove objects from free lists if possible.</span><br><span class="line">#</span><br><span class="line"># If all this fails, Redis will start to reply with errors to commands</span><br><span class="line"># that will use more memory, like SET, LPUSH, and so on, and will continue</span><br><span class="line"># to reply to most read-only commands like GET.</span><br><span class="line">#</span><br><span class="line"># WARNING: maxmemory can be a good idea mainly if you want to use Redis as a</span><br><span class="line"># &apos;state&apos; server or cache, not as a real DB. When Redis is used as a real</span><br><span class="line"># database the memory usage will grow over the weeks, it will be obvious if</span><br><span class="line"># it is going to use too much memory in the long run, and you&apos;ll have the time</span><br><span class="line"># to upgrade. With maxmemory after the limit is reached you&apos;ll start to get</span><br><span class="line"># errors for write operations, and this may even lead to DB inconsistency.</span><br><span class="line"># 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，</span><br><span class="line"># 当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。</span><br><span class="line"># Redis新的vm机制，会把Key存放内存，Value会存放在swap区</span><br><span class="line"># maxmemory &lt;bytes&gt;</span><br><span class="line"></span><br><span class="line"># MAXMEMORY POLICY: how Redis will select what to remove when maxmemory</span><br><span class="line"># is reached? You can select among five behavior:</span><br><span class="line"># </span><br><span class="line"># volatile-lru -&gt; remove the key with an expire set using an LRU algorithm</span><br><span class="line"># allkeys-lru -&gt; remove any key accordingly to the LRU algorithm</span><br><span class="line"># volatile-random -&gt; remove a random key with an expire set</span><br><span class="line"># allkeys-&gt;random -&gt; remove a random key, any key</span><br><span class="line"># volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)</span><br><span class="line"># noeviction -&gt; don&apos;t expire at all, just return an error on write operations</span><br><span class="line"># </span><br><span class="line"># Note: with all the kind of policies, Redis will return an error on write</span><br><span class="line">#       operations, when there are not suitable keys for eviction.</span><br><span class="line">#</span><br><span class="line">#       At the date of writing this commands are: set setnx setex append</span><br><span class="line">#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd</span><br><span class="line">#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby</span><br><span class="line">#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby</span><br><span class="line">#       getset mset msetnx exec sort</span><br><span class="line">#</span><br><span class="line"># The default is:</span><br><span class="line">#</span><br><span class="line"># maxmemory-policy volatile-lru</span><br><span class="line"></span><br><span class="line"># LRU and minimal TTL algorithms are not precise algorithms but approximated</span><br><span class="line"># algorithms (in order to save memory), so you can select as well the sample</span><br><span class="line"># size to check. For instance for default Redis will check three keys and</span><br><span class="line"># pick the one that was used less recently, you can change the sample size</span><br><span class="line"># using the following configuration directive.</span><br><span class="line">#</span><br><span class="line"># maxmemory-samples 3</span><br><span class="line"></span><br><span class="line">############################## APPEND ONLY MODE ###############################</span><br><span class="line"></span><br><span class="line"># </span><br><span class="line"># Note that you can have both the async dumps and the append only file if you</span><br><span class="line"># like (you have to comment the &quot;save&quot; statements above to disable the dumps).</span><br><span class="line"># Still if append only mode is enabled Redis will load the data from the</span><br><span class="line"># log file at startup ignoring the dump.rdb file.</span><br><span class="line"># 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。</span><br><span class="line"># 因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no</span><br><span class="line"># IMPORTANT: Check the BGREWRITEAOF to check how to rewrite the append</span><br><span class="line"># log file in background when it gets too big.</span><br><span class="line"></span><br><span class="line">appendonly no</span><br><span class="line"></span><br><span class="line"># 指定更新日志文件名，默认为appendonly.aof</span><br><span class="line"># appendfilename appendonly.aof</span><br><span class="line"></span><br><span class="line"># The fsync() call tells the Operating System to actually write data on disk</span><br><span class="line"># instead to wait for more data in the output buffer. Some OS will really flush </span><br><span class="line"># data on disk, some other OS will just try to do it ASAP.</span><br><span class="line"></span><br><span class="line"># 指定更新日志条件，共有3个可选值：</span><br><span class="line"># no:表示等操作系统进行数据缓存同步到磁盘（快）</span><br><span class="line"># always:表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）</span><br><span class="line"># everysec:表示每秒同步一次（折衷，默认值）</span><br><span class="line"></span><br><span class="line">appendfsync everysec</span><br><span class="line"># appendfsync no</span><br><span class="line"></span><br><span class="line"># When the AOF fsync policy is set to always or everysec, and a background</span><br><span class="line"># saving process (a background save or AOF log background rewriting) is</span><br><span class="line"># performing a lot of I/O against the disk, in some Linux configurations</span><br><span class="line"># Redis may block too long on the fsync() call. Note that there is no fix for</span><br><span class="line"># this currently, as even performing fsync in a different thread will block</span><br><span class="line"># our synchronous write(2) call.</span><br><span class="line">#</span><br><span class="line"># In order to mitigate this problem it&apos;s possible to use the following option</span><br><span class="line"># that will prevent fsync() from being called in the main process while a</span><br><span class="line"># BGSAVE or BGREWRITEAOF is in progress.</span><br><span class="line">#</span><br><span class="line"># This means that while another child is saving the durability of Redis is</span><br><span class="line"># the same as &quot;appendfsync none&quot;, that in pratical terms means that it is</span><br><span class="line"># possible to lost up to 30 seconds of log in the worst scenario (with the</span><br><span class="line"># default Linux settings).</span><br><span class="line"># </span><br><span class="line"># If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as</span><br><span class="line"># &quot;no&quot; that is the safest pick from the point of view of durability.</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"># Automatic rewrite of the append only file.</span><br><span class="line"># Redis is able to automatically rewrite the log file implicitly calling</span><br><span class="line"># BGREWRITEAOF when the AOF log size will growth by the specified percentage.</span><br><span class="line"># </span><br><span class="line"># This is how it works: Redis remembers the size of the AOF file after the</span><br><span class="line"># latest rewrite (or if no rewrite happened since the restart, the size of</span><br><span class="line"># the AOF at startup is used).</span><br><span class="line">#</span><br><span class="line"># This base size is compared to the current size. If the current size is</span><br><span class="line"># bigger than the specified percentage, the rewrite is triggered. Also</span><br><span class="line"># you need to specify a minimal size for the AOF file to be rewritten, this</span><br><span class="line"># is useful to avoid rewriting the AOF file even if the percentage increase</span><br><span class="line"># is reached but it is still pretty small.</span><br><span class="line">#</span><br><span class="line"># Specify a precentage of zero in order to disable the automatic AOF</span><br><span class="line"># rewrite feature.</span><br><span class="line"></span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"></span><br><span class="line">################################## SLOW LOG ###################################</span><br><span class="line"></span><br><span class="line"># The Redis Slow Log is a system to log queries that exceeded a specified</span><br><span class="line"># execution time. The execution time does not include the I/O operations</span><br><span class="line"># like talking with the client, sending the reply and so forth,</span><br><span class="line"># but just the time needed to actually execute the command (this is the only</span><br><span class="line"># stage of command execution where the thread is blocked and can not serve</span><br><span class="line"># other requests in the meantime).</span><br><span class="line"># </span><br><span class="line"># You can configure the slow log with two parameters: one tells Redis</span><br><span class="line"># what is the execution time, in microseconds, to exceed in order for the</span><br><span class="line"># command to get logged, and the other parameter is the length of the</span><br><span class="line"># slow log. When a new command is logged the oldest one is removed from the</span><br><span class="line"># queue of logged commands.</span><br><span class="line"></span><br><span class="line"># The following time is expressed in microseconds, so 1000000 is equivalent</span><br><span class="line"># to one second. Note that a negative number disables the slow log, while</span><br><span class="line"># a value of zero forces the logging of every command.</span><br><span class="line">slowlog-log-slower-than 10000</span><br><span class="line"></span><br><span class="line"># There is no limit to this length. Just be aware that it will consume memory.</span><br><span class="line"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span><br><span class="line">slowlog-max-len 1024</span><br><span class="line"></span><br><span class="line">################################ VIRTUAL MEMORY ###############################</span><br><span class="line"></span><br><span class="line">### WARNING! Virtual Memory is deprecated in Redis 2.4</span><br><span class="line">### The use of Virtual Memory is strongly discouraged.</span><br><span class="line"></span><br><span class="line">### WARNING! Virtual Memory is deprecated in Redis 2.4</span><br><span class="line">### The use of Virtual Memory is strongly discouraged.</span><br><span class="line"></span><br><span class="line"># Virtual Memory allows Redis to work with datasets bigger than the actual</span><br><span class="line"># amount of RAM needed to hold the whole dataset in memory.</span><br><span class="line"># In order to do so very used keys are taken in memory while the other keys</span><br><span class="line"># are swapped into a swap file, similarly to what operating systems do</span><br><span class="line"># with memory pages.</span><br><span class="line"># 指定是否启用虚拟内存机制，默认值为no，</span><br><span class="line"># VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中</span><br><span class="line"># 把vm-enabled设置为yes，根据需要设置好接下来的三个VM参数，就可以启动VM了</span><br><span class="line">vm-enabled no</span><br><span class="line"># vm-enabled yes</span><br><span class="line"></span><br><span class="line"># This is the path of the Redis swap file. As you can guess, swap files</span><br><span class="line"># can&apos;t be shared by different Redis instances, so make sure to use a swap</span><br><span class="line"># file for every redis process you are running. Redis will complain if the</span><br><span class="line"># swap file is already in use.</span><br><span class="line">#</span><br><span class="line"># Redis交换文件最好的存储是SSD（固态硬盘）</span><br><span class="line"># 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享</span><br><span class="line"># *** WARNING *** if you are using a shared hosting the default of putting</span><br><span class="line"># the swap file under /tmp is not secure. Create a dir with access granted</span><br><span class="line"># only to Redis user and configure Redis to create the swap file there.</span><br><span class="line">vm-swap-file /tmp/redis.swap</span><br><span class="line"></span><br><span class="line"># With vm-max-memory 0 the system will swap everything it can. Not a good</span><br><span class="line"># default, just specify the max amount of RAM you can in bytes, but it&apos;s</span><br><span class="line"># better to leave some margin. For instance specify an amount of RAM</span><br><span class="line"># that&apos;s more or less between 60 and 80% of your free RAM.</span><br><span class="line"># 将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多少，所有索引数据都是内存存储的（Redis的索引数据就是keys）</span><br><span class="line"># 也就是说当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认值为0</span><br><span class="line">vm-max-memory 0</span><br><span class="line"></span><br><span class="line"># Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的。</span><br><span class="line"># 建议如果存储很多小对象，page大小最后设置为32或64bytes；如果存储很大的对象，则可以使用更大的page，如果不确定，就使用默认值</span><br><span class="line">vm-page-size 32</span><br><span class="line"></span><br><span class="line"># 设置swap文件中的page数量由于页表（一种表示页面空闲或使用的bitmap）是存放在内存中的，在磁盘上每8个pages将消耗1byte的内存</span><br><span class="line"># swap空间总容量为 vm-page-size * vm-pages</span><br><span class="line">#</span><br><span class="line"># With the default of 32-bytes memory pages and 134217728 pages Redis will</span><br><span class="line"># use a 4 GB swap file, that will use 16 MB of RAM for the page table.</span><br><span class="line">#</span><br><span class="line"># It&apos;s better to use the smallest acceptable value for your application,</span><br><span class="line"># but the default is large in order to work in most conditions.</span><br><span class="line">vm-pages 134217728</span><br><span class="line"></span><br><span class="line"># Max number of VM I/O threads running at the same time.</span><br><span class="line"># This threads are used to read/write data from/to swap file, since they</span><br><span class="line"># also encode and decode objects from disk to memory or the reverse, a bigger</span><br><span class="line"># number of threads can help with big objects even if they can&apos;t help with</span><br><span class="line"># I/O itself as the physical device may not be able to couple with many</span><br><span class="line"># reads/writes operations at the same time.</span><br><span class="line"># 设置访问swap文件的I/O线程数，最后不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟，默认值为4</span><br><span class="line">vm-max-threads 4</span><br><span class="line"></span><br><span class="line">############################### ADVANCED CONFIG ###############################</span><br><span class="line"></span><br><span class="line"># Hashes are encoded in a special way (much more memory efficient) when they</span><br><span class="line"># have at max a given numer of elements, and the biggest element does not</span><br><span class="line"># exceed a given threshold. You can configure this limits with the following</span><br><span class="line"># configuration directives.</span><br><span class="line"># 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法</span><br><span class="line">hash-max-zipmap-entries 512</span><br><span class="line">hash-max-zipmap-value 64</span><br><span class="line"></span><br><span class="line"># Similarly to hashes, small lists are also encoded in a special way in order</span><br><span class="line"># to save a lot of space. The special representation is only used when</span><br><span class="line"># you are under the following limits:</span><br><span class="line">list-max-ziplist-entries 512</span><br><span class="line">list-max-ziplist-value 64</span><br><span class="line"></span><br><span class="line"># Sets have a special encoding in just one case: when a set is composed</span><br><span class="line"># of just strings that happens to be integers in radix 10 in the range</span><br><span class="line"># of 64 bit signed integers.</span><br><span class="line"># The following configuration setting sets the limit in the size of the</span><br><span class="line"># set in order to use this special memory saving encoding.</span><br><span class="line">set-max-intset-entries 512</span><br><span class="line"></span><br><span class="line"># Similarly to hashes and lists, sorted sets are also specially encoded in</span><br><span class="line"># order to save a lot of space. This encoding is only used when the length and</span><br><span class="line"># elements of a sorted set are below the following limits:</span><br><span class="line">zset-max-ziplist-entries 128</span><br><span class="line">zset-max-ziplist-value 64</span><br><span class="line"></span><br><span class="line"># Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in</span><br><span class="line"># order to help rehashing the main Redis hash table (the one mapping top-level</span><br><span class="line"># keys to values). The hash table implementation redis uses (see dict.c)</span><br><span class="line"># performs a lazy rehashing: the more operation you run into an hash table</span><br><span class="line"># that is rhashing, the more rehashing &quot;steps&quot; are performed, so if the</span><br><span class="line"># server is idle the rehashing is never complete and some more memory is used</span><br><span class="line"># by the hash table.</span><br><span class="line"># </span><br><span class="line"># The default is to use this millisecond 10 times every second in order to</span><br><span class="line"># active rehashing the main dictionaries, freeing memory when possible.</span><br><span class="line">#</span><br><span class="line"># If unsure:</span><br><span class="line"># use &quot;activerehashing no&quot; if you have hard latency requirements and it is</span><br><span class="line"># not a good thing in your environment that Redis can reply form time to time</span><br><span class="line"># to queries with 2 milliseconds delay.</span><br><span class="line"># 指定是否激活重置哈希，默认为开启</span><br><span class="line">activerehashing yes</span><br><span class="line"></span><br><span class="line">################################## INCLUDES ###################################</span><br><span class="line"></span><br><span class="line"># 指定包含其他的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各实例又拥有自己的特定配置文件</span><br><span class="line"># include /path/to/local.conf</span><br><span class="line"># include /path/to/other.conf</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Dec 05 2018 11:52:38 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;由于公司开发笔记本用的是mac，所以我这里介绍一下在mac和linux环境下的redis安装&lt;/p&gt;&lt;h2 id=&quot;Linu
      
    
    </summary>
    
    
      <category term="redis" scheme="http://www.fufan.me/tags/redis/"/>
    
  </entry>
  
</feed>
