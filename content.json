{"pages":[{"title":"About Me","date":"2017-11-26T03:42:51.000Z","updated":"2018-10-02T12:59:31.889Z","comments":true,"path":"about/index.html","permalink":"http://www.fufan.me/about/index.html","excerpt":"","text":"I AM WHAT I AM ……"},{"title":"tags","date":"2017-11-16T09:08:20.000Z","updated":"2018-10-02T07:52:02.919Z","comments":true,"path":"tags/index.html","permalink":"http://www.fufan.me/tags/index.html","excerpt":"","text":""},{"title":"Categories","date":"2017-11-14T05:59:36.000Z","updated":"2018-10-02T07:50:02.801Z","comments":true,"path":"categories/index.html","permalink":"http://www.fufan.me/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"常用的vim命令整理（持续更新）","slug":"常用的vim命令整理（持续更新）","date":"2017-10-02T12:58:00.000Z","updated":"2018-11-04T14:46:09.403Z","comments":true,"path":"2017/10/02/常用的vim命令整理（持续更新）/","link":"","permalink":"http://www.fufan.me/2017/10/02/常用的vim命令整理（持续更新）/","excerpt":"","text":"1. 插入模式 (command mode)命令模式切换至插入状态i光标前插入I行首插入a光标后插入A行尾插入o行上新行O行下新行2. 命令模式 (insert mode)ESC从插入状态切换至命令模式光标移动h左移j下移k上移l右移H到屏幕顶部M到屏幕中央L到屏幕底部0到行首$到行尾Ctrl+f向前翻屏Ctrl+b向后翻屏Ctrl+d向前翻半屏Ctrl+u向后翻半屏定位gg回到文件首行,G回到文件尾行:n和nG光标定位到文件第n行(:20或20G表示光标定位到第20行):set nu 或:set number显示行号,:set nonu 取消显示行号ctrl+g删除x删除光标所在字符(与Delete键相同的方向),X删除光标所在字符(与Backspace键相同的方向)nx删除光标后n个字符dd删除光标所在行ndd删除光标所在行以后的n行D删除光标到行尾的内容dG删除光标所在行到文件末尾的内容n1,n2d删除行n1到行n2的内容，包括第n1和n2行都被删除s删除一个字符来插入模式S删除当前行以插入模式复制、剪切、粘贴、替换yy或Y复制当前行nyy或nY从当前行开始赋值n行ggVG全选剪切使用dd和ndd，相当于删除p在光标所在行之后粘贴P在光标所在行之前粘贴r替换当前字符后回到命令模式R一直替换知道通过ESC回到命令模式查找、替换\\KeyWord回车，n查找下一处?KeyWord回车，n查找上一处n重复相同方向N重复反向方向·:s/old/new/g替换整个文件，不确认:s/old/new/gc替换整个文件，确认:n1,n2s/old/new/g替换n1-n2行中匹配内容，不确认撤销u保存及离开:w保存文件:w!强制保存:w file将修改另外保存到file:wq保存文件并退出:wq!强制保存文件并退出:q不保存退出:q!不保存强制退出:e!放弃所有修改，从上次保存文件开始再编辑","categories":[],"tags":[]},{"title":"ssh免密码登录步骤及别名设置","slug":"ssh免密码登录步骤及别名设置","date":"2017-10-02T05:23:00.000Z","updated":"2018-11-04T14:45:55.388Z","comments":true,"path":"2017/10/02/ssh免密码登录步骤及别名设置/","link":"","permalink":"http://www.fufan.me/2017/10/02/ssh免密码登录步骤及别名设置/","excerpt":"","text":"ssh免密码登录步骤及别名设置1. 生成本机的公私钥ssh-keygen -t rsa2. 将公钥复制到目标机器上ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.1003. 设置别名登录vim ~/.ssh/config添加如下内容123456Host 100HostName 192.168.0.100Port 22User rootIdentityFile ~/.ssh/id_rsa.pubIdentitiesOnly yes4. 登录ssh 100","categories":[{"name":"linux","slug":"linux","permalink":"http://www.fufan.me/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://www.fufan.me/tags/linux/"}]},{"title":"java多线程系列（八）——执行器Executor并发框架","slug":"Untitled","date":"2017-06-15T18:32:00.000Z","updated":"2018-11-05T18:34:33.969Z","comments":true,"path":"2017/06/16/Untitled/","link":"","permalink":"http://www.fufan.me/2017/06/16/Untitled/","excerpt":"","text":"线程池的架构图如下：1. Executor它是”执行者”接口，它是来执行任务的。准确的说，Executor提供了execute()接口来执行已提交的 Runnable 任务的对象。Executor存在的目的是提供一种将”任务提交”与”任务如何运行”分离开来的机制。它只包含一个函数接口：2. ExecutorServicexecutorService继承于Executor。它是”执行者服务”接口，它是为”执行者接口Executor”服务而存在的；准确的话，ExecutorService提供了”将任务提交给执行者的接口(submit方法)”，”让执行者执行任务(invokeAll, invokeAny方法)”的接口等等。3. AbstractExecutorServiceAbstractExecutorService是一个抽象类，它实现了ExecutorService接口。AbstractExecutorService存在的目的是为ExecutorService中的函数接口提供了默认实现。其实基本上抽象方法的作用一般也就是为了提供默认的实现，不过我们在jdk1.8开始，可以使用接口的默认方法，即default关键字。4. ThreadPoolExecutorThreadPoolExecutor就是大名鼎鼎的”线程池”。它继承于AbstractExecutorService抽象类。构造方法的核心参数corePoolSize：核心线程数量，当有新任务在execute()方法提交时，会执行以下判断：如果运行的线程少于 corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的；如果线程池中的线程数量大于等于 corePoolSize 且小于 maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务；如果设置的corePoolSize 和 maximumPoolSize相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理；如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务；所以，任务提交时，判断的顺序为 corePoolSize –&gt; workQueue –&gt; maximumPoolSize。maximumPoolSize：最大线程数量；workQueue：等待队列，当任务提交时，如果线程池中的线程数量大于等于corePoolSize的时候，把该任务封装成一个Worker对象放入等待队列；workQueue：保存等待执行的任务的阻塞队列，当提交一个新的任务到线程池以后, 线程池会根据当前线程池中正在运行着的线程的数量来决定对该任务的处理方式，主要有以下几种处理方式:直接切换：这种方式常用的队列是SynchronousQueue，但现在还没有研究过该队列，这里暂时还没法介绍；使用无界队列：一般使用基于链表的阻塞队列LinkedBlockingQueue。如果使用这种方式，那么线程池中能够创建的最大线程数就是corePoolSize，而maximumPoolSize就不会起作用了（后面也会说到）。当线程池中所有的核心线程都是RUNNING状态时，这时一个新的任务提交就会放入等待队列中。使用有界队列：一般使用ArrayBlockingQueue。使用该方式可以将线程池的最大线程数量限制为maximumPoolSize，这样能够降低资源的消耗，但同时这种方式也使得线程池对线程的调度变得更困难，因为线程池和队列的容量都是有限的值，所以要想使线程池处理任务的吞吐率达到一个相对合理的范围，又想使线程调度相对简单，并且还要尽可能的降低线程池对资源的消耗，就需要合理的设置这两个数量。如果要想降低系统资源的消耗（包括CPU的使用率，操作系统资源的消耗，上下文环境切换的开销等）, 可以设置较大的队列容量和较小的线程池容量, 但这样也会降低线程处理任务的吞吐量。如果提交的任务经常发生阻塞，那么可以考虑通过调用 setMaximumPoolSize() 方法来重新设定线程池的容量。如果队列的容量设置的较小，通常需要将线程池的容量设置大一点，这样CPU的使用率会相对的高一些。但如果线程池的容量设置的过大，则在提交的任务数量太多的情况下，并发量会增加，那么线程之间的调度就是一个要考虑的问题，因为这样反而有可能降低处理任务的吞吐量。keepAliveTime：线程池维护线程所允许的空闲时间。当线程池中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime；threadFactory：它是ThreadFactory类型的变量，用来创建新线程。默认使用Executors.defaultThreadFactory() 来创建线程。使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称。handler：它是RejectedExecutionHandler类型的变量，表示线程池的饱和策略。如果阻塞队列满了并且没有空闲的线程，这时如果继续提交任务，就需要采取一种策略处理该任务。线程池提供了4种策略：AbortPolicy：直接抛出异常，这是默认策略；CallerRunsPolicy：用调用者所在的线程来执行任务；DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；DiscardPolicy：直接丢弃任务；execute()execute()方法用来提交任务，代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * clt记录着runState和workerCount */ int c = ctl.get(); /* * workerCountOf方法取出低29位的值，表示当前活动的线程数； * 如果当前活动线程数小于corePoolSize，则新建一个线程放入线程池中； * 并把任务添加到该线程中。 */ if (workerCountOf(c) &lt; corePoolSize) &#123; /* * addWorker中的第二个参数表示限制添加线程的数量是根据corePoolSize来判断还是maximumPoolSize来判断； * 如果为true，根据corePoolSize来判断； * 如果为false，则根据maximumPoolSize来判断 */ if (addWorker(command, true)) return; /* * 如果添加失败，则重新获取ctl值 */ c = ctl.get(); &#125; /* * 如果当前线程池是运行状态并且任务添加到队列成功 */ if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 重新获取ctl值 int recheck = ctl.get(); // 再次判断线程池的运行状态，如果不是运行状态，由于之前已经把command添加到workQueue中了， // 这时需要移除该command // 执行过后通过handler使用拒绝策略对该任务进行处理，整个方法返回 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); /* * 获取线程池中的有效线程数，如果数量是0，则执行addWorker方法 * 这里传入的参数表示： * 1. 第一个参数为null，表示在线程池中创建一个线程，但不去启动； * 2. 第二个参数为false，将线程池的有限线程数量的上限设置为maximumPoolSize，添加线程时根据maximumPoolSize来判断； * 如果判断workerCount大于0，则直接返回，在workQueue中新增的command会在将来的某个时刻被执行。 */ else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; /* * 如果执行到这里，有两种情况： * 1. 线程池已经不是RUNNING状态； * 2. 线程池是RUNNING状态，但workerCount &gt;= corePoolSize并且workQueue已满。 * 这时，再次调用addWorker方法，但第二个参数传入为false，将线程池的有限线程数量的上限设置为maximumPoolSize； * 如果失败则拒绝该任务 */ else if (!addWorker(command, false)) reject(command);&#125;简单来说，在执行execute()方法时如果状态一直是RUNNING时，的执行过程如下：如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务；如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中；如果workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务；如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。这里要注意一下addWorker(null, false);，也就是创建一个线程，但并没有传入任务，因为任务已经被添加到workQueue中了，所以worker在执行的时候，会直接从workQueue中获取任务。所以，在workerCountOf(recheck) == 0时执行addWorker(null, false);也是为了保证线程池在RUNNING状态下必须要有一个线程来执行任务。execute方法执行流程如下：addWorker方法addWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数 用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); // 获取运行状态 int rs = runStateOf(c); /* * 这个if判断 * 如果rs &gt;= SHUTDOWN，则表示此时不再接收新任务； * 接着判断以下3个条件，只要有1个不满足，则返回false： * 1. rs == SHUTDOWN，这时表示关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务 * 2. firsTask为空 * 3. 阻塞队列不为空 * * 首先考虑rs == SHUTDOWN的情况 * 这种情况下不会接受新提交的任务，所以在firstTask不为空的时候会返回false； * 然后，如果firstTask为空，并且workQueue也为空，则返回false， * 因为队列中已经没有任务了，不需要再添加线程了 */ // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; // 获取线程数 int wc = workerCountOf(c); // 如果wc超过CAPACITY，也就是ctl的低29位的最大值（二进制是29个1），返回false； // 这里的core是addWorker方法的第二个参数，如果为true表示根据corePoolSize来比较， // 如果为false则根据maximumPoolSize来比较。 // if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 尝试增加workerCount，如果成功，则跳出第一个for循环 if (compareAndIncrementWorkerCount(c)) break retry; // 如果增加workerCount失败，则重新获取ctl的值 c = ctl.get(); // Re-read ctl // 如果当前的运行状态不等于rs，说明状态已被改变，返回第一个for循环继续执行 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // 根据firstTask来创建Worker对象 w = new Worker(firstTask); // 每一个Worker对象都会创建一个线程 final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // rs &lt; SHUTDOWN表示是RUNNING状态； // 如果rs是RUNNING状态或者rs是SHUTDOWN状态并且firstTask为null，向线程池中添加线程。 // 因为在SHUTDOWN时不会在添加新的任务，但还是会执行workQueue中的任务 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // workers是一个HashSet workers.add(w); int s = workers.size(); // largestPoolSize记录着线程池中出现过的最大线程数量 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 启动线程 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125;注意一下这里的t.start()这个语句，启动时会调用Worker类中的run方法，Worker本身实现了Runnable接口，所以一个Worker类型的对象也是一个线程。Worker类线程池中的每一个线程被封装成一个Worker对象，ThreadPool维护的其实就是一组Worker对象，看一下Worker的定义：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 获取第一个任务 Runnable task = w.firstTask; w.firstTask = null; // 允许中断 w.unlock(); // allow interrupts // 是否因为异常退出循环 boolean completedAbruptly = true; try &#123; // 如果task为空，则通过getTask来获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125;这里说明一下第一个if判断，目的是：如果线程池正在停止，那么要保证当前线程是中断状态；如果不是的话，则要保证当前线程不是中断状态；这里要考虑在执行该if语句期间可能也执行了shutdownNow方法，shutdownNow方法会把状态设置为STOP，回顾一下STOP状态：不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态。 STOP状态要中断线程池中的所有线程，而这里使用Thread.interrupted()来判断是否中断是为了确保在RUNNING或者SHUTDOWN状态时线程是非中断状态的，因为Thread.interrupted()方法会复位中断的状态。总结一下runWorker方法的执行过程：while循环不断地通过getTask()方法获取任务；getTask()方法从阻塞队列中取任务；如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态；调用task.run()执行任务；如果task为null则跳出循环，执行processWorkerExit()方法；runWorker方法执行完毕，也代表着Worker中的run方法执行完毕，销毁线程。这里的beforeExecute方法和afterExecute方法在ThreadPoolExecutor类中是空的，留给子类来实现。completedAbruptly变量来表示在执行任务过程中是否出现了异常，在processWorkerExit方法中会对该变量的值进行判断。getTaskgetTask方法用来从阻塞队列中取任务，代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private Runnable getTask() &#123; // timeOut变量的值表示上次从阻塞队列中取任务时是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. /* * 如果线程池状态rs &gt;= SHUTDOWN，也就是非RUNNING状态，再进行以下判断： * 1. rs &gt;= STOP，线程池是否正在stop； * 2. 阻塞队列是否为空。 * 如果以上条件满足，则将workerCount减1并返回null。 * 因为如果当前线程池状态的值是SHUTDOWN或以上时，不允许再向阻塞队列中添加任务。 */ if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? // timed变量用于判断是否需要进行超时控制。 // allowCoreThreadTimeOut默认是false，也就是核心线程不允许进行超时； // wc &gt; corePoolSize，表示当前线程池中的线程数量大于核心线程数量； // 对于超过核心线程数量的这些线程，需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; /* * wc &gt; maximumPoolSize的情况是因为可能在此方法执行阶段同时执行了setMaximumPoolSize方法； * timed &amp;&amp; timedOut 如果为true，表示当前操作需要进行超时控制，并且上次从阻塞队列中获取任务发生了超时 * 接下来判断，如果有效线程数量大于1，或者阻塞队列是空的，那么尝试将workerCount减1； * 如果减1失败，则返回重试。 * 如果wc == 1时，也就说明当前线程是线程池中唯一的一个线程了。 */ if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; /* * 根据timed来判断，如果为true，则通过阻塞队列的poll方法进行超时控制，如果在keepAliveTime时间内没有获取到任务，则返回null； * 否则通过take方法，如果这时队列为空，则take方法会阻塞直到队列不为空。 * */ Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; // 如果 r == null，说明已经超时，timedOut设置为true timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果获取任务时当前线程发生了中断，则设置timedOut为false并返回循环重试 timedOut = false; &#125; &#125;&#125;这里重要的地方是第二个if判断，目的是控制线程池的有效线程数量。由上文中的分析可以知道，在执行execute方法时，如果当前线程池的线程数量超过了corePoolSize且小于maximumPoolSize，并且workQueue已满时，则可以增加工作线程，但这时如果超时没有获取到任务，也就是timedOut为true的情况，说明workQueue已经为空了，也就说明了当前线程池中不需要那么多线程来执行任务了，可以把多于corePoolSize数量的线程销毁掉，保持线程数量在corePoolSize即可。什么时候会销毁？当然是runWorker方法执行完之后，也就是Worker中的run方法执行完，由JVM自动回收。getTask方法返回null时，在runWorker方法中会跳出while循环，然后会执行processWorkerExit方法。processWorkerExit方法12345678910111213141516171819202122232425262728293031323334private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果completedAbruptly值为true，则说明线程执行时出现了异常，需要将workerCount减1； // 如果线程执行时没有出现异常，说明在getTask()方法中已经已经对workerCount进行了减1操作，这里就不必再减了。 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //统计完成的任务数 completedTaskCount += w.completedTasks; // 从workers中移除，也就表示着从线程池中移除了一个工作线程 workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 根据线程池状态进行判断是否结束线程池 tryTerminate(); int c = ctl.get(); /* * 当线程池是RUNNING或SHUTDOWN状态时，如果worker是异常结束，那么会直接addWorker； * 如果allowCoreThreadTimeOut=true，并且等待队列有任务，至少保留一个worker； * 如果allowCoreThreadTimeOut=false，workerCount不少于corePoolSize。 */ if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125;&#125;至此，processWorkerExit执行完之后，工作线程被销毁，以上就是整个工作线程的生命周期，从execute方法开始，Worker使用ThreadFactory创建新的工作线程，runWorker通过getTask获取任务，然后执行任务，如果getTask返回null，进入processWorkerExit方法，整个线程结束，如图所示：tryTerminate方法tryTerminate方法根据线程池状态进行判断是否结束线程池，代码如下：123456789101112131415161718192021222324252627282930313233343536373839final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); /* * 当前线程池的状态为以下几种情况时，直接返回： * 1. RUNNING，因为还在运行中，不能停止； * 2. TIDYING或TERMINATED，因为线程池中已经没有正在运行的线程了； * 3. SHUTDOWN并且等待队列非空，这时要执行完workQueue中的task； */ if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 如果线程数量不为0，则中断一个空闲的工作线程，并返回 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 这里尝试设置状态为TIDYING，如果设置成功，则调用terminated方法 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; // terminated方法默认什么都不做，留给子类实现 terminated(); &#125; finally &#123; // 设置状态为TERMINATED ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125;interruptIdleWorkers(ONLY_ONE);的作用是因为在getTask方法中执行workQueue.take()时，如果不执行中断会一直阻塞。在下面介绍的shutdown方法中，会中断所有空闲的工作线程，如果在执行shutdown时工作线程没有空闲，然后又去调用了getTask方法，这时如果workQueue中没有任务了，调用workQueue.take()时就会一直阻塞。所以每次在工作线程结束时调用tryTerminate方法来尝试中断一个空闲工作线程，避免在队列为空时取任务一直阻塞的情况。shutdown方法shutdown方法要将线程池切换到SHUTDOWN状态，并调用interruptIdleWorkers方法请求中断所有空闲的worker，最后调用tryTerminate尝试结束线程池。123456789101112131415161718public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 安全策略判断 checkShutdownAccess(); // 切换状态为SHUTDOWN advanceRunState(SHUTDOWN); // 中断空闲线程 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 尝试结束线程池 tryTerminate();&#125;这里思考一个问题：在runWorker方法中，执行任务时对Worker对象w进行了lock操作，为什么要在执行任务的时候对每个工作线程都加锁呢？下面仔细分析一下：在getTask方法中，如果这时线程池的状态是SHUTDOWN并且workQueue为空，那么就应该返回null来结束这个工作线程，而使线程池进入SHUTDOWN状态需要调用shutdown方法；shutdown方法会调用interruptIdleWorkers来中断空闲的线程，interruptIdleWorkers持有mainLock，会遍历workers来逐个判断工作线程是否空闲。但getTask方法中没有mainLock；在getTask中，如果判断当前线程池状态是RUNNING，并且阻塞队列为空，那么会调用workQueue.take()进行阻塞；如果在判断当前线程池状态是RUNNING后，这时调用了shutdown方法把状态改为了SHUTDOWN，这时如果不进行中断，那么当前的工作线程在调用了workQueue.take()后会一直阻塞而不会被销毁，因为在SHUTDOWN状态下不允许再有新的任务添加到workQueue中，这样一来线程池永远都关闭不了了；由上可知，shutdown方法与getTask方法（从队列中获取任务时）存在竞态条件；解决这一问题就需要用到线程的中断，也就是为什么要用interruptIdleWorkers方法。在调用workQueue.take()时，如果发现当前线程在执行之前或者执行期间是中断状态，则会抛出InterruptedException，解除阻塞的状态；但是要中断工作线程，还要判断工作线程是否是空闲的，如果工作线程正在处理任务，就不应该发生中断；所以Worker继承自AQS，在工作线程处理任务时会进行lock，interruptIdleWorkers在进行中断时会使用tryLock来判断该工作线程是否正在处理任务，如果tryLock返回true，说明该工作线程当前未执行任务，这时才可以被中断。interruptIdleWorkers方法123456789101112131415161718192021222324private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125;nterruptIdleWorkers遍历workers中所有的工作线程，若线程没有被中断tryLock成功，就中断该线程。为什么需要持有mainLock？因为workers是HashSet类型的，不能保证线程安全。shutdownNow方法1234567891011121314151617public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(STOP); // 中断所有工作线程，无论是否空闲 interruptWorkers(); // 取出队列中没有被执行的任务 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125;shutdownNow方法与shutdown方法类似，不同的地方在于：设置状态为STOP；中断所有工作线程，无论是否是空闲的；取出阻塞队列中没有被执行的任务并返回。shutdownNow方法执行完之后调用tryTerminate方法，该方法在上文已经分析过了，目的就是使线程池的状态设置为TERMINATED。线程池的监控通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用getTaskCount：线程池已经执行的和未执行的任务总数；getCompletedTaskCount：线程池已完成的任务数量，该值小于等于taskCount；getLargestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过，也就是达到了maximumPoolSize；getPoolSize：线程池当前的线程数量；getActiveCount：当前线程池中正在执行任务的线程数量。通过这些方法，可以对线程池进行监控，在ThreadPoolExecutor类中提供了几个空方法，如beforeExecute方法，afterExecute方法和terminated方法，可以扩展这些方法在执行前或执行后增加一些新的操作，例如统计线程池的执行任务的时间等，可以继承自ThreadPoolExecutor来进行扩展。5. ScheduledExecutorServiceScheduledExecutorService是一个接口，它继承于于ExecutorService。它相当于提供了”延时”和”周期执行”功能的ExecutorService。ScheduledExecutorService提供了相应的函数接口，可以安排任务在给定的延迟后执行，也可以让任务周期的执行。6. ScheduledThreadPoolExecutorScheduledThreadPoolExecutor继承于ThreadPoolExecutor，并且实现了ScheduledExecutorService接口。它相当于提供了”延时”和”周期执行”功能的ScheduledExecutorService。ScheduledThreadPoolExecutor类似于Timer，但是在高并发程序中，ScheduledThreadPoolExecutor的性能要优于Timer。7. ExecutorsExecutors是个静态工厂类。它通过静态工厂方法返回ExecutorService、ScheduledExecutorService、ThreadFactory 和 Callable 等类的对象。这里要注意，虽然Executors可以用静态方法来创建很多方便的线程池，但是我们在实际工作中发现，因为如果使用像newFixedThreadPool这种方式创建的线程池，会因为队列无限大，导致无法控制而出现内存溢出的问题，所以，我们创建线程池最优雅的方式是通过继承ThreadPoolExecutor，并重写相应的方法来处理。talk is cheap, let me show the code:12345678910111213/** * 任务处理线程池 */ private class WorkerPool extends ThreadPoolExecutor &#123; public WorkerPool(int coreSize, int maxSize, long keepAlive, TimeUnit timeUnit, BlockingQueue&lt;Runnable&gt; queue, ThreadFactory threadFactory) &#123; super(coreSize, maxSize, keepAlive, timeUnit, queue, threadFactory); &#125; @Override protected void afterExecute(Runnable runnable, Throwable throwable) &#123; super.afterExecute(runnable, throwable); &#125; &#125;这是我在项目中用到的手动构建线程池的简单示例，通过这种方式可以调用对应的构造方法，来构建你需要的线程池，包括参数的配置和策略的更换，只要你理解他是如何运行的，就可以轻松驾驭线程池，并发处理业务代码。博文参考Java多线程系列目录(共43篇)深入理解Java线程池：ThreadPoolExecutor","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/tags/多线程/"}]},{"title":"java多线程系列（七）——JUC锁","slug":"java多线程系列（七）——JUC锁","date":"2017-06-05T17:47:00.000Z","updated":"2018-11-05T17:55:14.987Z","comments":true,"path":"2017/06/06/java多线程系列（七）——JUC锁/","link":"","permalink":"http://www.fufan.me/2017/06/06/java多线程系列（七）——JUC锁/","excerpt":"","text":"下面介绍一下JUC包中可以让我们在多线程并发中使用的锁。UC包中的锁，包括：Lock接口ReadWriteLock接口LockSupport阻塞原语Condition条件AbstractOwnableSynchronizer/AbstractQueuedSynchronizer/AbstractQueuedLongSynchronizer三个抽象类ReentrantLock独占锁ReentrantReadWriteLock读写锁由于CountDownLatch，CyclicBarrier和Semaphore也是通过AQS来实现的；因此，我也将它们归纳到锁的框架中进行介绍。先看看锁的框架图，如下所示。下面简述一下每个类或接口Lock接口JUC包中的 Lock 接口支持那些语义不同(重入、公平等)的锁规则。所谓语义不同，是指锁可是有”公平机制的锁”、”非公平机制的锁”、”可重入的锁”等等。”公平机制”是指”不同线程获取锁的机制是公平的”，而”非公平机制”则是指”不同线程获取锁的机制是非公平的”，”可重入的锁”是指同一个锁能够被一个线程多次获取。ReadWriteLockReadWriteLock 接口以和Lock类似的方式定义了一些读取者可以共享而写入者独占的锁。JUC包只有一个类实现了该接口，即 ReentrantReadWriteLock，因为它适用于大部分的标准用法上下文。但程序员可以创建自己的、适用于非标准要求的实现。AbstractOwnableSynchronizer/AbstractQueuedSynchronizer/AbstractQueuedLongSynchronizerAbstractQueuedSynchronizer就是被称之为AQS的类，它是一个非常有用的超类，可用来定义锁以及依赖于排队阻塞线程的其他同步器；ReentrantLock，ReentrantReadWriteLock，CountDownLatch，CyclicBarrier和Semaphore等这些类都是基于AQS类实现的。AbstractQueuedLongSynchronizer 类提供相同的功能但扩展了对同步状态的 64 位的支持。两者都扩展了类 AbstractOwnableSynchronizer（一个帮助记录当前保持独占同步的线程的简单类）。LockSupportLockSupport提供“创建锁”和“其他同步类的基本线程阻塞原语”。LockSupport的功能和”Thread中的Thread.suspend()和Thread.resume()有点类似”，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。ConditionCondition需要和Lock联合使用，它的作用是代替Object监视器方法，可以通过await(),signal()来休眠/唤醒线程。Condition 接口描述了可能会与锁有关联的条件变量。这些变量在用法上与使用 Object.wait 访问的隐式监视器类似，但提供了更强大的功能。需要特别指出的是，单个 Lock 可能与多个 Condition 对象关联。为了避免兼容性问题，Condition 方法的名称与对应的 Object 版本中的不同。ReentrantLockReentrantLock是独占锁。所谓独占锁，是指只能被独自占领，即同一个时间点只能被一个线程锁获取到的锁。ReentrantLock锁包括”公平的ReentrantLock”和”非公平的ReentrantLock”。”公平的ReentrantLock”是指”不同线程获取锁的机制是公平的”，而”非公平的 ReentrantLock”则是指”不同线程获取锁的机制是非公平的”，ReentrantLock是”可重入的锁”。ReentrantLock的UML类图如下：ReentrantLock实现了Lock接口。ReentrantLock中有一个成员变量sync，sync是Sync类型；Sync是一个抽象类，而且它继承于AQS。ReentrantLock中有”公平锁类”FairSync和”非公平锁类”NonfairSync，它们都是Sync的子类。ReentrantReadWriteLock中sync对象，是FairSync与NonfairSync中的一种，这也意味着ReentrantLock是”公平锁”或”非公平锁”中的一种，ReentrantLock默认是非公平锁。ReentrantReadWriteLockReentrantReadWriteLock是读写锁接口ReadWriteLock的实现类，它包括子类ReadLock和WriteLock。ReentrantLock是共享锁，而WriteLock是独占锁。ReentrantReadWriteLock的UML类图如下：ReentrantReadWriteLock实现了ReadWriteLock接口。ReentrantReadWriteLock中包含sync对象，读锁readerLock和写锁writerLock。读锁ReadLock和写锁WriteLock都实现了Lock接口。和”ReentrantLock”一样，sync是Sync类型；而且，Sync也是一个继承于AQS的抽象类。Sync也包括”公平锁”FairSync和”非公平锁”NonfairSync。CountDownLatchCountDownLatch是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。CountDownLatch的UML类图如下：CountDownLatch包含了sync对象，sync是Sync类型。CountDownLatch的Sync是实例类，它继承于AQS。CyclicBarrierCyclicBarrier是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。CyclicBarrier的UML类图如下：CyclicBarrier是包含了”ReentrantLock对象lock”和”Condition对象trip”，它是通过独占锁实现的。CyclicBarrier和CountDownLatch的区别是：1. CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待。2. CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。SemaphoreSemaphore是一个计数信号量，它的本质是一个”共享锁”。信号量维护了一个信号量许可集。线程可以通过调用acquire()来获取信号量的许可；当信号量中有可用的许可时，线程能获取该许可；否则线程必须等待，直到有可用的许可为止。 线程可以通过release()来释放它所持有的信号量许可。Semaphore的UML类图如下：和”ReentrantLock”一样，Semaphore包含了sync对象，sync是Sync类型；而且，Sync也是一个继承于AQS的抽象类。Sync也包括”公平信号量”FairSync和”非公平信号量”NonfairSync。参考博文Java多线程系列目录(共43篇)","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/tags/多线程/"}]},{"title":"java多线程系列（六）——JUC并发集合","slug":"java多线程系列（六）——JUC并发集合","date":"2017-05-30T17:29:00.000Z","updated":"2018-11-05T17:30:24.014Z","comments":true,"path":"2017/05/31/java多线程系列（六）——JUC并发集合/","link":"","permalink":"http://www.fufan.me/2017/05/31/java多线程系列（六）——JUC并发集合/","excerpt":"","text":"说到并发集合，还是先回到java的集合包里来。Java集合包集合包主要包括两大类：CollectionListSetMapList的实现类主要有: LinkedList, ArrayList, Vector, Stack。LinkedList是双向链表实现的双端队列；它不是线程安全的，只适用于单线程。ArrayList是数组实现的队列，它是一个动态数组；它也不是线程安全的，只适用于单线程。Vector是数组实现的矢量队列，它也一个动态数组；不过和ArrayList不同的是，Vector是线程安全的，它支持并发。Stack是Vector实现的栈；和Vector一样，它也是线程安全的。Set的实现类主要有: HastSet和TreeSet。HashSet是一个没有重复元素的集合，它通过HashMap实现的；HashSet不是线程安全的，只适用于单线程。TreeSet也是一个没有重复元素的集合，不过和HashSet不同的是，TreeSet中的元素是有序的；它是通过TreeMap实现的；TreeSet也不是线程安全的，只适用于单线程。Map的实现类主要有: HashMap，WeakHashMap, Hashtable和TreeMap。HashMap是存储“键-值对”的哈希表；它不是线程安全的，只适用于单线程。WeakHashMap是也是哈希表；和HashMap不同的是，HashMap的“键”是强引用类型，而WeakHashMap的“键”是弱引用类型，也就是说当WeakHashMap 中的某个键不再正常使用时，会被从WeakHashMap中被自动移除。WeakHashMap也不是线程安全的，只适用于单线程。Hashtable也是哈希表；和HashMap不同的是，Hashtable是线程安全的，支持并发。TreeMap也是哈希表，不过TreeMap中的“键-值对”是有序的，它是通过R-B Tree(红黑树)实现的；TreeMap不是线程安全的，只适用于单线程。为了方便，我们将前面介绍集合类统称为”java集合包“。java集合包大多是“非线程安全的”，虽然可以通过Collections工具类中的方法获取java集合包对应的同步类，但是这些同步类的并发效率并不是很高。回顾完这些集合以后，我发现工作中其实多线程中使用到的集合印象深刻点的就是LinkedBlockingQueue，就是在线程池那里涉及到过，不过其实还有很多类似的变种，并发大师Doug Lea在JUC(java.util.concurrent)包中添加了java集合包中单线程类的对应的支持高并发的类。例如，ArrayList对应的高并发类是CopyOnWriteArrayList，HashMap对应的高并发类是ConcurrentHashMap，等等。JUC包在添加”java集合包“对应的高并发类时，为了保持API接口的一致性，使用了”Java集合包“中的框架。例如，CopyOnWriteArrayList实现了“Java集合包”中的List接口，HashMap继承了“java集合包”中的AbstractMap类，等等。得益于“JUC包使用了Java集合包中的类”，如果我们了解了Java集合包中的类的思想之后，理解JUC包中的类也相对容易；理解时，最大的难点是，对JUC包是如何添加对“高并发”的支持的！JUC中的集合类List和SetJUC集合包中的List和Set实现类包括: CopyOnWriteArrayList, CopyOnWriteArraySet和ConcurrentSkipListSet。ConcurrentSkipListSet稍后在说明Map时再说明，CopyOnWriteArrayList 和 CopyOnWriteArraySet的框架如下图所示：CopyOnWriteArrayList相当于线程安全的ArrayList，它实现了List接口。CopyOnWriteArrayList是支持高并发的。CopyOnWriteArraySet相当于线程安全的HashSet，它继承于AbstractSet类。CopyOnWriteArraySet内部包含一个CopyOnWriteArrayList对象，它是通过CopyOnWriteArrayList实现的。MapJUC集合包中Map的实现类包括: ConcurrentHashMap和ConcurrentSkipListMap。它们的框架如下图所示：ConcurrentHashMap是线程安全的哈希表(相当于线程安全的HashMap)；它继承于AbstractMap类，并且实现ConcurrentMap接口。ConcurrentHashMap是通过“锁分段”来实现的，它支持并发。ConcurrentSkipListMap是线程安全的有序的哈希表(相当于线程安全的TreeMap); 它继承于AbstractMap类，并且实现ConcurrentNavigableMap接口。ConcurrentSkipListMap是通过“跳表”来实现的，它支持并发。ConcurrentSkipListSet是线程安全的有序的集合(相当于线程安全的TreeSet)；它继承于AbstractSet，并实现了NavigableSet接口。ConcurrentSkipListSet是通过ConcurrentSkipListMap实现的，它也支持并发。QueueJUC集合包中Queue的实现类包括: ArrayBlockingQueue, LinkedBlockingQueue, LinkedBlockingDeque, ConcurrentLinkedQueue和ConcurrentLinkedDeque。它们的框架如下图所示：ArrayBlockingQueue是数组实现的线程安全的有界的阻塞队列。LinkedBlockingQueue是单向链表实现的(指定大小)阻塞队列，该队列按 FIFO（先进先出）排序元素。LinkedBlockingDeque是双向链表实现的(指定大小)双向并发阻塞队列，该阻塞队列同时支持FIFO和FILO两种操作方式。ConcurrentLinkedQueue是单向链表实现的无界队列，该队列按 FIFO（先进先出）排序元素。ConcurrentLinkedDeque是双向链表实现的无界队列，该队列同时支持FIFO和FILO两种操作方式参考博文Java多线程系列目录(共43篇)","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/tags/多线程/"}]},{"title":"java多线程系列（五）——JUC原子类","slug":"java多线程系列（五）——JUC原子类","date":"2017-05-25T17:09:00.000Z","updated":"2018-11-05T17:10:03.303Z","comments":true,"path":"2017/05/26/java多线程系列（五）——JUC原子类/","link":"","permalink":"http://www.fufan.me/2017/05/26/java多线程系列（五）——JUC原子类/","excerpt":"","text":"根据修改的数据类型，可以将JUC包中的原子操作类可以分为4类。基本类型: AtomicInteger, AtomicLong, AtomicBoolean ;数组类型: AtomicIntegerArray, AtomicLongArray, AtomicReferenceArray ;引用类型: AtomicReference, AtomicStampedRerence, AtomicMarkableReference ;对象的属性修改类型: AtomicIntegerFieldUpdater, AtomicLongFieldUpdater, AtomicReferenceFieldUpdater 。这些类存在的目的是对相应的数据进行原子操作。所谓原子操作，是指操作过程不会被中断，保证数据操作是以原子方式进行的。值得一提的是，Java的AtomXXX类并不是使用了锁的方式进行同步，而是采用了一种新的理念，叫做CAS.CAS是一组原语指令，用来实现多线程下的变量同步。在 x86 下的指令CMPXCHG实现了CAS，前置LOCK既可以达到原子性操作。由于CAS原语的直接操作与计算机底层的联系很大，CAS原语有三个参数，内存地址，期望值，新值。我们在Java中一般不去直接写CAS相关的代码，JDK为我们封装在AtomXXX中，因此，我们直接使用就可以了。基本类型用AtomicLong来举例主要函数AtomicLong是作用是对长整形进行原子操作。在32位操作系统中，64位的long 和 double 变量由于会被JVM当作两个分离的32位来进行操作，所以不具有原子性。而使用AtomicLong能让long的操作保持原子型。123456789101112131415161718192021222324252627282930313233343536// 构造函数AtomicLong()// 创建值为initialValue的AtomicLong对象AtomicLong(long initialValue)// 以原子方式设置当前值为newValue。final void set(long newValue) // 获取当前值final long get() // 以原子方式将当前值减 1，并返回减1后的值。等价于“--num”final long decrementAndGet() // 以原子方式将当前值减 1，并返回减1前的值。等价于“num--”final long getAndDecrement() // 以原子方式将当前值加 1，并返回加1后的值。等价于“++num”final long incrementAndGet() // 以原子方式将当前值加 1，并返回加1前的值。等价于“num++”final long getAndIncrement() // 以原子方式将delta与当前值相加，并返回相加后的值。final long addAndGet(long delta) // 以原子方式将delta添加到当前值，并返回相加前的值。final long getAndAdd(long delta) // 如果当前值 == expect，则以原子方式将该值设置为update。成功返回true，否则返回false，并且不修改原值。final boolean compareAndSet(long expect, long update)// 以原子方式设置当前值为newValue，并返回旧值。final long getAndSet(long newValue)// 返回当前值对应的int值int intValue() // 获取当前值对应的long值long longValue() // 以 float 形式返回当前值float floatValue() // 以 double 形式返回当前值double doubleValue() // 最后设置为给定值。延时设置变量值，这个等价于set()方法，但是由于字段是volatile类型的，因此次字段的修改会比普通字段（非volatile字段）有稍微的性能延时（尽管可以忽略），所以如果不是想立即读取设置的新值，允许在“后台”修改值，那么此方法就很有用。如果还是难以理解，这里就类似于启动一个后台线程如执行修改新值的任务，原线程就不等待修改结果立即返回（这种解释其实是不正确的，但是可以这么理解）。final void lazySet(long newValue)// 如果当前值 == 预期值，则以原子方式将该设置为给定的更新值。JSR规范中说：以原子方式读取和有条件地写入变量但不 创建任何 happen-before 排序，因此不提供与除 weakCompareAndSet 目标外任何变量以前或后续读取或写入操作有关的任何保证。大意就是说调用weakCompareAndSet时并不能保证不存在happen-before的发生（也就是可能存在指令重排序导致此操作失败）。但是从Java源码来看，其实此方法并没有实现JSR规范的要求，最后效果和compareAndSet是等效的，都调用了unsafe.compareAndSwapInt()完成操作。final boolean weakCompareAndSet(long expect, long update)源码分析AtomicLong的代码很简单，下面仅以incrementAndGet()为例，对AtomicLong的原理进行说明。incrementAndGet()源码如下：1234567891011public final long incrementAndGet() &#123; for (;;) &#123; // 获取AtomicLong当前对应的long值 long current = get(); // 将current加1 long next = current + 1; // 通过CAS函数，更新current的值 if (compareAndSet(current, next)) return next; &#125;&#125;说明：(01) incrementAndGet()首先会根据get()获取AtomicLong对应的long值。该值是volatile类型的变量，get()的源码如下：123456// value是AtomicLong对应的long值private volatile long value;// 返回AtomicLong对应的long值public final long get() &#123; return value;&#125;(02) incrementAndGet()接着将current加1,然后通过CAS函数，将新的值赋值给value。compareAndSet()的源码如下：123public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update);&#125;compareAndSet()的作用是更新AtomicLong对应的long值。它会比较AtomicLong的原始值是否与expect相等，若相等的话，则设置AtomicLong的值为update。数组类型AtomicLongArray函数列表123456789101112131415161718192021222324252627282930313233// 创建给定长度的新 AtomicLongArray。AtomicLongArray(int length)// 创建与给定数组具有相同长度的新 AtomicLongArray，并从给定数组复制其所有元素。AtomicLongArray(long[] array)// 以原子方式将给定值添加到索引 i 的元素。long addAndGet(int i, long delta)// 如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。boolean compareAndSet(int i, long expect, long update)// 以原子方式将索引 i 的元素减1。long decrementAndGet(int i)// 获取位置 i 的当前值。long get(int i)// 以原子方式将给定值与索引 i 的元素相加。long getAndAdd(int i, long delta)// 以原子方式将索引 i 的元素减 1。long getAndDecrement(int i)// 以原子方式将索引 i 的元素加 1。long getAndIncrement(int i)// 以原子方式将位置 i 的元素设置为给定值，并返回旧值。long getAndSet(int i, long newValue)// 以原子方式将索引 i 的元素加1。long incrementAndGet(int i)// 最终将位置 i 的元素设置为给定值。void lazySet(int i, long newValue)// 返回该数组的长度。int length()// 将位置 i 的元素设置为给定值。void set(int i, long newValue)// 返回数组当前值的字符串表示形式。String toString()// 如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。boolean weakCompareAndSet(int i, long expect, long update)源码分析同AtomicLong类似incrementAndGet()源码如下：123public final long incrementAndGet(int i) &#123; return addAndGet(i, 1);&#125;说明：incrementAndGet()的作用是以原子方式将long数组的索引 i 的元素加1，并返回加1之后的值。addAndGet()源码如下：12345678910111213public long addAndGet(int i, long delta) &#123; // 检查数组是否越界 long offset = checkedByteOffset(i); while (true) &#123; // 获取long型数组的索引 offset 的原始值 long current = getRaw(offset); // 修改long型值 long next = current + delta; // 通过CAS更新long型数组的索引 offset的值。 if (compareAndSetRaw(offset, current, next)) return next; &#125;&#125;getRaw()源码如下：123private long getRaw(long offset) &#123; return unsafe.getLongVolatile(array, offset);&#125;说明：unsafe是通过Unsafe.getUnsafe()返回的一个Unsafe对象。通过Unsafe的CAS函数对long型数组的元素进行原子操作。如compareAndSetRaw()就是调用Unsafe的CAS函数，它的源码如下：123private boolean compareAndSetRaw(long offset, long expect, long update) &#123; return unsafe.compareAndSwapLong(array, offset, expect, update);&#125;说明：addAndGet()首先检查数组是否越界。如果没有越界的话，则先获取数组索引i的值；然后通过CAS函数更新i的值。引用类型AtomicReference函数列表12345678910111213141516171819// 使用 null 初始值创建新的 AtomicReference。AtomicReference()// 使用给定的初始值创建新的 AtomicReference。AtomicReference(V initialValue)// 如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。boolean compareAndSet(V expect, V update)// 获取当前值。V get()// 以原子方式设置为给定值，并返回旧值。V getAndSet(V newValue)// 最终设置为给定值。void lazySet(V newValue)// 设置为给定值。void set(V newValue)// 返回当前值的字符串表示形式。String toString()// 如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。boolean weakCompareAndSet(V expect, V update)源码123456789101112131415161718192021222324252627282930// AtomicReferenceTest.java的源码import java.util.concurrent.atomic.AtomicReference;public class AtomicReferenceTest &#123; public static void main(String[] args)&#123; // 创建两个Person对象，它们的id分别是101和102。 Person p1 = new Person(101); Person p2 = new Person(102); // 新建AtomicReference对象，初始化它的值为p1对象 AtomicReference ar = new AtomicReference(p1); // 通过CAS设置ar。如果ar的值为p1的话，则将其设置为p2。 ar.compareAndSet(p1, p2); Person p3 = (Person)ar.get(); System.out.println(\"p3 is \"+p3); System.out.println(\"p3.equals(p1)=\"+p3.equals(p1)); &#125;&#125;class Person &#123; volatile long id; public Person(long id) &#123; this.id = id; &#125; public String toString() &#123; return \"id:\"+id; &#125;&#125;AtomicReference的源码比较简单。它是通过”volatile”和”Unsafe提供的CAS函数实现”原子操作。value是volatile类型。这保证了：当某线程修改value的值时，其他线程看到的value值都是最新的value值，即修改之后的volatile的值。通过CAS设置value。这保证了：当某线程池通过CAS函数(如compareAndSet函数)设置value时，它的操作是原子的，即线程在操作value时不会被中断。对象的属性修改类型AtomicIntegerFieldUpdater简单介绍一下同上面的几种类型一样，也是通过原子和CAS的方式来保证多线程使用变量同步不会出问题。AtomicLongFieldUpdater示例代码实例：12345678910111213141516171819202122232425262728293031// LongTest.java的源码import java.util.concurrent.atomic.AtomicLongFieldUpdater;public class LongFieldTest &#123; public static void main(String[] args) &#123; // 获取Person的class对象 Class cls = Person.class; // 新建AtomicLongFieldUpdater对象，传递参数是“class对象”和“long类型在类中对应的名称” AtomicLongFieldUpdater mAtoLong = AtomicLongFieldUpdater.newUpdater(cls, \"id\"); Person person = new Person(12345678L); // 比较person的\"id\"属性，如果id的值为12345678L，则设置为1000。 mAtoLong.compareAndSet(person, 12345678L, 1000); System.out.println(\"id=\"+person.getId()); &#125;&#125;class Person &#123; volatile long id; public Person(long id) &#123; this.id = id; &#125; public void setId(long id) &#123; this.id = id; &#125; public long getId() &#123; return id; &#125;&#125;运行结果：1id=1000参考博文Java多线程系列目录(共43篇)","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/tags/多线程/"}]},{"title":"java多线程系列（四）——CAS和AQS学习","slug":"java多线程系列（四）——CAS和AQS学习","date":"2017-05-20T12:16:00.000Z","updated":"2018-11-05T12:18:32.323Z","comments":true,"path":"2017/05/20/java多线程系列（四）——CAS和AQS学习/","link":"","permalink":"http://www.fufan.me/2017/05/20/java多线程系列（四）——CAS和AQS学习/","excerpt":"","text":"CASCAS的全称是Compare And Swap 即比较交换，其算法核心思想如下1执行函数：CAS(V,E,N)其包含3个参数V表示要更新的变量E表示预期值N表示新值如果V值等于E值，则将V的值设为N。若V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。通俗的理解就是CAS操作需要我们提供一个期望值，当期望值与当前线程的变量值相同时，说明还没线程修改该值，当前线程可以进行修改，也就是执行CAS操作，但如果期望值与当前线程不符，则说明该值已被其他线程修改，此时不执行更新操作，但可以选择重新读取该变量再尝试再次修改该变量，也可以放弃操作.由于CAS操作属于乐观派，它总认为自己可以成功完成操作，当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作，这点从图中也可以看出来。基于这样的原理，CAS操作即使没有锁，同样知道其他线程对共享资源操作影响，并执行相应的处理措施。同时从这点也可以看出，由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说无锁操作天生免疫死锁.鲜为人知的指针: Unsafe类Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，单从名称看来就可以知道该类是非安全的，毕竟Unsafe拥有着类似于C的指针操作，因此总是不应该首先使用Unsafe类，Java官方也不建议直接使用的Unsafe类，但我们还是很有必要了解该类，因为Java中CAS操作的执行依赖于Unsafe类的方法，注意Unsafe类中的所有方法都是native修饰的，也就是说Unsafe类中的方法都直接调用操作系统底层资源执行相应任务.CAS是一些CPU直接支持的指令，也就是我们前面分析的无锁操作，在Java中无锁操作CAS基于以下3个方法实现，在稍后讲解Atomic系列内部方法是基于下述方法的实现的。CAS的ABA问题及其解决方案假设这样一种场景，当第一个线程执行CAS(V,E,U)操作，在获取到当前变量V，准备修改为新值U前，另外两个线程已连续修改了两次变量V的值，使得该值又恢复为旧值，这样的话，我们就无法正确判断这个变量是否已被修改过这就是典型的CAS的ABA问题，一般情况这种情况发现的概率比较小，可能发生了也不会造成什么问题，比如说我们对某个做加减法，不关心数字的过程，那么发生ABA问题也没啥关系。但是在某些情况下还是需要防止的，那么该如何解决呢？在Java中解决ABA问题，我们可以使用以下两个原子类AtomicStampedReference类AtomicStampedReference原子类是一个带有时间戳的对象引用，在每次修改后，AtomicStampedReference不仅会设置新值而且还会记录更改的时间。当AtomicStampedReference设置对象值时，对象值以及时间戳都必须满足期望值才能写入成功，这也就解决了反复读写时，无法预知值是否已被修改的窘境同此类类似，还有AtomicMarkableReference类，这种方式并不能完全防止ABA问题的发生，只能减少ABA问题发生的概率。AtomicMarkableReference的实现原理与AtomicStampedReference类似，这里不再介绍。到此，我们也明白了如果要完全杜绝ABA问题的发生，我们应该使用AtomicStampedReference原子类更新对象，而对于AtomicMarkableReference来说只能减少ABA问题的发生概率，并不能杜绝。AQSCLH队列AQS内部维护着一个FIFO的队列，即CLH队列。AQS的同步机制就是依靠CLH队列实现的。CLH队列是FIFO的双端双向队列，实现公平锁。线程通过AQS获取锁失败，就会将线程封装成一个Node节点，插入队列尾。当有线程释放锁时，后尝试把队头的next节点占用锁。CLH队列结构NodeCLH队列由Node对象组成，Node是AQS中的内部类。 在CLH同步队列中，一个节点表示一个线程，它保存着线程的引用（thread）、状态（waitStatus）、前驱节点（prev）、后继节点（next） 入列addWaiter(Node.EXCLUSIVE)方法会将当前线程封装成Node节点，追加在队尾。1234567891011121314151617private Node addWaiter(Node mode) &#123; //新建Node Node node = new Node(Thread.currentThread(), mode); //快速尝试添加尾节点 Node pred = tail; if (pred != null) &#123; node.prev = pred; //CAS设置尾节点 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //多次尝试 enq(node); return node; &#125;addWaiter(Node node)先通过快速尝试设置尾节点，如果失败，则调用enq(Node node)方法设置尾节点123456789101112131415161718private Node enq(final Node node) &#123; //多次尝试，直到成功为止 for (;;) &#123; Node t = tail; //tail不存在，设置为首节点 if (t == null) &#123; if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; //设置为尾节点 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125;在上面代码中，两个方法都是通过一个CAS方法compareAndSetTail(Node expect, Node update)来设置尾节点，该方法可以确保节点是线程安全添加的。在enq(Node node)方法中，AQS通过“死循环”的方式来保证节点可以正确添加，只有成功添加后，当前线程才会从该方法返回，否则会一直执行下去。过程图如下：出列CLH同步队列遵循FIFO，首节点的线程释放同步状态后，将会唤醒它的后继节点（next），而后继节点将会在获取同步状态成功时将自己设置为首节点，这个过程非常简单，head执行该节点并断开原首节点的next和当前节点的prev即可，注意在这个过程是不需要使用CAS来保证的，因为只有一个线程能够成功获取到同步状态。过程图如下：Jdk的并发包提供了各种锁及同步机制，其实现的核心类是AbstractQueuedSynchronizer，我们简称为AQS框架，它为不同场景提供了实现锁及同步机制的基本框架，为同步状态的原子性管理、线程的阻塞、线程的解除阻塞及排队管理提供了一种通用的机制。Jdk的并发包（juc）的作者是Doug Lea，但其中思想却是结合了多位大师的智慧，如果你想深入理解juc的相关理论可以参考Doug Lea写的《The_java.util.concurrent_Synchronizer_Framework》论文。从这里可以找到AQS的理论基础，包括框架的基本原理、需求、设计、实现思路、用法及性能，由于这些方面篇幅较大，本文不打算涉及所有方面，主要将针对AQS类的结构及相关操作进行分析。AQS框架它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）状态维护AQS用的是一个32位的整型来表示同步状态的，它是用volatile修饰的：1private volatile int state;在互斥锁中它表示着线程是否已经获取了锁，0未获取，1已经获取了，大于1表示重入数。同时AQS提供了getState()、setState()、compareAndSetState()方法来获取和修改该值：可重入锁指的是在一个线程中可以多次获取同一把锁，比如：一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法，而无需重新获得锁。synchronized也可以看做重入锁所以可重入数大于1表示该线程可能调用了多个需要当前锁的方法，或同一个线程调用了多次lock()方法。队列AQS内部维护着一个FIFO的CLH队列，所以AQS并不支持基于优先级的同步策略。至于为何要选择CLH队列，主要在于CLH锁相对于MSC锁，他更加容易处理cancel和timeout，同时他具备进出队列快、无所、畅通无阻、检查是否有线程在等待也非常容易（head != tail,头尾指针不同）。当然相对于原始的CLH队列锁，AQS采用的是一种变种的CLH队列锁：原始CLH使用的locked自旋，而AQS的CLH则是在每个node里面使用一个状态字段来控制阻塞，而不是自旋。为了可以处理timeout和cancel操作，每个node维护一个指向前驱的指针。如果一个node的前驱被cancel，这个node可以前向移动使用前驱的状态字段。head结点使用的是傀儡结点。AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch），即我们常说的” 独占锁” 和 “共享锁”。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法：isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)：共享方式。尝试释放资源，成功则返回true，失败则返回false。以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock，他是一个读写锁。参考博文【死磕Java并发】—–J.U.C之AQS：CLH同步队列Java并发之AQS详解JAVA中的CAS","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/tags/多线程/"}]},{"title":"Mysql深入学习系列（一）——MyISAM与InnoDB比较","slug":"MyISAM与InnoDB比较（一）","date":"2017-05-15T09:39:00.000Z","updated":"2018-11-05T14:58:09.870Z","comments":true,"path":"2017/05/15/MyISAM与InnoDB比较（一）/","link":"","permalink":"http://www.fufan.me/2017/05/15/MyISAM与InnoDB比较（一）/","excerpt":"","text":"MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。不过，在这几年的发展下，MySQL也导入了InnoDB（另一种数据库引擎），以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。InnoDB，是MySQL的数据库引擎之一，为MySQL AB发布binary的标准之一。InnoDB由Innobase Oy公司所开发，2006年五月时由甲骨文公司并购。与传统的ISAM与MyISAM相比，InnoDB的最大特色就是支持了ACID兼容的事务（Transaction）功能，类似于PostgreSQL。目前InnoDB采用双轨制授权，一是GPL授权，另一是专有软件授权。MyISAM与InnoDB的区别是什么？MyISAM构成上的区别：每个MyISAM在磁盘上存储成三个文件。第一个 文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩 展名为.MYD (MYData)。索引文件的扩 展名是.MYI (MYIndex)。基于磁盘的资源是InnoDB表空间数据文件和它的日志文件，InnoDB 表的 大小只受限于操作系统文件的大小，一般为 2GB事务处理上方面:MyISAM类型的表强调的是性能，其执行数 度比InnoDB类型更快，但是不提供事务支持InnoDB提供事务支持事务，外部键等高级 数据库功能SELECTUPDATEINSERTDelete如果执行大量的SELECT，MyISAM是更好的选择1.如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表2.DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的 删除。3.LOAD TABLE FROM MASTER操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性（例如外键）的表不适用对AUTO_INCREMENT的 操作每表一个AUTO_INCREMEN列的内部处理。MyISAM为INSERT和UPDATE操 作自动更新这一列。这使得AUTO_INCREMENT列更快（至少10%）。在序列顶的值被删除之后就不 能再利用。(当AUTO_INCREMENT列被定义为多列索引的最后一列， 可以出现重使用从序列顶部删除的值的情况）。AUTO_INCREMENT值可用ALTER TABLE或myisamch来重置对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但 是在MyISAM表中，可以和其他字段一起建立联 合索引更好和更快的auto_increment处理如果你为一个表指定AUTO_INCREMENT列，在数据词典里的InnoDB表句柄包含一个名为自动增长计数 器的计数器，它被用在为该列赋新值。自动增长计数 器仅被存储在主内存中，而不是存在磁盘上表的具体行数select count() from table,MyISAM只要简单的读出保存好的行数，注意的是，当count()语句包含 where条件时，两种表的操作是一样的InnoDB 中不 保存表的具体行数，也就是说，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行锁表锁提供行锁(locking on row level)，提供与 Oracle 类型一致的不加锁读取(non-locking read in SELECTs)，另外，InnoDB表的行锁也不是绝对的，如果在执 行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表，例如update table set num=1 where name like “%aaa%”存储结构MyISAM：每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。InnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。存储空间MyISAM：可被压缩，存储空间较小。支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。InnoDB：需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。可移植性、备份及恢复MyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。InnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。事务支持MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。AUTO_INCREMENTMyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。InnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。表锁差异MyISAM：只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。InnoDB：支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。全文索引MyISAM：支持 FULLTEXT类型的全文索引InnoDB：不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。表主键MyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。InnoDB：如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。表的具体行数MyISAM：保存有表的总行数，如果select count() from table;会直接取出出该值。InnoDB：没有保存表的总行数，如果使用select count() from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。CURD操作MyISAM：如果执行大量的SELECT，MyISAM是更好的选择。InnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。外键MyISAM：不支持InnoDB：支持通过上述的分析，基本上可以考虑使用InnoDB来替代MyISAM引擎了，原因是InnoDB自身很多良好的特点，比如事务支持、存储 过程、视图、行级锁定等等，在并发很多的情况下，相信InnoDB的表现肯定要比MyISAM强很多。另外，任何一种表都不是万能的，只用恰当的针对业务类型来选择合适的表类型，才能最大的发挥MySQL的性能优势。如果不是很复杂的Web应用，非关键应用，还是可以继续考虑MyISAM的，这个具体情况可以自己斟酌。总结MyISAM：每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。MyISAM表格可以被压缩，而且它们支持全文搜索。不支持事务，而且也不支持外键。如果事物回滚将造成不完全回滚，不具有原子性。在进行updata时进行表锁，并发量相对较小。如果执行大量的SELECT，MyISAM是更好的选择。MyISAM的索引和数据是分开的，并且索引是有压缩的，内存使用率就对应提高了不少。能加载更多索引，而Innodb是索引和数据是紧密捆绑的，没有使用压缩从而会造成Innodb比MyISAM体积庞大不小MyISAM缓存在内存的是索引，不是数据。而InnoDB缓存在内存的是数据，相对来说，服务器内存越大，InnoDB发挥的优势越大。优点：查询数据相对较快，适合大量的select，可以全文索引。缺点：不支持事务，不支持外键，并发量较小，不适合大量updateInnoDB这种类型是事务安全的。.它与BDB类型具有相同的特性,它们还支持外键。InnoDB表格速度很快。具有比BDB还丰富的特性,因此如果需要一个事务安全的存储引擎，建议使用它。在update时表进行行锁，并发量相对较大。如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。优点：支持事务，支持外键，并发量较大，适合大量update缺点：查询数据相对较快，不适合大量的select对于支持事物的InnoDB类型的表，影响速度的主要原因是AUTOCOMMIT默认设置是打开的，而且程序没有显式调用BEGIN 开始事务，导致每插入一条都自动Commit，严重影响了速度。可以在执行sql前调用begin，多条sql形成一个事物（即使autocommit打开也可以），将大大提高性能。基本的差别为：MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持。MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持已经外部键等高级数据库功能。参考博文MySQL存储引擎中的MyISAM和InnoDB区别详解MySQL存储引擎之Myisam和Innodb总结性梳理","categories":[{"name":"mysql","slug":"mysql","permalink":"http://www.fufan.me/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://www.fufan.me/tags/mysql/"}]},{"title":"分布式一致性——从CAP到BASE","slug":"分布式一致性——从CAP到BASE","date":"2017-05-11T07:24:00.000Z","updated":"2018-11-05T07:25:25.467Z","comments":true,"path":"2017/05/11/分布式一致性——从CAP到BASE/","link":"","permalink":"http://www.fufan.me/2017/05/11/分布式一致性——从CAP到BASE/","excerpt":"","text":"问题的提出火车站售票假如说我们的终端用户是一位经常坐火车的旅行家，通常他是去车站的售票处购买车 票，然后拿着车票去检票口，再坐上火车，开始一段美好的旅行—-一切似乎都是那么和谐。想象一下，如果他选择的目的地是杭州，而某一趟开往杭州的火车 只剩下最后一张车票，可能在同一时刻，不同售票窗口的另一位乘客也购买了同一张车票。假如说售票系统没有进行一致性的保障，两人都购票成功了。而在检票口 检票的时候，其中一位乘客会被告知他的车票无效—-当然，现代的中国铁路售票系统已经很少出现这样的问题了。但在这个例子中我们可以看出，终端用户对 于系统的需求非常简单：“请售票给我，如果没有余票了，请在售票的时候就告诉我票是无效的”这就对购票系统提出了严格的一致性要求—-系统的数据（本例中指的就是那趟开往杭州的火车的余票数）无论在哪个售票窗口，每时每刻都必须是准确无误的！银行转账假如我们的终端用户是一位刚毕业的大学生，通常在拿到第一个月工资的时候，都会选 择向家里汇款。当他来到银行柜台，完成转账操作后，银行的柜台服务员会友善地提醒他：”您的转账将在N个工作日后到账！”。此时这名毕业生有一定的沮丧， 会对那名柜台服务员叮嘱：”好吧，多久没关系，钱不要少就好了！”—-这也成为了几乎所有用户对于现代银行系统最基本的需求网上购物假如说我们的终端用户是一位网购达人，当他看见一件库存量为5的心仪商品，会迅速地确认购买，写下收货地址，然后下单—-然而，在下单的那个瞬间，系统可能会告知该用户：”库存量不足！”。此时绝大部分消费者都会抱怨自己动作太慢，使得心爱的商品被其他人抢走了。但其实有过网购系统开发经验的工程师一定明白，在商品详情页上显示的那个库存量，通常不是该商品的真实库存量，只有在真正下单购买的时候，系统才会检查该商品的真实库存量。但是，谁在意呢？问题的解读对于上面三个例子，相信大家一定看出来了，我们的终端用户在使用不同的计算机产品时对于数据一致性的需求是不一样的：1、有些系统，既要快速地响应用户，同时还要保证系统的数据对于任意客户端都是真实可靠的，就像火车站售票系统2、有些系统，需要为用户保证绝对可靠的数据安全，虽然在数据一致性上存在延时，但最终务必保证严格的一致性，就像银行的转账系统3、有些系统，虽然向用户展示了一些可以说是”错误”的数据，但是在整个系统使用过程中，一定会在某一个流程上对系统数据进行准确无误的检查，从而避免用户发生不必要的损失，就像网购系统分布式一致性在分布式系统中要解决的一个重要问题就是数据的复制。在我们的日常开发经验中，相 信很多开发人员都遇到过这样的问题：假设客户端C1将系统中的一个值K由V1更新为V2，但客户端C2无法立即读取到K的最新值，需要在一段时间之后才能 读取到。这很正常，因为数据库复制之间存在延时。分布式系统对于数据的复制需求一般都来自于以下两个原因：1、为了增加系统的可用性，以防止单点故障引起的系统不可用2、提高系统的整体性能，通过负载均衡技术，能够让分布在不同地方的数据副本都能够为用户提供服务数据复制在可用性和性能方面给分布式系统带来的巨大好处是不言而喻的，然而数据复制所带来的一致性挑战，也是每一个系统研发人员不得不面对的。所谓分布一致性问题，是指在分布式环境中引入数据复制机制之后，不同数据节点之间 可能出现的，并无法依靠计算机应用程序自身解决的数据不一致的情况。简单讲，数据一致性就是指在对一个副本数据进行更新的时候，必须确保也能够更新其他的 副本，否则不同副本之间的数据将不一致。那么如何解决这个问题？一种思路是”既然是由于延时动作引起的问题，那我可以将写入的动作阻塞，直到数据复制完成后，才完成写入动作”。 没错，这似乎能解决问题，而且有一些系统的架构也确实直接使用了这个思路。但这个思路在解决一致性问题的同时，又带来了新的问题：写入的性能。如果你的应 用场景有非常多的写请求，那么使用这个思路之后，后续的写请求都将会阻塞在前一个请求的写操作上，导致系统整体性能急剧下降。总得来说，我们无法找到一种能够满足分布式系统所有系统属性的分布式一致性解决方案。因此，如何既保证数据的一致性，同时又不影响系统运行的性能，是每一个分布式系统都需要重点考虑和权衡的。于是，一致性级别由此诞生：强一致性这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大弱一致性这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不久承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态最终一致性最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型分布式环境的各种问题分布式系统体系结构从其出现之初就伴随着诸多的难题和挑战：通信异常从集中式向分布式演变的过程中，必然引入网络因素，由于网络本身的不可靠性，因此 也引入了额外的问题。分布式系统需要在各个节点之间进行网络通信，因此每次网络通信都会伴随着网络不可用的风险，网络光纤、路由器或是DNS等硬件设备或 是系统不可用都会导致最终分布式系统无法顺利完成一次网络通信。另外，即使分布式系统各个节点之间的网络通信能够正常进行，其延时也会大于单机操作。通常 我们认为现代计算机体系结构中，单机内存访问的延时在纳秒数量级（通常是10ns），而正常的一次网络通信的延迟在0.1~1ms左右（相当于内存访问延 时的105倍），如此巨大的延时差别，也会影响到消息的收发过程，因此消息丢失和消息延迟变得非常普遍网络分区当网络由于发生异常情况，导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式系统的所有节点中，只有部分节点之间能够正常通信，而另一些节点则不能—-我们将这个现象称为网络分区。当网络分区出现时，分布式系统会出现局部小集群，在极端情况下，这些局部小集群会独立完成原本需要整个分布式系统才能完成的功能，包括对数据的事物处理，这就对分布式一致性提出了非常大的挑战三态上面两点，我们已经了解到在分布式环境下，网络可能会出现各式各样的问题，因此分布式系统的每一次请求与响应，存在特有的三态概念，即成功、失败、超时。 在传统的单机系统中，应用程序在调用一个函数之后，能够得到一个非常明确的响应：成功或失败。而在分布式系统中，由于网络是不可靠的，虽然在绝大部分情况 下，网络通信也能够接受到成功或失败的响应，当时当网络出现异常的情况下，就可能会出现超时现象，通常有以下两种情况：（1）由于网络原因，该请求并没有被成功地发送到接收方，而是在发送过程中就发生了消息丢失现象（2）该请求成功地被接收方接收后，进行了处理，但是在将响应反馈给发送方的过程中，发生了消息丢失现象当出现这样的超时现象时，网络通信的发起方是无法确定当前请求是否被成功处理的节点故障节点故障则是分布式环境下另一个比较常见的问题，指的是组成分布式系统的服务器节点出现的宕机或”僵死”现象，通常根据经验来说，每个节点都有可能出现故障，并且每天都在发生分布式事物随着分布式计算的发展，事物在分布式计算领域也得到了广泛的应用。在单机数据库中，我们很容易能够实现一套满足ACID特性的事物处理系统，但在分布式数据库中，数据分散在各台不同的机器上，如何对这些数据进行分布式的事物处理具有非常大的挑战。分布式事物是指事物的参与者、支持事物的服务器、资源服务器以及事物管理器分别位于分布式系统的不同节点上，通常一个分布式事物中会涉及对多个数据源或业务系统的操作。可以设想一个最典型的分布式事物场景：一个跨银行的转账操作涉及调用两个异地的银 行服务，其中一个是本地银行提供的取款服务，另一个则是目标银行提供的存款服务，这两个服务本身是无状态并且相互独立的，共同构成了一个完整的分布式事 物。如果从本地银行取款成功，但是因为某种原因存款服务失败了，那么就必须回滚到取款之前的状态，否则用户可能会发现自己的钱不翼而飞了。从这个例子可以看到，一个分布式事务可以看做是多个分布式的操作序列组成的，例如 上面例子的取款服务和存款服务，通常可以把这一系列分布式的操作序列称为子事物。因此，分布式事务也可以被定义为一种嵌套型的事物，同时也就具有了 ACID事物特性。但由于在分布式事务中，各个子事物的执行是分布式的，因此要实现一种能够保证ACID特性的分布式事物处理系统就显得格外复杂。CAP理论一个经典的分布式系统理论。CAP理论告诉我们：一个分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中两项。1、一致性在分布式环境下，一致性是指数据在多个副本之间能否保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一直的状态。对于一个将数据副本分布在不同分布式节点上的系统来说，如果对第一个节点的数据进 行了更新操作并且更新成功后，却没有使得第二个节点上的数据得到相应的更新，于是在对第二个节点的数据进行读取操作时，获取的依然是老数据（或称为脏数 据），这就是典型的分布式数据不一致的情况。在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都可以读取到其最新的值，那么 这样的系统就被认为具有强一致性2、可用性可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。这里的重点是”有限时间内”和”返回结果”。“有限时间内”是指，对于用户的一个操作请求，系统必须能够在指定的时间内返回对 应的处理结果，如果超过了这个时间范围，那么系统就被认为是不可用的。另外，”有限的时间内”是指系统设计之初就设计好的运行指标，通常不同系统之间有很 大的不同，无论如何，对于用户请求，系统必须存在一个合理的响应时间，否则用户便会对系统感到失望。“返回结果”是可用性的另一个非常重要的指标，它要求系统在完成对用户请求的处理后，返回一个正常的响应结果。正常的响应结果通常能够明确地反映出队请求的处理结果，即成功或失败，而不是一个让用户感到困惑的返回结果。3、分区容错性分区容错性约束了一个分布式系统具有如下特性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。网络分区是指在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络） 中，由于一些特殊的原因导致这些子网络出现网络不连通的状况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域。 需要注意的是，组成一个分布式系统的每个节点的加入与退出都可以看作是一个特殊的网络分区。既然一个分布式系统无法同时满足一致性、可用性、分区容错性三个特点，所以我们就需要抛弃一样：选 择说 明CA放弃分区容错性，加强一致性和可用性，其实就是传统的单机数据库的选择AP放弃一致性（这里说的一致性是强一致性），追求分区容错性和可用性，这是很多分布式系统设计时的选择，例如很多NoSQL系统就是如此CP放弃可用性，追求一致性和分区容错性，基本不会选择，网络问题会直接让整个系统不可用需要明确的一点是，对于一个分布式系统而言，分区容错性是一个最基本的要求。因为 既然是一个分布式系统，那么分布式系统中的组件必然需要被部署到不同的节点，否则也就无所谓分布式系统了，因此必然出现子网络。而对于分布式系统而言，网 络问题又是一个必定会出现的异常情况，因此分区容错性也就成为了一个分布式系统必然需要面对和解决的问题。因此系统架构师往往需要把精力花在如何根据业务 特点在C（一致性）和A（可用性）之间寻求平衡。BASE理论BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的缩写。BASE理论是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结， 是基于CAP定理逐步演化而来的。BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。接下来看一下BASE中的三要素：基本可用基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性—-注意，这绝不等价于系统不可用。比如：（1）响应时间上的损失。正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒（2）系统功能上的损失：正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面软状态软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时最终一致性最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统的事物ACID特性是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性和BASE理论往往又会结合在一起。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.fufan.me/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.fufan.me/tags/分布式/"}]},{"title":"消息队列和rpc的比较","slug":"消息队列和rpc的比较","date":"2017-05-10T06:46:00.000Z","updated":"2018-11-05T06:54:35.357Z","comments":true,"path":"2017/05/10/消息队列和rpc的比较/","link":"","permalink":"http://www.fufan.me/2017/05/10/消息队列和rpc的比较/","excerpt":"","text":"消息队列和RPC远程服务调用是微服务目前使用最多的处理任务和调用服务的两种方式，然而什么场景下适合用哪个是非常关键的。消息队列概述消息队列中间件是分布式系统中重要的组件，主要解决应用解耦，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ，当然也可以用有些缓存中间件来模拟消息队列，如redis。应用场景1. 异步处理场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种 1.串行的方式；2.并行方式a、串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。b、并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。2. 应用解耦场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图：传统模式的缺点：假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，订单系统与库存系统耦合如何解决以上问题呢？引入应用消息队列后的方案，如下图：订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦3. 流量削锋流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。a、可以控制活动的人数b、可以缓解短时间内高流量压垮应用用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。秒杀业务根据消息队列中的请求信息，再做后续处理4. 日志处理日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下日志采集客户端，负责日志数据采集，定时写受写入Kafka队列Kafka消息队列，负责日志数据的接收，存储和转发日志处理应用：订阅并消费kafka队列中的日志数据5. 消息通讯消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等点对点通讯：客户端A和客户端B使用同一队列，进行消息通讯。聊天室通讯：客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。以上实际是消息队列的两种消息模式，点对点或发布订阅模式。模型为示意图，供参考。中间件项目架构实例电商系统消息队列采用高可用，可持久化的消息中间件。比如Active MQ，Rabbit MQ，Rocket Mq。（1）应用将主干逻辑处理完成后，写入消息队列。消息发送是否成功可以开启消息的确认模式。（消息队列返回消息接收成功状态后，应用再返回，这样保障消息的完整性）（2）扩展流程（发短信，配送处理）订阅队列消息。采用推或拉的方式获取消息并处理。（3）消息将应用解耦的同时，带来了数据一致性问题，可以采用最终一致性方式解决。比如主数据写入数据库，扩展应用根据消息队列，并结合数据库方式实现基于消息队列的后续处理。日志收集系统分为Zookeeper注册中心，日志收集客户端，Kafka集群和Storm集群（OtherApp）四部分组成。Zookeeper注册中心，提出负载均衡和地址查找服务日志收集客户端，用于采集应用系统的日志，并将数据推送到kafka队列Kafka集群：接收，路由，存储，转发等消息处理Storm集群：与OtherApp处于同一级别，采用拉的方式消费队列中的数据消息模型讲消息队列就不得不提JMS 。JMS（Java Message Service,Java消息服务）API是一个消息服务的标准/规范，允许应用程序组件基于JavaEE平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。在JMS标准中，有两种消息模型P2P（Point to Point）,Publish/Subscribe(Pub/Sub)。p2p模式P2P模式包含三个角色：消息队列（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。P2P的特点每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列接收者在成功接收消息之后需向队列应答成功如果希望发送的每个消息都会被成功处理的话，那么需要P2P模式。Pub/sub模式包含三个角色主题（Topic），发布者（Publisher），订阅者（Subscriber） 多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。Pub/Sub的特点每个消息可以有多个消费者发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息为了消费消息，订阅者必须保持运行的状态为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型。常用消息队列一般商用的容器，比如WebLogic，JBoss，都支持JMS标准，开发上很方便。但免费的比如Tomcat，Jetty等则需要使用第三方的消息中间件。本部分内容介绍常用的消息中间件（Active MQ,Rabbit MQ，Zero MQ,Kafka）以及他们的特点。ActiveMqActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。ActiveMQ特性如下：⒈ 多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP⒉ 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)⒊ 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性⒋ 通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上⒌ 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA⒍ 支持通过JDBC和journal提供高速的消息持久化⒎ 从设计上保证了高性能的集群，客户端-服务器，点对点⒏ 支持Ajax⒐ 支持与Axis的整合⒑ 可以很容易得调用内嵌JMS provider，进行测试KafkaKafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群机来提供实时的消费。Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。（文件追加的方式写入数据，过期的数据定期删除）高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息支持通过Kafka服务器和消费机集群来分区消息支持Hadoop并行数据加载Kafka相关概念BrokerKafka集群包含一个或多个服务器，这种服务器被称为broker[5]Topic每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）PartitionParition是物理上的概念，每个Topic包含一个或多个Partition.Producer负责发布消息到Kafka brokerConsumer消息消费者，向Kafka broker读取消息的客户端。Consumer Group每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用。RPC远程调用一. 区别1. 消息队列能够积压消息,让消费者可以按照自己的节奏处理消息,但是RPC不能.2. 消息队列是一个异步的过程(生产者发送消息之后,不会等待消息的处理),RPC是一个同步的过程.3. 消息队列的生产者不能得知谁消费了消息,消费结果是否成功,而RPC的调用者明确知道被调用者是谁,处理结果也能获取到.4. 由于消息队列在生产者和消费者之间还有一个queue节点,系统性能除了受自身因素影响外还受queue节点影响,而RPC没有中间节点,,系统性能只受自己的影响.二. 适用场景由异同大致就能理解出两者的适用场景是什么:1. 消息队列能够让服务器的负载不会过高,降低了并发度,所以效率受到了影响,又由于消息队列是一个异步的过程,且生产者不能得知消费者的信息,所以消息队列一般用于实时性要求不高的花费时间的操作.2. RPC是一个同步的过程,可能会因为突然高的并发量导致系统出问题,但是RPC具有很高的实时性,所以他一般用户需要立即返回结果的操作.参考博文关于消息队列的使用","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.fufan.me/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.fufan.me/tags/消息队列/"}]},{"title":"java多线程系列（三）——锁","slug":"java多线程系列（三）——锁","date":"2017-05-04T17:58:00.000Z","updated":"2018-11-04T18:00:43.820Z","comments":true,"path":"2017/05/05/java多线程系列（三）——锁/","link":"","permalink":"http://www.fufan.me/2017/05/05/java多线程系列（三）——锁/","excerpt":"","text":"这里整理了Java中的各种锁：公平锁、非公平锁、自旋锁、可重入锁、偏向锁、轻量级锁、重量级锁、读写锁、互斥锁等待。公平锁和非公平锁公平锁是指多个线程在等待同一个锁时，必须按照申请锁的先后顺序来一次获得锁。公平锁的好处是等待锁的线程不会饿死，但是整体效率相对低一些；非公平锁的好处是整体效率相对高一些，但是有些线程可能会饿死或者说很早就在等待锁，但要等很久才会获得锁。其中的原因是公平锁是严格按照请求所的顺序来排队获得锁的，而非公平锁时可以抢占的，即如果在某个时刻有线程需要获取锁，而这个时候刚好锁可用，那么这个线程会直接抢占，而这时阻塞在等待队列的线程则不会被唤醒。new ReentrantLock(true)，用参数来觉得是否为公平锁。自旋锁Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此状态装换需要耗费很多的处理器时间，对于代码简单的同步块（如被synchronized修饰的getter()和setter()方法），状态转换消耗的时间有可能比用户代码执行的时间还要长。自旋等待不能代替阻塞。自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋当代的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会拜拜浪费处理器资源。因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK6中已经变为默认开启，并且引入了自适应的自旋锁。自适应意味着自旋的时间不在固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。自旋是在轻量级锁中使用的，在重量级锁中，线程不使用自旋。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100次循环。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。可重入锁可重入锁，也叫做递归锁，指的是同一线程外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。在JAVA环境下 ReentrantLock 和synchronized 都是可重入锁。可重入锁最大的作用是避免死锁。类锁和对象锁类锁：作用在类上的，两种表现形式，一是静态方法被synchronized修饰，二是通过锁住类名.class的代码块方式1234public static synchronized void method1()&#123;&#125;public void method2()&#123; synchronized(LockStrategy.class)&#123;&#125; &#125;对象锁：普通方法被synchronized修饰，二是通过锁住object的代码块方式12345678910public synchronized void method4()&#123;&#125;public void method5()&#123; synchronized(this)&#123;&#125;&#125;public void method6()&#123; synchronized(object1)&#123;&#125;&#125;偏向锁、轻量级锁、重量级锁synchronized的偏向锁、轻量级锁以及重量级锁是通过Java对象头实现的。博主在Java对象大小内幕浅析中提到了Java对象的内存布局分为：对象头、实例数据和对其填充，而对象头又可以分为”Mark Word”和类型指针klass。”Mark Word”是关键，默认情况下，其存储对象的HashCode、分代年龄和锁标记位。偏向锁是JDK6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。偏向锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要同步。大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当锁对象第一次被线程获取的时候，线程使用CAS操作把这个锁的线程ID记录再对象Mark Word之中，同时置偏向标志位1。以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需要简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果线程使用CAS操作时失败则表示该锁对象上存在竞争并且这个时候另外一个线程获得偏向锁的所有权。当到达全局安全点（safepoint，这个时间点上没有正在执行的字节码）时获得偏向锁的线程被挂起，膨胀为轻量级锁（涉及Monitor Record，Lock Record相关操作，这里不展开），同时被撤销偏向锁的线程继续往下执行同步代码。当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。线程在执行同步块之前，JVM会先在当前线程的栈帧中创建用于存储锁记录(Lock Record)的空间，并将对象头中的Mard Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。如果自旋失败则锁会膨胀成重量级锁。如果自旋成功则依然处于轻量级锁的状态。轻量级锁的解锁过程也是通过CAS操作来进行的，如果对象的Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中赋值的Displaced Mark Word替换回来，如果替换成功，整个同步过程就完成了，如果替换失败，就说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程。轻量级锁提升程序同步性能的依据是：对于绝大部分的锁，在整个同步周期内都是不存在竞争的（区别于偏向锁）。这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁比传统的重量级锁更慢。整个synchronized锁流程如下：检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。如果自旋成功则依然处于轻量级状态。如果自旋失败，则升级为重量级锁。悲观锁和乐观锁悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。乐观锁：假定不会发生并发冲突，只在提交操作时检测是否违反数据完整性。（使用版本号或者时间戳来配合实现）共享锁和排它锁共享锁：如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排它锁。获准共享锁的事务只能读数据，不能修改数据。排它锁：如果事务T对数据A加上排它锁后，则其他事务不能再对A加任何类型的锁。获得排它锁的事务即能读数据又能修改数据。读写锁读写锁是一个资源能够被多个读线程访问，或者被一个写线程访问但不能同时存在读线程。Java当中的读写锁通过ReentrantReadWriteLock实现。具体使用方法这里不展开。互斥锁所谓互斥锁就是指一次最多只能有一个线程持有的锁。在JDK中synchronized和JUC的Lock就是互斥锁。无锁要保证现场安全，并不是一定就要进行同步，两者没有因果关系。同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的。无状态编程。无状态代码有一些共同的特征：不依赖于存储在对上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非无状态的方法等。可以参考Servlet。线程本地存储。可以参考ThreadLocalvolatileCAS协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/tags/多线程/"}]},{"title":"java多线程系列（二）——关键字和方法","slug":"java多线程系列（二）——关键字和方法","date":"2017-05-01T13:47:00.000Z","updated":"2018-11-04T14:45:32.414Z","comments":true,"path":"2017/05/01/java多线程系列（二）——关键字和方法/","link":"","permalink":"http://www.fufan.me/2017/05/01/java多线程系列（二）——关键字和方法/","excerpt":"","text":"关键字synchronized用途synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。使用方式修饰实例方法，作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 。也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份，所以对该类的所有对象都加了锁）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 和 synchronized 方法一样，synchronized(this)代码块也是锁定当前对象的。synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。这里再提一下：synchronized关键字加到非 static 静态方法上是给对象实例上锁。另外需要注意的是：尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓冲功能！如写一个单例类的实现：123456789101112131415161718192021public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) &#123; //类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125;uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：为 uniqueInstance 分配内存空间初始化 uniqueInstance将 uniqueInstance 指向分配的内存地址但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出先问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。synchronized和ReenTrantLock 的区别两者都是可重入锁synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 APIReenTrantLock 比 synchronized 增加了一些高级功能ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。性能已不是选择标准volatile内存可见性所谓可见性，是指当一条线程修改了共享变量的值，新值对于其他线程来说是可以立即得知的。很显然，上述的例子中是没有办法做到内存可见性的。java虚拟机有自己的内存模型（Java Memory Model，JMM），JMM可以屏蔽掉各种硬件和操作系统的内存访问差异，以实现让java程序在各种平台下都能达到一致的内存访问效果。JMM决定一个线程对共享变量的写入何时对另一个线程可见，JMM定义了线程和主内存之间的抽象关系：共享变量存储在主内存(Main Memory)中，每个线程都有一个私有的本地内存（Local Memory），本地内存保存了被该线程使用到的主内存的副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。volatile具备两种特性，第一就是保证共享变量对所有线程的可见性。将一个共享变量声明为volatile后，会有以下效应：当写一个volatile变量时，JMM会把该线程对应的本地内存中的变量强制刷新到主内存中去；这个写会操作会导致其他线程中的缓存无效。不能解决原子性但是需要注意的是，我们一直在拿volatile和synchronized做对比，仅仅是因为这两个关键字在某些内存语义上有共通之处，volatile并不能完全替代synchronized，它依然是个轻量级锁，在很多场景下，volatile并不能胜任。看下这个例子：12345678910111213141516171819202122232425package test;import java.util.concurrent.CountDownLatch;public class Counter &#123; public static volatile int num = 0; //使用CountDownLatch来等待计算线程执行完 static CountDownLatch countDownLatch = new CountDownLatch(30); public static void main(String []args) throws InterruptedException &#123; //开启30个线程进行累加操作 for(int i=0;i&lt;30;i++)&#123; new Thread()&#123; public void run()&#123; for(int j=0;j&lt;10000;j++)&#123; num++;//自加操作 &#125; countDownLatch.countDown(); &#125; &#125;.start(); &#125; //等待计算线程执行完 countDownLatch.await(); System.out.println(num); &#125;&#125;执行结果：1224291如果用volatile修饰的共享变量可以保证可见性，那么结果不应该是300000么?问题就出在num++这个操作上，因为num++不是个原子性的操作，而是个复合操作。我们可以简单讲这个操作理解为由这三步组成:读取加一赋值所以，在多线程环境下，有可能线程A将num读取到本地内存中，此时其他线程可能已经将num增大了很多，线程A依然对过期的num进行自加，重新写到主存中，最终导致了num的结果不合预期，而是小于30000。禁止指令重排序jvm在执行代码块的时候，会通过一些策略对代码顺序进行重排序来优化程序，不过有两个原则：重排序操作不会对存在数据依赖关系的操作进行重排序。比如：a=1;b=a; 这个指令序列，由于第二个操作依赖于第一个操作，所以在编译时和处理器运行时这两个操作不会被重排序。重排序是为了优化性能，但是不管怎么重排序，单线程下程序的执行结果不能被改变比如：a=1;b=2;c=a+b这三个操作，第一步（a=1)和第二步(b=2)由于不存在数据依赖关系，所以可能会发生重排序，但是c=a+b这个操作是不会被重排序的，因为需要保证最终的结果一定是c=a+b=3。重排序在单线程模式下是一定会保证最终结果的正确性，但是在多线程环境下，问题就出来了，volatile就可以解决这个问题。重排序在单线程模式下是一定会保证最终结果的正确性，但是在多线程环境下，问题就出来了，来看个例子，我们对第一个TestVolatile的例子稍稍改进，再增加个共享变量a12345678910111213141516171819202122public class TestVolatile &#123; int a = 1; boolean status = false; /** * 状态切换为true */ public void changeStatus()&#123; a = 2;//1 status = true;//2 &#125; /** * 若状态为true，则running。 */ public void run()&#123; if(status)&#123;//3 int b = a+1;//4 System.out.println(b); &#125; &#125;&#125;假设线程A执行changeStatus后，线程B执行run，我们能保证在4处，b一定等于3么？答案依然是无法保证！也有可能b仍然为2。上面我们提到过，为了提供程序并行度，编译器和处理器可能会对指令进行重排序，而上例中的1和2由于不存在数据依赖关系，则有可能会被重排序，先执行status=true再执行a=2。而此时线程B会顺利到达4处，而线程A中a=2这个操作还未被执行，所以b=a+1的结果也有可能依然等于2。使用volatile关键字修饰共享变量便可以禁止这种重排序。若用volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序volatile禁止指令重排序也有一些规则，简单列举一下：1. 当第二个操作是voaltile写时，无论第一个操作是什么，都不能进行重排序2. 当地一个操作是volatile读时，不管第二个操作是什么，都不能进行重排序3. 当第一个操作是volatile写时，第二个操作是volatile读时，不能进行重排序与synchronized的区别和使用在某些场景下，使用synchronized关键字和volatile是等价的：写入变量值时候不依赖变量的当前值，或者能够保证只有一个线程修改变量值。写入的变量值不依赖其他变量的参与。读取变量值时候不能因为其他原因进行加锁。volatile本质是在告诉jvm当前变量在寄存器中的值是不确定的,需要从主存中读取,synchronized则是锁定当前变量,只有当前线程可以访问该变量,其他线程被阻塞住.volatile仅能使用在变量级别,synchronized则可以使用在变量,方法.volatile仅能实现变量的修改可见性,而synchronized则可以保证变量的修改可见性和原子性.volatile不会造成线程的阻塞,而synchronized可能会造成线程的阻塞.当一个域的值依赖于它之前的值时，volatile就无法工作了，如n=n+1,n++等。如果某个域的值受到其他域的值的限制，那么volatile也无法工作，如Range类的lower和upper边界，必须遵循lower&lt;=upper的限制。总结简单总结下，volatile是一种轻量级的同步机制，它主要有两个特性：一是保证共享变量对所有线程的可见性；二是禁止指令重排序优化。同时需要注意的是，volatile对于单个的共享变量的读/写具有原子性，但是像num++这种复合操作，volatile无法保证其原子性。我们可以通过java本身提供的AtomicInteger来解决该问题，其具体实现看后面的博文。wait、notify和notifyAllwait()的作用是让当前线程进入等待状态，同时，wait()也会让当前线程释放它所持有的锁。“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法”，当前线程被唤醒(进入“就绪状态”)notify()和notifyAll()的作用，则是唤醒当前对象上的等待线程；notify()是唤醒单个线程，而notifyAll()是唤醒所有的线程。wait(long timeout)让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的notify()方法或 notifyAll() 方法，或者超过指定的时间量”，当前线程被唤醒(进入“就绪状态”)。wait()、notify/notifyAll() 方法是Object的本地final方法，无法被重写。wait()使当前线程阻塞，前提是 必须先获得锁，一般配合synchronized 关键字使用，即，一般在synchronized 同步代码块里使用 wait()、notify/notifyAll() 方法。wait()使当前线程阻塞，前提是 必须先获得锁，一般配合synchronized 关键字使用，即，一般在synchronized 同步代码块里使用 wait()、notify/notifyAll() 方法。当线程执行wait()方法时候，会释放当前的锁，然后让出CPU，进入等待状态。只有当 notify/notifyAll() 被执行时候，才会唤醒一个或多个正处于等待状态的线程，然后继续往下执行，直到执行完synchronized 代码块的代码或是中途遇到wait() ，再次释放锁。notify 和 notifyAll的区别notify方法只唤醒一个等待（对象的）线程并使该线程开始执行。所以如果有多个线程等待一个对象，这个方法只会唤醒其中一个线程，选择哪个线程取决于操作系统对多线程管理的实现。notifyAll 会唤醒所有等待(对象的)线程，尽管哪一个线程将会第一个处理取决于操作系统的实现。如果当前情况下有多个线程需要被唤醒，推荐使用notifyAll 方法。比如在生产者-消费者里面的使用，每次都需要唤醒所有的消费者或是生产者，以判断程序是否可以继续往下执行。","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/tags/多线程/"}]},{"title":"java多线程系列（一）——多线程基础","slug":"java多线程系列（一）——多线程基础","date":"2017-04-30T03:39:00.000Z","updated":"2018-11-05T15:10:11.598Z","comments":true,"path":"2017/04/30/java多线程系列（一）——多线程基础/","link":"","permalink":"http://www.fufan.me/2017/04/30/java多线程系列（一）——多线程基础/","excerpt":"","text":"多线程基础基本概念和术语进程所谓进程就是运行在操作系统的一个任务，进程是计算机任务调度的一个单位，操作系统在启动一个程序的时候，会为其创建一个进程，JVM就是一个进程。进程与进程之间是相互隔离的，每个进程都有独立的内存空间。计算机实现并发的原理是：CPU分时间片，交替执行，宏观并行，微观串行。同理，在进程的基础上分出更小的任务调度单元就是线程，我们所谓的多线程就是一个进程并发多个线程。线程在上面我们提到，一个进程可以并发出多个线程，而线程就是最小的任务执行单元，具体来说，一个程序顺序执行的流程就是一个线程，我们常见的main就是一个线程（主线程）。java多线程每一个Java的应用都至少包含一个线程——主线程。尽管后台也会存在一些其他的线程，例如内存管理，系统管理，信号处理等等，但是从应用来看，主函数是第一个线程，并且我们可以从其中创建多个线程。多线程指的是2个或者更多的线程来在一个程序中并发地执行任务。单处理的电脑只能在同一时间执行一个线程，时间分片是操作系统给不同的进程线程用来共享处理器时间的。线程的优先级java 中的线程优先级的范围是1～10，默认的优先级是5。“高优先级线程”会优先于“低优先级线程”执行用户线程和守护线程所谓守护线程是指在程序运行的时候在后台提供一种通用服务的线程，比如垃圾回收线程就是一个很称职的守护者，并且这种线程并不属于程序中不可或缺的部分。因 此，当所有的非守护线程结束时，程序也就终止了，同时会杀死进程中的所有守护线程。反过来说，只要任何非守护线程还在运行，程序就不会终止。守护线程和用户线程的没啥本质的区别：唯一的不同之处就在于虚拟机的离开：如果用户线程已经全部退出运行了，只剩下守护线程存在了，虚拟机也就退出了。 因为没有了被守护者，守护线程也就没有工作可做了，也就没有继续运行程序的必要了。线程安全线程安全概念：当多个线程访问某一个类（对象或方法）时，这个类始终能表现出正确的行为，那么这个类（对象或方法）就是线程安全的。锁线程安全就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。 线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。这里的加锁机制常见的如：synchronized线程的状态Java中的线程的生命周期大体可分为5种状态。新建(NEW)：新创建了一个线程对象。可运行(RUNNABLE)：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。运行(RUNNING)：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。阻塞(BLOCKED)：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种：(一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。(二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。(三). 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。死亡(DEAD)：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。线程状态切换详解线程的状态图初始状态实现Runnable接口和继承Thread可以得到一个线程类，new一个实例出来，线程就进入了初始状态可运行状态可运行状态只是说你资格运行，调度程序没有挑选到你，你就永远是可运行状态。调用线程的start()方法，此线程进入可运行状态。当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些线程也将进入可运行状态。当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入可运行状态。锁池里的线程拿到对象锁后，进入可运行状态。运行状态线程调度程序从可运行池中选择一个线程作为当前线程时线程所处的状态。这也是线程进入运行状态的唯一一种方式。死亡状态当线程的run()方法完成时，或者主线程的main()方法完成时，我们就认为它死去。这个线程对象也许是活的，但是，它已经不是一个单独执行的线程。线程一旦死亡，就不能复生。在一个死去的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。阻塞状态当前线程T调用Thread.sleep()方法，当前线程进入阻塞状态。运行在当前线程里的其它线程t2调用join()方法，当前线程进入阻塞状态。等待用户输入的时候，当前线程进入阻塞状态。等待队列调用obj的wait(), notify()方法前，必须获得obj锁，也就是必须写在synchronized(obj) 代码段内。与等待队列相关的步骤和图线程1获取对象A的锁，正在使用对象A。线程1调用对象A的wait()方法。线程1释放对象A的锁，并马上进入等待队列。锁池里面的对象争抢对象A的锁。线程5获得对象A的锁，进入synchronized块，使用对象A。线程5调用对象A的notifyAll()方法，唤醒所有线程，所有线程进入锁池。||||| 线程5调用对象A的notify()方法，唤醒一个线程，不知道会唤醒谁，被唤醒的那个线程进入锁池。notifyAll()方法所在synchronized结束，线程5释放对象A的锁。锁池里面的线程争抢对象锁，但线程1什么时候能抢到就不知道了。||||| 原本锁池+第6步被唤醒的线程一起争抢对象锁。锁池状态当前线程想调用对象A的同步方法时，发现对象A的锁被别的线程占有，此时当前线程进入锁池状态。简言之，锁池里面放的都是想争夺对象锁的线程。当一个线程1被另外一个线程2唤醒时，1线程进入锁池状态，去争夺对象锁。锁池是在同步的环境下才有的概念，一个对象对应一个锁池。apiThread.sleep(long millis)，一定是当前线程调用此方法，当前线程进入阻塞，但不释放对象锁，millis后线程自动苏醒进入可运行状态。作用：给其它线程执行机会的最佳方式。Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的cpu时间片，由运行状态变会可运行状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。t.join()/t.join(long millis)，当前线程里调用其它线程1的join方法，当前线程阻塞，但不释放对象锁，直到线程1执行完毕或者millis时间到，当前线程进入可运行状态。obj.wait()，当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者wait(long timeout)timeout时间到自动唤醒。obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程api部分的内容会在之后的部分详解","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.fufan.me/tags/多线程/"}]},{"title":"java常用集合源码分析之Map（二）","slug":"java常用集合源码分析之Map（二）","date":"2017-04-24T18:48:00.000Z","updated":"2018-11-02T18:59:18.187Z","comments":true,"path":"2017/04/25/java常用集合源码分析之Map（二）/","link":"","permalink":"http://www.fufan.me/2017/04/25/java常用集合源码分析之Map（二）/","excerpt":"","text":"HashMap以下基于 JDK1.7 分析。如图所示，HashMap 底层是基于数组和链表实现的。其中有两个重要的参数：容量负载因子容量的默认大小是 16，负载因子是 0.75，当 HashMap 的 size &gt; 16*0.75 时就会发生扩容(容量和负载因子都可以自由调整)。put 方法首先会将传入的 Key 做 hash 运算计算出 hashcode,然后根据数组长度取模计算出在数组中的 index 下标。由于在计算中位运算比取模运算效率高的多，所以 HashMap 规定数组的长度为 2^n 。这样用 2^n - 1 做位运算与取模效果一致，并且效率还要高出许多。由于数组的长度有限，所以难免会出现不同的 Key 通过运算得到的 index 相同，这种情况可以利用链表来解决，HashMap 会在 table[index]处形成链表，采用头插法将数据插入到链表中。get 方法get 和 put 类似，也是将传入的 Key 计算出 index ，如果该位置上是一个链表就需要遍历整个链表，通过 key.equals(k) 来找到对应的元素。遍历方式12345Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; entryIterator = map.entrySet().iterator(); while (entryIterator.hasNext()) &#123; Map.Entry&lt;String, Integer&gt; next = entryIterator.next(); System.out.println(\"key=\" + next.getKey() + \" value=\" + next.getValue()); &#125;123456Iterator&lt;String&gt; iterator = map.keySet().iterator(); while (iterator.hasNext())&#123; String key = iterator.next(); System.out.println(\"key=\" + key + \" value=\" + map.get(key)); &#125;123map.forEach((key,value)-&gt;&#123; System.out.println(\"key=\" + key + \" value=\" + value);&#125;);强烈建议使用第一种 EntrySet 进行遍历。第一种可以把 key value 同时取出，第二种还得需要通过 key 取一次 value，效率较低, 第三种需要 JDK1.8 以上，通过外层遍历 table，内层遍历链表或红黑树。notice在并发环境下使用 HashMap 容易出现死循环。并发场景发生扩容，调用 resize() 方法里的 rehash() 时，容易出现环形链表。这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标时就会出现死循环。所以 HashMap 只能在单线程中使用，并且尽量的预设容量，尽可能的减少扩容。在 JDK1.8 中对 HashMap 进行了优化：当 hash 碰撞之后写入链表的长度超过了阈值(默认为8)，链表将会转换为红黑树。假设 hash 冲突非常严重，一个数组后面接了很长的链表，此时重新的时间复杂度就是 O(n) 。如果是红黑树，时间复杂度就是 O(logn) 。大大提高了查询效率。线程不安全表现及原因resize死循环，形成环形链表put、addEntry、resize等方法不同步具体查看 谈谈HashMap线程不安全的体现ConcurrentHashMap由于 HashMap 是一个线程不安全的容器，因此需要支持线程安全的并发容器 ConcurrentHashMap 。JDK1.7 实现数据结构如图所示，是由 Segment 数组、HashEntry 数组组成，和 HashMap 一样，仍然是数组加链表组成。ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。get 方法ConcurrentHashMap 的 get 方法是非常高效的，因为整个过程都不需要加锁。只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值(volatile 相关知识点)。put 方法内部 HashEntry 类 ：12345678910111213static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next; HashEntry(int hash, K key, V value, HashEntry&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125;&#125;虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。首先也是通过 Key 的 Hash 定位到具体的 Segment，在 put 之前会进行一次扩容校验。这里比 HashMap 要好的一点是：HashMap 是插入元素之后再看是否需要扩容，有可能扩容之后后续就没有插入就浪费了本次扩容(扩容非常消耗性能)。而 ConcurrentHashMap 不一样，它是在将数据插入之前检查是否需要扩容，之后再做插入操作。size 方法每个 Segment 都有一个 volatile 修饰的全局变量 count ,求整个 ConcurrentHashMap 的 size 时很明显就是将所有的 count 累加即可。但是 volatile 修饰的变量却不能保证多线程的原子性，所有直接累加很容易出现并发问题。但如果每次调用 size 方法将其余的修改操作加锁效率也很低。所以做法是先尝试两次将 count 累加，如果容器的 count 发生了变化再加锁来统计 size。至于 ConcurrentHashMap 是如何知道在统计时大小发生了变化呢，每个 Segment 都有一个 modCount 变量，每当进行一次 put remove 等操作，modCount 将会 +1。只要 modCount 发生了变化就认为容器的大小也在发生变化。JDK1.8 实现1.8 中的 ConcurrentHashMap 数据结构和实现与 1.7 还是有着明显的差异。其中抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。1234567891011121314151617181920212223242526272829static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; return key + \"=\" + val; &#125; public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((o instanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125;也将 1.7 中存放数据的 HashEntry 改为 Node，但作用都是相同的。其中的 val next 都用了 volatile 修饰，保证了可见性。put 方法重点来看看 put 函数：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125;根据 key 计算出 hashcode 。判断是否需要进行初始化。f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。如果都不满足，则利用 synchronized 锁写入数据。如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。get 方法12345678910111213141516171819public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125;根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。如果是红黑树那就按照树的方式获取值。都不满足那就按照链表的方式遍历获取值。总结1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。TreeMap简介TreeMap 是一个有序的key-value集合，它是通过红黑树实现的。TreeMap 继承于AbstractMap，所以它是一个Map，即一个key-value集合。TreeMap 实现了NavigableMap接口，意味着它支持一系列的导航方法。比如返回有序的key集合。TreeMap 实现了Cloneable接口，意味着它能被克隆。TreeMap 实现了java.io.Serializable接口，意味着它支持序列化。TreeMap基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。TreeMap的基本操作 containsKey、get、put 和 remove 的时间复杂度是 log(n) 。另外，TreeMap是非同步的。 它的iterator 方法返回的迭代器是fail-fastl的。构造函数1234567891011// 默认构造函数。使用该构造函数，TreeMap中的元素按照自然排序进行排列。TreeMap()// 创建的TreeMap包含MapTreeMap(Map&lt;? extends K, ? extends V&gt; copyFrom)// 指定Tree的比较器TreeMap(Comparator&lt;? super K&gt; comparator)// 创建的TreeSet包含copyFromTreeMap(SortedMap&lt;K, ? extends V&gt; copyFrom)TreeMap与Map关系如下图：从图中可以看出：TreeMap实现继承于AbstractMap，并且实现了NavigableMap接口。TreeMap的本质是R-B Tree(红黑树)，它包含几个重要的成员变量： root, size, comparator。root 是红黑数的根节点。它是Entry类型，Entry是红黑数的节点，它包含了红黑数的6个基本组成成分：key(键)、value(值)、left(左孩子)、right(右孩子)、parent(父节点)、color(颜色)。Entry节点根据key进行排序，Entry节点包含的内容为value。红黑数排序时，根据Entry中的key进行排序；Entry中的key比较大小是根据比较器comparator来进行判断的。size是红黑数中节点的个数。源码解析可以参看此blog遍历方式遍历TreeMap的键值对，使用iterator遍历TreeMap的键，调用keySet方法遍历TreeMap的值，调用values方法","categories":[{"name":"集合","slug":"集合","permalink":"http://www.fufan.me/categories/集合/"}],"tags":[{"name":"集合","slug":"集合","permalink":"http://www.fufan.me/tags/集合/"},{"name":"map","slug":"map","permalink":"http://www.fufan.me/tags/map/"}]},{"title":"java常用集合源码分析之HashSet（三）","slug":"java常用集合源码分析之HashSet（三）","date":"2017-04-19T18:06:00.000Z","updated":"2018-11-02T18:34:30.164Z","comments":true,"path":"2017/04/20/java常用集合源码分析之HashSet（三）/","link":"","permalink":"http://www.fufan.me/2017/04/20/java常用集合源码分析之HashSet（三）/","excerpt":"","text":"HashSetHashSet 是一个不允许存储重复元素的集合，它的实现比较简单，只要理解了 HashMap，HashSet 就水到渠成了。成员变量首先了解下 HashSet 的成员变量:1234private transient HashMap&lt;E,Object&gt; map;// Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object();发现主要就两个变量:map ：用于存放最终数据的。PRESENT ：是所有写入 map 的 value 值。构造函数1234567public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;构造函数很简单，利用了 HashMap 初始化了 map 。add123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;比较关键的就是这个 add() 方法。可以看出它是将存放的对象当做了 HashMap 的健，value 都是相同的 PRESENT 。由于 HashMap 的 key 是不能重复的，所以每当有重复的值写入到 HashSet 时，value 会被覆盖，但 key 不会受到影响，这样就保证了 HashSet 中只能存放不重复的元素。遍历方式几种方式（iterator，for循环，lambda）jdk1.8 lambda123set.stream.foreach((v) -&gt; &#123; System.out.println(v);&#125;)总结HashSet 的原理比较简单，几乎全部借助于 HashMap 来实现的。所以 HashMap 会出现的问题 HashSet 依然不能避免。","categories":[],"tags":[{"name":"集合","slug":"集合","permalink":"http://www.fufan.me/tags/集合/"},{"name":"set","slug":"set","permalink":"http://www.fufan.me/tags/set/"}]},{"title":"java常用集合源码分析之List（一）","slug":"java常用集合源码分析之List（一）","date":"2017-04-09T16:44:00.000Z","updated":"2018-11-05T03:05:36.775Z","comments":true,"path":"2017/04/10/java常用集合源码分析之List（一）/","link":"","permalink":"http://www.fufan.me/2017/04/10/java常用集合源码分析之List（一）/","excerpt":"","text":"ArrayListArrayList 实现于 List、RandomAccess 接口。可以插入空数据，也支持随机访问。ArrayList默认初始化长度为10个1234/** * Default initial capacity. */private static final int DEFAULT_CAPACITY = 10;ArrayList相当于动态数据，其中最重要的两个属性分别是:elementData 数组，以及 size 大小。在调用 add() 方法的时候：12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;首先进行扩容校验。将插入的值放到尾部，并将 size + 1 。如果是调用 add(index,e) 在指定位置添加的话：12345678910public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //复制，向后移动 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125;也是首先扩容校验。接着对数据进行复制，目的是把 index 位置空出来放本次插入的数据，并将后面的数据向后移动一个位置。其实扩容最终调用的代码:1234567891011private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;也是一个数组复制的过程。由此可见 ArrayList 的主要消耗是数组扩容以及在指定位置添加数据，在日常使用时最好是指定大小，尽量减少扩容。更要减少在指定位置插入数据的操作。序列化由于 ArrayList 是基于动态数组实现的，所以并不是所有的空间都被使用。因此使用了 transient 修饰，可以防止被自动序列化。1transient Object[] elementData;因此 ArrayList 自定义了序列化与反序列化：1234567891011121314151617181920212223242526272829303132333435363738394041private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. //只序列化了被使用的数据 for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125;private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125;当对象中自定义了 writeObject 和 readObject 方法时，JVM 会调用这两个自定义方法来实现序列化与反序列化。从实现中可以看出 ArrayList 只序列化了被使用的数据。遍历方式ArrayList支持3种遍历方式通过迭代器遍历：12345Iterator iter = list.iterator();while (iter.hasNext())&#123; System.out.println(iter.next());&#125;随机访问，通过索引值去遍历，由于ArrayList实现了RandomAccess接口12345int size = list.size();for (int i=0; i&lt;size; i++) &#123; System.out.println(list.get(i)); &#125;for循环遍历1234for(String str:list) &#123; System.out.println(str); &#125;lambda123list.stream.foreach((v) -&gt; &#123; System.out.println(v);&#125;)VectorVector 也是实现于 List 接口，底层数据结构和 ArrayList 类似,也是一个动态数组存放数据。不过是在 add() 方法的时候使用 synchronized 进行同步写数据，但是开销较大，所以 Vector 是一个同步容器并不是一个并发容器。以下是 add() 方法：123456public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125;以及指定位置插入数据:1234567891011121314public void add(int index, E element) &#123; insertElementAt(element, index);&#125;public synchronized void insertElementAt(E obj, int index) &#123; modCount++; if (index &gt; elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + \" &gt; \" + elementCount); &#125; ensureCapacityHelper(elementCount + 1); System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); elementData[index] = obj; elementCount++;&#125;遍历方式和ArrayList相比, 多了一种Enumeration遍历12345Integer value = null;Enumeration enu = vec.elements();while (enu.hasMoreElements()) &#123; value = (Integer)enu.nextElement();&#125;LinkedList如图所示 LinkedList 底层是基于双向链表实现的，也是实现了 List 接口，所以也拥有 List 的一些特点(JDK1.7/8 之后取消了循环，修改为双向链表)。新增方法123456789101112131415161718public boolean add(E e) &#123; linkLast(e); return true;&#125; /** * Links e as last element. */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;可见每次插入都是移动指针，和 ArrayList 的拷贝数组来说效率要高上不少。查询方法1234567891011121314151617181920public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125;上述代码，利用了双向链表的特性，如果index离链表头比较近，就从节点头部遍历。否则就从节点尾部开始遍历。使用空间（双向链表）来换取时间。node()会以O(n/2)的性能去获取一个结点如果索引值大于链表大小的一半，那么将从尾结点开始遍历这样的效率是非常低的，特别是当 index 越接近 size 的中间值时。总结：LinkedList 插入，删除都是移动指针效率很高。查找需要进行遍历查询，效率较低。遍历方式除了arraylist的四种遍历方式以外，还可以通过removeFirst()和removeLast()的方式：1234567891011//removeFirst()try &#123; while(list.removeFirst() != null) ; &#125; catch (NoSuchElementException e) &#123; &#125; //removeLast()try &#123; while(list.removeLast() != null) ; &#125; catch (NoSuchElementException e) &#123;这种方式是效率最高的，不过他会删除原始数据。随机遍历是效率最低的，推荐用for循环的方式。后面我也会拿出小节专门来分析集合的遍历效率","categories":[{"name":"集合","slug":"集合","permalink":"http://www.fufan.me/categories/集合/"}],"tags":[{"name":"集合","slug":"集合","permalink":"http://www.fufan.me/tags/集合/"},{"name":"list","slug":"list","permalink":"http://www.fufan.me/tags/list/"}]},{"title":"OSI和TCP/IP的模型简述","slug":"OSI和TCP-IP的7层模型简述","date":"2017-04-02T12:40:00.000Z","updated":"2018-11-02T13:37:34.149Z","comments":true,"path":"2017/04/02/OSI和TCP-IP的7层模型简述/","link":"","permalink":"http://www.fufan.me/2017/04/02/OSI和TCP-IP的7层模型简述/","excerpt":"","text":"体系结构概述先盗取盗图一张^_^, OSI的七层体系结构概念清楚，理论也很完整，但是它比较复杂而且不实用，总图如下：但是由于7层模型过于复杂，大部分公司和国家支持更简单的5层模型五层协议各层详述应用层（application layer）应用层的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统DNS，支持万维网应用的HTTP协议，支持电子邮件的SMTP协议等等。我们把应用层交互的数据单元称为报文。域名系统（Domain Name System缩写DNS，Domain Name被译为域名）域名系统是因特网的一项核心服务，它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。（百度百科）例如：一个公司的Web网站可看作是它在网上的门户，而域名就相当于其门牌地址，通常域名都使用该公司的名称或简称。例如上面提到的微软公司的域名，类似的还有：IBM公司的域名是www.ibm.com、Oracle公司的域名是www.oracle.com、Cisco公司的域名是www.cisco.com等。HTTP协议超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。（百度百科）运输层（transport layer）运输层的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。运输层主要使用以下两种协议：传输控制协议TCP（Transmisson Control Protocol）–提供面向连接的，可靠的数据传输服务。用户数据协议UDP（User Datagram Protocol）–提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。UDP的主要特点：UDP是无连接的；UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；UDP是面向报文的；UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）；UDP支持一对一、一对多、多对一和多对多的交互通信；UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。TCP的主要特点：TCP是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）；TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；面向字节流。TCP中的“流”（stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。网络层（network layer）网络层负责为分组交换网上的不同主机提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在TCP/IP体系结构中，由于网络层使用IP协议，因此分组也叫IP数据报，简称数据报。这里要注意：不要把运输层的“用户数据报UDP”和网络层的“IP数据报”弄混。另外，无论是哪一层的数据单元，都可笼统地用“分组”来表示。网络层的另一个任务就是选择合适的路由，使源主机运输层所传下来的分株，能通过网络层中的路由器找到目的主机。这里强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称.互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Prococol）和许多路由选择协议，因此互联网的网络层也叫做网际层或IP层。数据链路层（data link layer）数据链路层通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 在两个相邻节点之间传送数据时，数据链路层将网络层交下来的IP数据报组装程帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。在 接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。物理层（physical layer）在物理层上所传送的数据单位是比特。物理层的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。","categories":[{"name":"网络","slug":"网络","permalink":"http://www.fufan.me/categories/网络/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://www.fufan.me/tags/网络/"}]},{"title":"java常用集合源码分析之绪论","slug":"java常用集合源码分析之绪论","date":"2017-04-01T02:52:00.000Z","updated":"2018-11-05T03:06:23.200Z","comments":true,"path":"2017/04/01/java常用集合源码分析之绪论/","link":"","permalink":"http://www.fufan.me/2017/04/01/java常用集合源码分析之绪论/","excerpt":"","text":"面向对象语言对事物的体现都是以对象的形式，所以为了方便对多个对象的操作，就对对象进行存储，集合就是存储对象最常用的一种方式。数组虽然也可以存储对象，但长度是固定的；集合长度是可变的，数组中可以存储基本数据类型，集合只能存储对象。集合类的特点：集合只用于存储对象，集合长度是可变的，集合可以存储不同类型的对象。java集合继承关系图先来看两张图：上述类图中，实线边框的是实现类，比如ArrayList，LinkedList，HashMap等，折线边框的是抽象类，比如AbstractCollection，AbstractList，AbstractMap等，而点线边框的是接口，比如Collection，Iterator，List等。1、Iterator接口Iterator接口，这是一个用于遍历集合中元素的接口，主要包含hashNext(),next(),remove()三种方法。它的一个子接口LinkedIterator在它的基础上又添加了三种方法，分别是add(),previous(),hasPrevious()。也就是说如果是先Iterator接口，那么在遍历集合中元素的时候，只能往后遍历，被遍历后的元素不会在遍历到，通常无序集合实现的都是这个接口，比如HashSet，HashMap；而那些元素有序的集合，实现的一般都是LinkedIterator接口，实现这个接口的集合可以双向遍历，既可以通过next()访问下一个元素，又可以通过previous()访问前一个元素，比如ArrayList。抽象类的使用。如果要自己实现一个集合类，去实现那些抽象的接口会非常麻烦，工作量很大。这个时候就可以使用抽象类，这些抽象类中给我们提供了许多现成的实现，我们只需要根据自己的需求重写一些方法或者添加一些方法就可以实现自己需要的集合类，工作流昂大大降低。2、Collection （集合的最大接口）继承关系——List 可以存放重复的内容——Set 不能存放重复的内容，所以的重复内容靠hashCode()和equals()两个方法区分——Queue 队列接口——SortedSet 可以对集合中的数据进行排序Collection定义了集合框架的共性功能。add方法的参数类型是Object。以便于接收任意类型对象。集合中存储的都是对象的引用(地址)。3、List的常用子类特有方法。凡是可以操作角标的方法都是该体系特有的方法。——ArrayList 线程不安全，查询速度快——Vector 线程安全，但速度慢，已被ArrayList替代——LinkedList 链表结果，增删速度快4、Set接口Set：元素是无序(存入和取出的顺序不一定一致)，元素不可以重复。——HashSet:底层数据结构是哈希表。是线程不安全的。不同步。HashSet是如何保证元素唯一性的呢？是通过元素的两个方法，hashCode和equals来完成。如果元素的HashCode值相同，才会判断equals是否为true。如果元素的hashcode值不同，不会调用equals。注意,对于判断元素是否存在，以及删除等操作，依赖的方法是元素的hashcode和equals方法。——TreeSet：有序的存放：TreeSet线程不安全，可以对Set集合中的元素进行排序; 通过compareTo或者compare方法来保证元素的唯一性，元素以二叉树的形式存放。5、Object类在实际开发中经常会碰到区分同一对象的问题，一个完整的类最好覆写Object类的hashCode()、equals()、toString()三个方法。6、集合的输出5种常见的输出方式——Iterator： 迭代输出，使用最多的输出方式——ListIterator： Iterator的子接口，专门用于输出List中的内容——Enumeration——foreach——lambda在迭代时，不可以通过集合对象的方法操作集合中的元素，因为会发生ConcurrentModificationException异常。所以，在迭代器时，只能用迭代器的放过操作元素，可是Iterator方法是有限的，只能对元素进行判断，取出，删除的操作，如果想要其他的操作如添加，修改等，就需要使用其子接口，ListIterator。该接口只能通过List集合的listIterator方法获取。7、Map接口Correction、Set、List接口都属于单值的操作，而Map中的每个元素都使用key——&gt;value的形式存储在集合中。Map集合：该集合存储键值对。一对一对往里存。而且要保证键的唯一性。8、Map接口的常用子类Map——HashMap：底层是哈希表数据结构，允许使用 null 值和 null 键，该集合是不同步的。将hashtable替代，jdk1.2.效率高。——TreeMap：底层是二叉树数据结构。线程不同步。可以用于给map集合中的键进行排序。9、集合工具类Collections:集合框架的工具类。里面定义的都是静态方法。Collections和Collection有什么区别？Collection是集合框架中的一个顶层接口，它里面定义了单列集合的共性方法。它有两个常用的子接口，——List：对元素都有定义索引。有序的。可以重复元素。——Set：不可以重复元素。无序。Collections是集合框架中的一个工具类。该类中的方法都是静态的。提供的方法中有可以对list集合进行排序，二分查找等方法。通常常用的集合都是线程不安全的。因为要提高效率。如果多线程操作这些集合时，可以通过该工具类中的同步方法，将线程不安全的集合，转换成安全的。10、比较11、总结List：add/remove/get/set。ArrayList：其实就是数组，容量一大，频繁增删就是噩梦，适合随机查找；LinkedList：增加了push/[pop|remove|pull]，其实都是removeFirst；Vector：历史遗留产物，同步版的ArrayList，代码和ArrayList太像；Stack：继承自Vector。Java里其实没有纯粹的Stack，可以自己实现，用组合的方式，封装一下LinkedList即可；Queue：本来是单独的一类，不过在SUN的JDK里就是用LinkedList来提供这个功能的，主要方法是offer/pull/peek，因此归到这里呢。Set：add/remove。可以用迭代器或者转换成list。HashSet：内部采用HashMap实现的；LinkedHashSet：采用LinkedHashMap实现；TreeSet：TreeMap。Map：put/get/remove。HashMap/HashTable：散列表，和ArrayList一样采用数组实现，超过初始容量会对性能有损耗；LinkedHashMap：继承自HashMap，但通过重写嵌套类HashMap.Entry实现了链表结构，同样有容量的问题；Properties：是继承的HashTable。","categories":[],"tags":[{"name":"集合","slug":"集合","permalink":"http://www.fufan.me/tags/集合/"}]},{"title":"Java面试总结积累（基础篇）之集合问题","slug":"Java面试总结积累（基础篇）之集合问题","date":"2017-01-12T16:35:00.000Z","updated":"2018-11-05T03:12:48.337Z","comments":true,"path":"2017/01/13/Java面试总结积累（基础篇）之集合问题/","link":"","permalink":"http://www.fufan.me/2017/01/13/Java面试总结积累（基础篇）之集合问题/","excerpt":"","text":"这里通过收集网上一些比较好的博客对集合的总结做一下记录和积累。List, Set, Map三者的区别及总结List：对付顺序的好帮手List接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象Set:注重独一无二的性质不允许重复的集合。不会有多个元素引用相同的对象。Map:用Key来搜索的专家使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。Arraylist 与 LinkedList 区别Arraylist底层使用的是数组（存读数据效率高，插入删除特定位置效率低），LinkedList底层使用的是双向循环链表数据结构（插入，删除效率特别高）。学过数据结构这门课后我们就知道采用链表存储，插入，删除元素时间复杂度不受元素位置的影响，都是近似O（1）而数组为近似O（n），因此当数据特别多，而且经常需要插入删除元素时建议选用LinkedList.一般程序只用Arraylist就够用了，因为一般数据量都不会蛮大，Arraylist是使用最多的集合类。ArrayList 与 Vector 区别（为什么要用Arraylist取代Vector呢？）Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector ，代码要在同步操作上耗费大量的时间。Arraylist不是同步的，所以在不需要同步时建议使用Arraylist。HashMap 和 Hashtable 的区别HashMap是非线程安全的，HashTable是线程安全的；HashTable内部的方法基本都经过synchronized修饰。因为线程安全的问题，HashMap要比HashTable效率高一点，HashTable基本被淘汰。HashMap允许有null值的存在，而在HashTable中put进的键值只要有一个null，直接抛出NullPointerException。TIPS: Hashtable和HashMap有几个主要的不同：线程安全以及速度。仅在你需要完全的线程安全的时候使用Hashtable，而如果你使用Java5或以上的话，请使用ConcurrentHashMap吧HashMap 和 ConcurrentHashMap 的区别ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护，相对于HashTable的synchronized锁的粒度更精细了一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。（JDK1.8之后ConcurrentHashMap启用了一种全新的方式实现,利用CAS算法。）HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。HashSet如何检查重复当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。==与equals的区别如果两个对象相等，则hashcode一定也是相同的两个对象相等,对两个equals方法返回true两个对象有相同的hashcode值，它们也不一定是相等的综上，equals方法被覆盖过，则hashCode方法也必须被覆盖hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。==是判断两个变量或实例是不是指向同一个内存空间 equals是判断两个变量或实例所指向的内存空间的值是不是相同==是指对内存地址进行比较 equals()是对字符串的内容进行比较3.==指引用是否相同 equals()指的是值是否相同comparable 和 comparator的区别？comparable接口实际上是出自java.lang包 它有一个 compareTo(Object obj)方法用来排序comparator接口实际上是出自 java.util 包它有一个compare(Object obj1, Object obj2)方法用来排序一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo方法或compare方法，当我们需要对某一个集合实现两种排序方式，比如一个song对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo方法和使用自制的Comparator方法或者以两个Comparator来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的Collections.sort().如何对Object的list排序？对objects数组进行排序，我们可以用Arrays.sort()方法对objects的集合进行排序，需要使用Collections.sort()方法如何实现数组与List的相互转换？List转数组:toArray(arraylist.size()方法数组转List:Arrays的asList(a)方法1234567891011121314151617181920212223List&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(); arrayList.add(&quot;s&quot;); arrayList.add(&quot;e&quot;); arrayList.add(&quot;n&quot;); /** * ArrayList转数组 */ int size=arrayList.size(); String[] a = arrayList.toArray(new String[size]); //输出第二个元素 System.out.println(a[1]);//结果：e //输出整个数组 System.out.println(Arrays.toString(a));//结果：[s, e, n] /** * 数组转list */ List&lt;String&gt; list=Arrays.asList(a); /** * list转Arraylist */ List&lt;String&gt; arrayList2 = new ArrayList&lt;String&gt;(); arrayList2.addAll(list); System.out.println(list);如何求ArrayList集合的交集 并集 差集 去重复并集需要用到List接口中定义的几个方法：addAll(Collection&lt;? extends E&gt; c) :按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾retainAll(Collection&lt;?&gt; c): 仅保留此列表中包含在指定集合中的元素。removeAll(Collection&lt;?&gt; c) :从此列表中删除指定集合中包含的所有元素。TIPS: JAVA8中提供了通过lambda方式处理集合，如Collections类中好多工具方法用stream流方式处理，方便了我们在处理集合时的各种情况，JAVA8集合这块再后面的blog中会单独拿出来总结。HashMap 的工作原理及代码实现集合框架源码学习之HashMap(JDK1.8)ConcurrentHashMap 的工作原理及代码实现ConcurrentHashMap实现原理及源码分析集合框架底层数据结构总结CollectionListArraylist：数组（查询快,增删慢 线程不安全,效率高 ）Vector：数组（查询快,增删慢 线程安全,效率低 ）LinkedList：链表（查询慢,增删快 线程不安全,效率高 ）SetHashSet（无序，唯一）:哈希表或者叫散列集(hash table)LinkedHashSet：链表和哈希表组成 。 由链表保证元素的排序 ， 由哈希表证元素的唯一性TreeSet（有序，唯一）：红黑树(自平衡的排序二叉树。)MapHashMap：基于哈希表的Map接口实现（哈希表对键进行散列，Map结构即映射表存放键值对）LinkedHashMap:HashMap 的基础上加上了链表数据结构HashTable:哈希表TreeMap:红黑树（自平衡的排序二叉树）集合的选用主要根据集合的特点来选用，比如我们需要根据键值获取到元素值时就选用Map接口下的集合，需要排序时选择TreeMap,不需要排序时就选择HashMap,需要保证线程安全就选用ConcurrentHashMap.当我们只需要存放元素值时，就选择实现Collection接口的集合，需要保证元素唯一时选择实现Set接口的集合比如TreeSet或HashSet，不需要就选择实现List接口的比如ArrayList或LinkedList，然后再根据实现这些接口的集合的特点来选用。","categories":[{"name":"面试","slug":"面试","permalink":"http://www.fufan.me/categories/面试/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://www.fufan.me/tags/面试/"},{"name":"java基础","slug":"java基础","permalink":"http://www.fufan.me/tags/java基础/"}]},{"title":"Java面试总结积累（基础篇）之语法问题","slug":"Java面试总结积累（基础篇）之语法问题","date":"2017-01-02T16:34:00.000Z","updated":"2018-11-05T03:12:29.706Z","comments":true,"path":"2017/01/03/Java面试总结积累（基础篇）之语法问题/","link":"","permalink":"http://www.fufan.me/2017/01/03/Java面试总结积累（基础篇）之语法问题/","excerpt":"","text":"java开发经验固然很重要，但是有很多面试当中会遇到一些基础问题，需要自己来进行总结归类，也算是扫盲和回归吧。 面向对象和面向过程的区别面向过程：优点：性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、Linux/Unix等一般采用面向过程开发，性能是最重要的因素。缺点：没有面向对象易维护、易复用、易扩展面向对象：优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护缺点：性能比面向过程低Java语言有哪些特点？1，简单易学；2，面向对象（封装，继承，多态）；3，平台无关性（Java虚拟机实现平台无关性）；4，可靠性；5，安全性；6，支持多线程（C++语言没有内置的多线程机制，因此必须调用操作系统的多线程功能来进行多线程程序设计，而Java语言却提供了多线程支持）；7，支持网络编程并且很方便（Java语言诞生本身就是为简化网络编程设计的，因此Java语言不仅支持网络编程而且很方便）；8，编译与解释并存；什么是字节码？采用字节码的最大好处是什么？什么Java是虚拟机？先看下java中的编译器和解释器：Java中引入了虚拟机的概念，即在机器和编译程序之间加入了一层抽象的虚拟的机器。这台虚拟的机器在任何平台上都提供给编译程序一个的共同的接口。编译程序只需要面向虚拟机，生成虚拟机能够理解的代码，然后由解释器来将虚拟机代码转换为特定系统的机器码执行。在Java中，这种供虚拟机理解的代码叫做字节码（即扩展名为.class的文件），它不面向任何特定的处理器，只面向虚拟机。每一种平台的解释器是不同的，但是实现的虚拟机是相同的。Java源程序经过编译器编译后变成字节码，字节码由虚拟机解释执行，虚拟机将每一条要执行的字节码送给解释器，解释器将其翻译成特定机器上的机器码，然后在特定的机器上运行，这就是上面提到的Java的特点的编译与解释并存的解释。Java源代码—-&gt;编译器—-&gt;jvm可执行的Java字节码(即虚拟指令)—-&gt;jvm—-&gt;jvm中解释器—–&gt;机器可执行的二进制机器码—-&gt;程序运行。采用字节码的好处：Java语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以Java程序运行时比较高效，而且，由于字节码并不专对一种特定的机器，因此，Java程序无须重新编译便可在多种不同的计算机上运行。什么是Java虚拟机任何一种可以运行Java字节码的软件均可看成是Java的虚拟机（JVM）字符型常量和字符串常量的区别形式上:字符常量是单引号引起的一个字符字符串常量是双引号引起的若干个字符含义上:字符常量相当于一个整形值(ASCII值),可以参加表达式运算字符串常量代表一个地址值(该字符串在内存中存放位置)占内存大小字符常量只占一个字节字符串常量占若干个字节(至少一个字符结束标志)Java语言采用何种编码方案？有何特点？Java语言采用Unicode编码标准，Unicode（标准码），它为每个字符制订了一个唯一的数值，因此在任何的语言，平台，程序都可以放心的使用。构造器Constructor是否可被override在讲继承的时候我们就知道父类的私有属性和构造方法并不能被继承，所以Constructor也就不能被override,但是可以overload,所以你可以看到一个类中有多个构造函数的情况。重载和重写的区别重载：发生在同一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同，发生在编译时。重写：发生在父子类中，方法名、参数列表必须相同，返回值小于等于父类，抛出的异常小于等于父类，访问修饰符大于等于父类；如果父类方法访问修饰符为private则子类中就不是重写。java 面向对象编程三大特性封装、继承、多态String和StringBuffer、StringBuilder的区别是什么？String为什么是不可变的可变性String类中使用字符数组保存字符串，private final char value[]，所以string对象是不可变的。StringBuilder与StringBuffer都继承自AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串，char[]value，这两种对象都是可变的。线程安全性String中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder是StringBuilder与StringBuffer的公共父类，定义了一些字符串的基本操作，如expandCapacity、append、insert、indexOf等公共方法。StringBuffer对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder并没有对方法进行加同步锁，所以是非线程安全的。性能每次对String 类型进行改变的时候，都会生成一个新的String对象，然后将指针指向新的String 对象。StringBuffer每次都会对StringBuffer对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用StirngBuilder 相比使用StringBuffer 仅能获得10%~15% 左右的性能提升，但却要冒多线程不安全的风险。对于三者使用的总结：如果要操作少量的数据用 = String单线程操作字符串缓冲区 下操作大量数据 = StringBuilder多线程操作字符串缓冲区 下操作大量数据 = StringBuffer在一个静态方法内调用一个非静态成员为什么是非法的？由于静态方法可以不通过对象进行调用，因此在静态方法里，不能调用其他非静态变量，也不可以访问非静态变量成员。在Java中定义一个不做事且没有参数的构造方法的作用Java程序在执行子类的构造方法之前，如果没有用super()来调用父类特定的构造方法，则会调用父类中“没有参数的构造方法”。因此，如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用super()来调用父类中特定的构造方法，则编译时将发生错误，因为Java程序在父类中找不到没有参数的构造方法可供执行。解决办法是在父类里加上一个不做事且没有参数的构造方法。接口和抽象类的区别是什么？接口的方法默认是public，所有方法在接口中不能有实现，抽象类可以有非抽象的方法接口中的实例变量默认是final类型的，而抽象类中则不一定一个类可以实现多个接口，但最多只能实现一个抽象类一个类实现接口的话要实现接口的所有方法，而抽象类不一定接口不能用new实例化，但可以声明，但是必须引用一个实现该接口的对象从设计层面来说，抽象是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。成员变量与局部变量的区别有那些？从语法形式上，看成员变量是属于类的，而局部变量是在方法中定义的变量或是方法的参数；成员变量可以被public,private,static等修饰符所修饰，而局部变量不能被访问控制修饰符及static所修饰；成员变量和局部变量都能被final所修饰；从变量在内存中的存储方式来看，成员变量是对象的一部分，而对象存在于堆内存，局部变量存在于栈内存从变量在内存中的生存时间上看，成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动消失。成员变量如果没有被赋初值，则会自动以类型的默认值而赋值（一种情况例外被final修饰但没有被static修饰的成员变量必须显示地赋值）；而局部变量则不会自动赋值。创建一个对象用什么运算符？对象实体与对象引用有何不同？new运算符，new创建对象实例（对象实例在堆内存中），对象引用指向对象实例（对象引用存放在栈内存中）。一个对象引用可以指向0个或1个对象（一根绳子可以不系气球，也可以系一个气球）;一个对象可以有n个引用指向它（可以用n条绳子系住一个气球）什么是方法的返回值？返回值在类的方法里的作用是什么方法的返回值是指我们获取到的某个方法体中的代码执行后产生的结果！（前提是该方法可能产生结果）。返回值的作用:接收出结果，使得它可以用于其他的操作！一个类的构造方法的作用是什么？若一个类没有声明构造方法，改程序能正确执行吗？为什么？主要作用是完成对类对象的初始化工作。可以执行。因为一个类即使没有声明构造方法也会有默认的不带参数的构造方法。构造方法有哪些特性？名字与类名相同；没有返回值，但不能用void声明构造函数；生成类的对象时自动执行，无需调用。静态方法和实例方法有何不同？静态方法和实例方法的区别主要体现在两个方面：在外部调用静态方法时，可以使用”类名.方法名”的方式，也可以使用”对象名.方法名”的方式。而实例方法只有后面这种方式。也就是说，调用静态方法可以无需创建对象。静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），而不允许访问实例成员变量和实例方法；实例方法则无此限制对象的相等与指向他们的引用相等，两者有什么不同？对象的相等 比的是内存中存放的内容是否相等而 引用相等 比较的是他们指向的内存地址是否相等。在调用子类构造方法之前会先调用父类没有参数的构造方法，其目的是？帮助子类做初始化工作。equals 和 == 的区别？通俗点讲：==是看看左右是不是一个东西。equals是看看左右是不是长得一样。如何记住嘛。如果单纯是想记住，==：等于。equals：相同。两个长得一样的人，只能说长的相同(equals)，但是不等于他们俩是一个人。你只要记住equals，==就不用记了。术语来讲的区别：==是判断两个变量或实例是不是指向同一个内存空间 equals是判断两个变量或实例所指向的内存空间的值是不是相同==是指对内存地址进行比较 equals()是对字符串的内容进行比较3.==指引用是否相同 equals()指的是值是否相同","categories":[{"name":"面试","slug":"面试","permalink":"http://www.fufan.me/categories/面试/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://www.fufan.me/tags/面试/"},{"name":"java base","slug":"java-base","permalink":"http://www.fufan.me/tags/java-base/"}]},{"title":"（绪）设计模式之架构中的设计原则","slug":"（绪）设计模式之架构中的设计原则","date":"2016-10-11T10:51:00.000Z","updated":"2018-11-05T08:13:53.199Z","comments":true,"path":"2016/10/11/（绪）设计模式之架构中的设计原则/","link":"","permalink":"http://www.fufan.me/2016/10/11/（绪）设计模式之架构中的设计原则/","excerpt":"","text":"在进行软件架构工作时，需要遵循面向对象原则，这些原则同样在各类设计模式、架构模式之中，在学习过程中可以通过类图、时序图、示例代码等形式，不断体会这些原则在解决“依赖”和变化中的效果。当然，这些“原则”的队伍也在变化。不断有新的“原则加入，也有被淘汰掉的，真正沉淀下来的通用的”原则“其实并不多在使用面向对象的思想进行系统设计时，前任总结出了7条原则，分别是单一职责原则、开闭原则、里氏替换原则、依赖注入原则、接口分离原则、迪米特原则和有限使用组合而不是继承原则。下面来介绍下这几种原则的含义，也为后面学习设计模式打下基础。原则一：单一职责原则但以职责原则的核心思想就是：系统中的每一个对象都应该只有一个单独的职责，而所有对象所关注的就是自身职责的完成，全称即Single Responsibility Principle。其实单一职责的意思就是开发人员经常说的”高内聚、低耦合“。也就是说，每一个类应该只有一个职责，对外只能提供一种功能，而引起类变化的原因应该只有一个。在设计模式中，所有的设计模式都要遵守这个原则。”单一职责“也就是”单一变化原因“。通常一个类的职责越多，导致的变化因素也与阿朵，我们在设计的时候可能会把该类的有关的操作都组合在这个类中，这样做的后果就有可能将多个职责“耦合”到一起。解决这个问题的方法就是“分耦”，将不同的职责分别进行封装，不要将组合在一个类中。例如将用户的属性和用户的行为放在一个接口中声明，如下：12345678910interface User&#123; //身高 public double getHeight(); //体重 public double getWeight(); //吃饭 public void eat(); //玩游戏 public void gaming();&#125;上面的例子就存在这个问题，身高和体重属于业务对象，与之对应的方法主要负责用户的属性，而吃饭和玩游戏是相应的业务逻辑，主要负责用户的行为，这会给人一种不知道这个接口到底是做什么的感觉，职责不清晰，后期维护的时候会造成各种各样的问题。可以将这个接口分为两个。123456interface UserPro&#123; //身高 public double getHeight(); //体重 public double getWeight();&#125;123456interface UserAct&#123; //吃饭 public void eat(); //玩游戏 public void gaming();&#125;然后分别实现这两个接口，这里的实现我就不详细写了，主要通过这种方式可以做到当需要修改用户属性的时候，只需要对UserPro这个接口进行修改，而不会影响到其他类。另外，SRP原则的好处是可以消除耦合，减小因需求变化引起代码僵化的难堪局面。需要注意：一个合理的类，应该仅有一个引起他变化的原因，即单一职责。在没有变化征兆的情况下，应用SRP或其他原则是不明智的。在需求实际发生变化时就应该应用SRP等原则来重构代码。使用测试驱动开发会迫使我们在设计出现劣质趋势之前分离不合理代码如果测试不能迫使职责分离，僵化性和脆弱性的腐朽味会变得很浓烈，那就应该用Facade或者Proxy模式对代码重构原则二：里氏替换原则（LSP）里氏替换原则的核心思想就是：在任何父类出现的地方都可以用他的自雷来替代。它的英文缩写为LSP，全称是Liskov Subsitituition Principle。通俗点讲，就是同一个继承体系中的对象应该有果农共同的行为特征。里氏替换原则关注的是怎样良好地使用继承，也就是说不要滥用继承，它是继承复用的基石。在里氏替换原则中，所有引用基类的地方必须能够透明地使用其子类对象，也就是说，只要父类出现的地方，子类就能出现，而且替换为子类不会产生任何错误或者异常。但是反过来，子类出现的地方，替换为父类就可能出现问题了。主要抓住以下四层含义（子类的范围大于等于父类的范围）：子类必须完全实现父类的方法子类可以有自己的特性覆盖或者实现父类的方法时输入参数可以被放大覆写或者实现父类的方法时输出结果可以被缩小原则三：依赖注入原则（DIP）依赖注入原则的核心思想就是：要依赖于抽象，不要依赖于具体的实现。英文全称就是Dependence Inversion Principle。通俗的讲：在应用程序中，所有的类如果使用或者依赖于其他的类，则都应该依赖于这些其他类的抽象类，而不是这些其他类的具体实现。即要求开发人员在编程时针对接口编程，而不是针对实现编程。依赖注入原则有三点要注意的：高层模块不应该依赖低层模块，两者都应该依赖于抽象（抽象类或接口）。抽象（抽象类或接口）不应该依赖于细节（具体实现类）。细节（具体实现类）应该依赖抽象这里的抽象指的是不能被实例化的抽象类或接口，具体的实现则是可以通过new直接实例化的。这个原则是开闭原则的基础（对扩展开放，对修改关闭）。三种实现方式：通过构造函数传递依赖对象通过setter方法传递依赖对象接口声明实现依赖对象原则四：接口分离原则（ISP）接口分离原则的核心思想就是：不应该强迫客户程序依赖它们不需要使用的方法。它的全称是Interface Segregation Principle。其实接口分离原则的意思就是一个接口不需要提供太多的行为，一个接口应该只提供一种对外的功能，不应该吧所有的操作都封装到一个接口中。这里的接口不仅是interface关键字的实例，接口分为以下两种：对象接口（object Interface）java中声明一个类，通过new出一个实例，它是对一个类型的事务的描述，这也是一种接口。例如：1Phone phone = new Phone(); //这里的类Phone就是实例Phone的一个接口类接口（Class Interface）这种接口就是通过关键字Interface定义的接口。接口分离原则要求的是在一个模块中应该只依赖它需要的接口，以保证接口的纯洁。切勿定义太臃肿的接口。接口分离原则与但以职责原则有点类似，都是说如何设计接口，不过不同在于单一职责原则要求的是类和接口职责单一，注重的是职责，是业务逻辑上的划分。而接口分离原则要求的是接口的方法尽量少，针对一个模块尽量有用。如何做到该原则：接口尽量小：小的概念是保证一个接口之服务于一个子模块或者业务逻辑接口高内聚：指的是对内高度依赖，对外尽可能隔离。即一个接口内部声明的方法相互之间都与某一个子模块相关，且这个子模块必需的。接口设计是有限度的：话说回来，如果过度地遵循该原则，会使得接口数量剧增，复杂度正价，这并不是我们想要的结果。原则五：迪米特原则（LOD）全称是Law of Demeter。核心思想就是：一个对象应当对其他对象尽可能少地了解。意思就是降低各个对象之间的耦合，提高系统的可维护性。在模块之间，应该只通过接口来通信，而不理会模块的内部工作原理，它可以使各个模块偶和程度降到最低，促进软件的复用。它的核心观念还是类间解耦，弱耦合。举个例子，监狱的犯人是不能随便和外面的人打交道，除非探亲，所以狱警就是这个迪米特法则的执行者，监狱就是类，犯人就是类的内部信息。总结下这个原则要注意的地方：在类的划分上，因可更改创建有弱耦合的类。在类的结构设计上，每一个类都应当尽量降低成员的访问权限。在类的设计上，只要有可能，一个类应当设计成不变类在对其他类的引用上，一个对象对其他对象的引用应当降到最低尽量降低类的访问权限谨慎使用序列化功能不要暴露类成员，而应该提供相应的访问方法（属性getter）原则六：开闭原则（OCP）开闭原则的核心思想：一个对象对扩展开放，对修改关闭。其实开闭原则就是：对类的改动是通过增加代码进行的，而不是改动现有的代码。也就是说，软件开发人员一旦写出了可以运行的代码，就不应该去改变它，而是要保证他一直能运行下去，这就需要借助java的抽象和多态，即把可能变化的内容抽象出来，从而使抽象的部分是相对稳定的，而具体的实现层则是可以改变和扩展的。注意：这些设计原则并不是绝对的，而是应根据项目的实际需求来定夺。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.fufan.me/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.fufan.me/tags/设计模式/"}]},{"title":"JAVA基本数据结构","slug":"JAVA基本数据结构","date":"2016-09-12T15:18:00.000Z","updated":"2018-11-05T03:13:08.387Z","comments":true,"path":"2016/09/12/JAVA基本数据结构/","link":"","permalink":"http://www.fufan.me/2016/09/12/JAVA基本数据结构/","excerpt":"","text":"java基本数据结构其实学一门语言，基础很重要，现在很多java程序员只是对jdk和各种框架特别熟悉，能熟练地使用各种包和api组件，包括现在很多培训都是灌输这些所谓的实际应用。这会导致学到最后只会照葫芦画瓢。java数据结构的只是体系包括线性表、树、数组、集合、矩阵、排序、查找、哈希表，并将java的设计思想、方法及一些常见的算法、设计模式贯穿其中。其中线性表、链表、哈希表是最为常用的数据结构，在进行java开发时，jdk已经为我们提供了一系列相应的类，如下图。来实现基本的数据结构。这些类均在java.util包中。CollectionListLinkedListArrayListVector(Stack)SetQueueMapHashtableHashMapWeakHashMapCollection接口接口Collection是最基本的集合接口，一个Collection代表一组Object，即Collection的元素（Elements）。主要分为两类，LIst和Set，它们是以是否允许有相同元素来区分。当然其结构也不同。所有实现Collection接口的类都必须提供两个标准的构造函数。无参为空，有参则可复制一个传入的Collection。如何遍历？可以通过迭代器iterator()方法，注意访问Collection中的每一个元素，这种方式也是所有继承于它的类都可以使用的遍历方式。12345Collection collection = new ArrayList&lt;String&gt;();Iterator i = collection.iterator();while(i.hasNext())&#123; Object s = i.next();&#125;它的派生类包括List和Set，以下是他接口中的主要方法：boolean add(Object o)：用于添加对象到集合boolean remove(Object o)：用于删除指定的对象int size()：用于返回当前集合中元素的个数boolean isEmpty()：用于判断集合是否为空。Iterator iterator()：返回一个迭代器boolean contains(Object o)：用于查找集合中是否有指定的对象boolean containsAll(Collection c)：用于查找集合中是否有集合c中的元素boolean addAll（Collection c）：用于将集合c中的元素全部添加到该集合中void clear()：用于清空该集合void removeAll(Collection c)：用于从集合中删除从集合中所有的元素void retainAll(Collection c)：从集合中删除集合c中不包含的元素List接口List是有序的Collection，用户能够使用索引来访问List中的元素，类似数组。LIst包括以下几种子类ArrayList:：是一个数组队列，相当于动态数组。它由数组实现，随机访问效率高，随机插入、随机删除效率低。LinkedList：是一个双向链表。它也可以被当作堆栈、队列或双端队列进行操作。LinkedList随机访问效率高，但随机插入、随机删除效率低。Vector 是矢量队列，和ArrayList一样，它也是一个动态数组，由数组实现。但是ArrayList是非线程安全的，而Vector是线程安全的。Stack 是栈，它继承于Vector。它的特性是：先进后出(FILO, First In Last Out)。如果涉及到“栈”、“队列”、“链表”等操作，应该考虑用List，具体的选择哪个List，根据下面的标准来取舍。(01) 对于需要快速插入，删除元素，应该使用LinkedList。(02) 对于需要快速随机访问元素，应该使用ArrayList。(03)对于“单线程环境” 或者 “多线程环境，但List仅仅只会被单个线程操作”，此时应该使用非同步的类(如ArrayList)。对于“多线程环境，且List可能同时被多个线程操作”，此时，应该使用同步的类(如Vector)。通过下面的测试程序，我们来验证上面的(01)和(02)结论。参考代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import java.util.*;import java.lang.Class;/* * @desc 对比ArrayList和LinkedList的插入、随机读取效率、删除的效率 * * @author skywang */public class ListCompareTest &#123; private static final int COUNT = 100000; private static LinkedList linkedList = new LinkedList(); private static ArrayList arrayList = new ArrayList(); private static Vector vector = new Vector(); private static Stack stack = new Stack(); public static void main(String[] args) &#123; // 换行符 System.out.println(&quot;插入元素&quot;); // 插入 insertByPosition(stack) ; insertByPosition(vector) ; insertByPosition(linkedList) ; insertByPosition(arrayList) ; // 换行符 System.out.println(&quot;随机读取&quot;); // 随机读取 readByPosition(stack); readByPosition(vector); readByPosition(linkedList); readByPosition(arrayList); // 换行符 System.out.println(&quot;删除元素&quot;); // 删除 deleteByPosition(stack); deleteByPosition(vector); deleteByPosition(linkedList); deleteByPosition(arrayList); &#125; // 获取list的名称 private static String getListName(List list) &#123; if (list instanceof LinkedList) &#123; return &quot;LinkedList&quot;; &#125; else if (list instanceof ArrayList) &#123; return &quot;ArrayList&quot;; &#125; else if (list instanceof Stack) &#123; return &quot;Stack&quot;; &#125; else if (list instanceof Vector) &#123; return &quot;Vector&quot;; &#125; else &#123; return &quot;List&quot;; &#125; &#125; // 向list的指定位置插入COUNT个元素，并统计时间 private static void insertByPosition(List list) &#123; long startTime = System.currentTimeMillis(); // 向list的位置0插入COUNT个数 for (int i=0; i&lt;COUNT; i++) list.add(0, i); long endTime = System.currentTimeMillis(); long interval = endTime - startTime; System.out.println(getListName(list) + &quot; : insert &quot;+COUNT+&quot; elements into the 1st position use time：&quot; + interval+&quot; ms&quot;); &#125; // 从list的指定位置删除COUNT个元素，并统计时间 private static void deleteByPosition(List list) &#123; long startTime = System.currentTimeMillis(); // 删除list第一个位置元素 for (int i=0; i&lt;COUNT; i++) list.remove(0); long endTime = System.currentTimeMillis(); long interval = endTime - startTime; System.out.println(getListName(list) + &quot; : delete &quot;+COUNT+&quot; elements from the 1st position use time：&quot; + interval+&quot; ms&quot;); &#125; // 根据position，不断从list中读取元素，并统计时间 private static void readByPosition(List list) &#123; long startTime = System.currentTimeMillis(); // 读取list元素 for (int i=0; i&lt;COUNT; i++) list.get(i); long endTime = System.currentTimeMillis(); long interval = endTime - startTime; System.out.println(getListName(list) + &quot; : read &quot;+COUNT+&quot; elements by position use time：&quot; + interval+&quot; ms&quot;); &#125;&#125;运行结果如下：插入元素Stack : insert 100000 elements into the 1st position use time：1544 msVector : insert 100000 elements into the 1st position use time：1520 msLinkedList : insert 100000 elements into the 1st position use time：17 msArrayList : insert 100000 elements into the 1st position use time：1519 ms随机读取Stack : read 100000 elements by position use time：7 msVector : read 100000 elements by position use time：7 msLinkedList : read 100000 elements by position use time：8023 msArrayList : read 100000 elements by position use time：2 ms删除元素Stack : delete 100000 elements from the 1st position use time：1553 msVector : delete 100000 elements from the 1st position use time：1525 msLinkedList : delete 100000 elements from the 1st position use time：9 msArrayList : delete 100000 elements from the 1st position use time：1547 ms这里只是对性能做了大致的测试，如果需要研究为何产生如此差异，需要看下数据结构的相关资料。Set接口Set接口是一种不包含重复元素的Collection，也就是说任何两个在Set里面的元素都存在以下e1.equals(e2) == false关系，且Set最多只有一个NULL元素。很明显，Set的构造函数有一个约束条件，就是传入的Collection参数不能包含重复的元素。Queue接口Queue接口与List、Set同一级别，都是继承了Collection接口。LinkedList实现了Queue接 口。Queue接口窄化了对LinkedList的方法的访问权限（即在方法中的参数类型如果是Queue时，就完全只能访问Queue接口所定义的方法 了，而不能直接访问 LinkedList的非Queue的方法），以使得只有恰当的方法才可以使用。BlockingQueue 继承了Queue接口。队列是一种数据结构．它有两个基本操作：在队列尾部加人一个元素，和从队列头部移除一个元素就是说，队列以一种先进先出的方式管理数据，如果你试图向一个 已经满了的阻塞队列中添加一个元素或者是从一个空的阻塞队列中移除一个元索，将导致线程阻塞．在多线程进行合作时，阻塞队列是很有用的工具。工作者线程可 以定期地把中间结果存到阻塞队列中而其他工作者线线程把中间结果取出并在将来修改它们。队列会自动平衡负载。如果第一个线程集运行得比第二个慢，则第二个 线程集在等待结果时就会阻塞。如果第一个线程集运行得快，那么它将等待第二个线程集赶上来。下表显示了jdk1.5中的阻塞队列的操作：add 增加一个元索 如果队列已满，则抛出一个IIIegaISlabEepeplian异常remove 移除并返回队列头部的元素 如果队列为空，则抛出一个NoSuchElementException异常element 返回队列头部的元素 如果队列为空，则抛出一个NoSuchElementException异常offer 添加一个元素并返回true 如果队列已满，则返回falsepoll 移除并返问队列头部的元素 如果队列为空，则返回nullpeek 返回队列头部的元素 如果队列为空，则返回nullput 添加一个元素 如果队列满，则阻塞take 移除并返回队列头部的元素 如果队列为空，则阻塞remove、element、offer 、poll、peek 其实是属于Queue接口。Map接口Map接口没有继承于接口Collection，Map提供key到value的映射。键值对key-value，主要方法如下：boolean equals(Object o)：用于比较对象boolean remove(Object o)：用于删除一个对象void put(Object key, Object value)：用于添加key和valueMap可分为HashMap、HashTable、WeakHashMap、ConcurrentHashMap等。但是我们常用的主要是HashMap和HashTable，下面比较下两者区别：HashMap是非线程安全的，HashTable是线程安全的。HashMap的键和值都允许有null值存在，而HashTable则不行。因为线程安全的问题，HashMap效率比HashTable的要高。能答出上面的三点，简单的面试，算是过了，但是如果再问：Java中的另一个线程安全的与HashMap及其类似的类是什么？(ConcurrentHashMap)同样是线程安全，它与HashTable在线程同步上有什么不同？(synchronized关键字加锁的原理，其实是对对象加锁，不论你是在方法前加synchronized还是语句块前加，锁住的都是对象整体，但是ConcurrentHashMap的同步机制和这个不同，它不是加synchronized关键字，而是基于lock操作的，这样的目的是保证同步的时候，锁住的不是整个对象。事实上，ConcurrentHashMap可以满足concurrentLevel个线程并发无阻塞的操作集合对象)能把第二个问题完整的答出来，说明你的基础算是不错的了。下面浅析更多区别。HashMap1) hashmap的数据结构Hashmap是一个数组和链表的结合体（在数据结构称“链表散列“），如下图示：当我们往hashmap中put元素的时候，先根据key的hash值得到这个元素在数组中的位置（即下标），然后就可以把这个元素放到对应的位置中了。如果这个元素所在的位子上已经存放有其他元素了，那么在同一个位子上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。2)使用和遍历1234567891011Map map = new HashMap();map.put(&quot;Rajib Sarma&quot;,&quot;100&quot;);map.put(&quot;Rajib Sarma&quot;,&quot;200&quot;);//The value &quot;100&quot; is replaced by &quot;200&quot;.map.put(&quot;Sazid Ahmed&quot;,&quot;200&quot;);Iterator iter = map.entrySet().iterator();while (iter.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter.next(); Object key = entry.getKey(); Object val = entry.getValue();&#125;HashTable和HashMap区别继承不同。public class Hashtable extends Dictionary implements Mappublic class HashMap extends AbstractMap implements MapHashtable 中的方法是同步的，而HashMap中的方法在缺省情况下是非同步的。在多线程并发的环境下，可以直接使用Hashtable，但是要使用HashMap的话就要自己增加同步处理了。Hashtable中，key和value都不允许出现null值。在HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。当get()方法返回null值时，即可以表示 HashMap中没有该键，也可以表示该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。两个遍历方式的内部实现上不同。Hashtable、HashMap都使用了 Iterator。而由于历史原因，Hashtable还使用了Enumeration的方式 。哈希值的使用不同，HashTable直接使用对象的hashCode。而HashMap重新计算hash值。Hashtable和HashMap它们两个内部实现方式的数组的初始大小和扩容的方式。HashTable中hash数组默认大小是11，增加的方式是 old*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。","categories":[{"name":"java base","slug":"java-base","permalink":"http://www.fufan.me/categories/java-base/"}],"tags":[{"name":"java 数据结构","slug":"java-数据结构","permalink":"http://www.fufan.me/tags/java-数据结构/"}]},{"title":"JAVA的Reflection反射机制","slug":"JAVA的Reflection反射机制","date":"2016-09-11T06:55:00.000Z","updated":"2018-11-05T03:13:21.648Z","comments":true,"path":"2016/09/11/JAVA的Reflection反射机制/","link":"","permalink":"http://www.fufan.me/2016/09/11/JAVA的Reflection反射机制/","excerpt":"","text":"反射即reflectionjava反射运用了代理模式，代理模式在之后学习的设计模式中可以了解反射主要用了以下几点：在运行时判断任意一个对象所属的类。在运行时构造任意一个类的对象。在运行时判断任意一个类所具有的成员变量和方法。在运行时调用任意一个对象的方法Class首先要搞清楚Class这个类，每个类在创建的时候都会有Class这个类伴随产生，这个Class是JVM产生的，由于是JVM产生的，所以我们一般获取Class的方法是：object.getClass()Class.forName(“java.lang.String”)Class.getSuperClass()运用.class语法,如java.lang.String.classprimitive wrapper classes的TYPE语法,如：Boolean.TYPE，类似Boolean.class12345Class&lt;?&gt; clazz = s.getClass();Class&lt;?&gt; clazz2 = Class.forName(&quot;com.fufan.reflection.Son&quot;);Class&lt;?&gt; clazz3 = clazz2.getSuperclass();Class&lt;?&gt; clazz4 = com.fufan.reflection.Son.class;Class&lt;?&gt; clazz5 = Boolean.class;Class是Reflection起源。针对任何您想探勘的class，唯有先为它产生一个Class object，接下来才能经由后者唤起为数十多个的Reflection APIs接下来就可以通过Class调用衍生出的一系列API：getName()：获得类的完整名字。getFields()：获得类的public类型的属性。getDeclaredFields()：获得类的所有属性。getMethods()：获得类的public类型的方法。getDeclaredMethods()：获得类的所有方法。getConstructors()：获得类的public类型的构造方法。getMethod(String name, Class[] parameterTypes)：获得类的特定方法，name参数指定方法的名字，parameterTypes 参数指定方法的参数类型。getConstructors()：获得类的public类型的构造方法。getConstructor(Class[] parameterTypes)：获得类的特定构造方法，parameterTypes 参数指定构造方法的参数类型。FieldFiled类：代表类的成员变量（成员变量也称为类的属性）。1String fieldName = field.getName();MethodMethod类：代表类的方法，invoke1Object value = getMethod.invoke(object, new Object[] &#123;&#125;);ConstructorConstructor类：代表类的构造方法，调用有参和无参newInstance()：通过类的不带参数的构造方法创建这个类的一个对象。newInstance(new Object[]{value})：当调用有参构造函数时使用。12345//无参构造方法Constructor constructor1 = classType.getConstructor();//有参构造方法Constructor constructor2 = classType.getConstructor(new Class[] &#123;int.class, String.class&#125;);代码示例11234567891011121314151617181920212223242526272829// 获得对象的类型 Class&lt;?&gt; classType = object.getClass(); System.out.println(&quot;Class:&quot; + classType.getName()); // 通过默认构造方法创建一个新的对象 Object objectCopy = classType.getConstructor(new Class[] &#123;&#125;).newInstance(new Object[] &#123;&#125;); // 获得对象的所有属性 Field fields[] = classType.getDeclaredFields(); for (int i = 0; i &lt; fields.length; i++) &#123; Field field = fields[i]; String fieldName = field.getName(); String firstLetter = fieldName.substring(0, 1).toUpperCase(); // 获得和属性对应的getXXX()方法的名字 String getMethodName = &quot;get&quot; + firstLetter + fieldName.substring(1); // 获得和属性对应的setXXX()方法的名字 String setMethodName = &quot;set&quot; + firstLetter + fieldName.substring(1); // 获得和属性对应的getXXX()方法 Method getMethod = classType.getMethod(getMethodName, new Class[] &#123;&#125;); // 获得和属性对应的setXXX()方法 Method setMethod = classType.getMethod(setMethodName, new Class[] &#123; field.getType() &#125;); // 调用原对象的getXXX()方法 Object value = getMethod.invoke(object, new Object[] &#123;&#125;); System.out.println(fieldName + &quot;:&quot; + value); // 调用拷贝对象的setXXX()方法 setMethod.invoke(objectCopy, new Object[] &#123; value &#125;);&#125;ArrayArray类：提供了动态创建数组，以及访问数组的元素的静态方法代码示例2123456789101112131415161718//一维数组的使用Object array = Array.newInstance(Integer.TYPE, 10);System.out.println(Integer.TYPE);for(int index=1; index&lt;10; index ++)&#123; Array.set(array, index, index);&#125;System.out.println(Array.get(array, 4));//多维数组的使用Object arrays = Array.newInstance(String.class, 3,5);Object array1 = Array.get(arrays, 2);Array.set(array1, 3, &quot;fufan&quot;);String[][] arrayInt = (String[][]) arrays; System.out.println(arrayInt[1][3]);","categories":[{"name":"java base","slug":"java-base","permalink":"http://www.fufan.me/categories/java-base/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.fufan.me/tags/java/"}]}]}